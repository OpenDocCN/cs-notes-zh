- en: P22：Lecture 22 Data Replication and Distributed Transactions I - ___main___
    - BV1cL411t7Fz
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P22：讲座22 数据复制和分布式事务 I - ___main___ - BV1cL411t7Fz
- en: Because we would like to actually move on next to the next topic of like what
    happens when we try to run transactions on parallel databases。 which is going
    to be another fun topic to discuss。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们接下来要讨论的话题是当我们尝试在并行数据库上运行事务时会发生什么。这将是另一个有趣的话题。
- en: '![](img/36def6d6b9866c9c33a169a2bce65f2c_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36def6d6b9866c9c33a169a2bce65f2c_1.png)'
- en: But before that， right， so just do a little bit of review。 So the whole reason
    why we started talking about parallelism， right。 was because we've got tons of
    different machines now。 And like， you know。 how can we actually leverage them
    such that we don't。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但在此之前，稍微复习一下。我们开始谈论并行处理的原因是因为现在有大量不同的机器。而且，你知道的，我们如何才能有效利用它们，以免浪费。
- en: we can actually gain performance right by doing so。 So basically that's what
    we were trying to。 that's what we were trying to discuss starting last lecture。
    And by the way。 if you guys don't mind turning on videos， that would be great。
    I think right now we're seeing like Warren and Jack， I mean， thanks for the busy
    and gate。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们实际上可以提高性能。所以基本上，这就是我们上节课试图讨论的内容。顺便说一下，如果你们不介意打开视频的话，那就太好了。我现在看到的是Warren和Jack，感谢你们的忙碌与参与。
- en: And that I feel like I'm just talking to like a wall of very nice looking， some
    pro topic。 Great。 Yeah， so， right， so and then also as I was saying last time，
    right， we have pretty much by now。 And then we have a couple of different methods
    that we've already done。 And then we have a couple of different methods that we've
    already done。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得我就像是在对着一面非常漂亮的墙说话，真是个专业的话题。太好了。是的，正如我上次说的，我们差不多已经掌握了。然后我们已经做了一些不同的方法。然后我们已经做了一些不同的方法。
- en: And then we have a couple of different methods that we've done。 And then we
    have a couple of different methods that we've done。 And then we have a couple
    of different methods that we've done。 And then we have already now master of single
    node career processing。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们已经做了一些不同的方法。然后我们已经做了一些不同的方法。然后我们已经做了一些不同的方法。现在我们已经掌握了单节点计算处理。
- en: So that's why now we're transitioning to the next module in the class。 which
    is talking about what happens when we have multiple machines。 So last time， I
    did， yeah。 also talked about this picture with different types of architectures
    that you encounter when we talk about parallel career processing。 So this aspect
    of shared memory， where we have a bunch of CPUs or a bunch of course they're just
    sharing a common piece of RAM。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在我们正在过渡到课堂的下一个模块，这个模块讨论的是当我们有多台机器时会发生什么。所以上次我也谈到过这张图，它展示了我们在谈论并行计算处理时遇到的不同类型的架构。这里的共享内存方面，我们有一堆CPU或多个核心，它们共享同一块RAM。
- en: right， which is main memory in this case。 That's shared memory。 There's also
    shared disk where each individual machine have their own RAM。 But then they're
    basically sharing a same disk across all the other machines。 And there's also
    this aspect of share nothing architecture where nobody shares anything。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对，这里指的是主内存，这就是共享内存。还有共享磁盘架构，每台机器都有自己的RAM，但它们基本上共享同一块磁盘。还有共享无架构（shared nothing
    architecture），在这种架构下，任何东西都不共享。
- en: So we now need to communicate across the network and also reach data that can
    be stored on another machine or data that has already been loaded on another machine's
    main memory。 So these are the three types of architectures that you see when people
    talk about parallel data processing。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们现在需要通过网络进行通信，并且访问存储在另一台机器上的数据，或者访问已经加载到另一台机器主内存中的数据。这是人们在谈论并行数据处理时会涉及的三种架构。
- en: And then for this class， we're going to focus on the shared nothing architecture。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在这节课中，我们将重点讨论共享无架构（shared nothing architecture）。
- en: '![](img/36def6d6b9866c9c33a169a2bce65f2c_3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36def6d6b9866c9c33a169a2bce65f2c_3.png)'
- en: And then at this year also talk about in the last lecture about like how do
    we do data petitioning in that world right。 So now we have a bunch of disks， we
    have， we still have the whole relation to worry about right except that now the
    accept that now the relation might not fit onto one single machine。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在今年的课程中，我也讲到过上节课讨论的如何在这个环境中进行数据分区。所以现在我们有了很多磁盘，我们仍然需要考虑整个关系，只是现在可能整个关系不能装入单台机器中。
- en: So how do we actually want to petition data across all the different machines
    that we have。 So we also talked about three different potential schemes of doing
    that。 So in range petitioning。 we basically just set aside an arbitrary range
    that each of the machines should be holding in terms of records。 So for instance，
    in this case， the example last time we're students。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们到底怎么在所有不同的机器之间分配数据呢？我们也讨论了三种可能的方案来实现这一点。对于范围分配，我们基本上只是设定一个任意的范围，每台机器应该持有这个范围内的记录。例如，在上次讨论的案例中，我们是学生数据。
- en: So we can imagine we need to petition students records across multiple machines。
    So we can do range petitioning by just assigning a range of let's say last names。
    starting letters right on to individual disks。 So the second scheme here called
    hash petitioning is basically relying on a separate hash function to do this petitioning
    for us。 So basically we're going to feed each of the records across using a hash
    function and then whatever that hash function decides to put the record on。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以想象，需要将学生记录分配到多台机器上。我们可以通过简单地分配一个范围，比如按姓氏的首字母，把它们分配到不同的磁盘上，这就是范围分配。第二种方案，称为哈希分配，基本上依赖于一个独立的哈希函数来为我们进行分配。我们将每条记录通过哈希函数处理，然后无论哈希函数决定将记录放到哪里。
- en: who subsequently send that record to that particular machine。 So that is the
    second scheme。 And the third scheme is called round Robin， and that basically
    means we're just going to rotate among all the different disks that we have and
    then send the two ball the new record where they arrive。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将该记录发送到特定的机器上。这是第二种方案。第三种方案称为轮询（round Robin），基本上意味着我们会在所有不同的磁盘之间轮流，发送新的记录到它们到达的地方。
- en: So the point that I did here was making last time was basically these two different
    aspects when it talks about locality of accessing the records。 and also balancing
    balancing the load across all the different machines。 So。 can someone remind us
    like you know why for instance round Robin is like the most in terms of balancing
    the load across all the different machines。 Most in this case means it's kind
    of like the most fair right like every machine is going to get hopefully an equal
    amount roughly equal amount of of tools。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我上次讲到的重点基本上是这两个方面：一是访问记录的局部性，二是如何平衡所有机器之间的负载。那么，有人能提醒我们，为什么例如轮询调度在平衡负载方面是最有效的吗？这里的“最有效”意味着它是最公平的，意味着每台机器都会大致获得相等数量的元组。
- en: And so that's why I'm not saying that because they're not being sorted by a
    specific key right so for instance we're not assigning a particular range so we
    don't have to worry about like you know what if。 like you know， like I think what
    if I did see a very popular name right so then that case then whatever machine
    that。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是为什么我并没有说它们是按照特定的键排序的。比如说，我们并没有为每个机器分配特定的范围，因此我们不必担心，像你知道的，万一，假设我看到一个非常受欢迎的名字，那么在这种情况下，那个机器就会负责。
- en: I might end up like having most of the tuples right so but in this case since
    we're doing round Robin。 that's why we are doing that in that case load will be
    balanced because we don't really care what is the content of the individual to
    pull on the set。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能最终会正确处理大部分的元组，但在这种情况下，由于我们采用的是轮询调度（round Robin）。这就是我们这么做的原因。在这种情况下，负载将会均衡，因为我们其实并不关心每个集合中的单个元素的内容。
- en: Does that make sense。 Now the other hand like you know why is like round Robin
    for instance the least right in terms of locality of access。 meaning that it's
    most difficult to get to an individual to pull。 So it's basically a to add sort
    right so like you know the same reason why it makes load to be balanced。 It's
    also the reason why it's making it hard for us to predict right you know which
    machine is actually holding on to specific record。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这样讲清楚了吗？另一方面，为什么轮询调度在访问局部性方面是最差的呢？意味着它是最难访问单个元素的。它本质上是一个“添加排序”的方法，正如它能使负载均衡一样，也正是它让我们很难预测到底是哪台机器持有特定的记录。
- en: So in this case we are assuming that there's no global index anywhere right
    so we can look up a particular record。 So the only way that we can do it is to
    basically query each of the machine asking you know do you have the record with
    a bit of name on it。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们假设没有全局索引可供查找特定记录。所以我们能做的唯一方法就是查询每台机器，询问是否拥有某个名字的记录。
- en: Versus if we have the hash petitioning scheme or the range petitioning scheme。
    we already know a priority which machine a particular record is going to reside
    right because you know just consult the range。 or just run the hash function and
    that will tell you which machine currently has that record。 If that record actually
    exists。 Okay。 Any questions about this so far。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 相比于如果我们有哈希分区方案或范围分区方案。我们已经知道哪个机器上会有特定的记录，因为你知道只需要查看范围，或者运行哈希函数，它就会告诉你哪个机器上当前存有该记录。如果该记录确实存在。好，有关这一点有问题吗？
- en: By the way this is not an exhaustive list of ways that you can petition data
    across multiple machines right so this is just basically given you a sample of
    what you can do。 So there are other schemes as well so for instance why don't
    we just make copies of data if you can afford it。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，这并不是一个详尽的列表，列出了你可以如何将数据分区到多个机器上的所有方式。这基本上只是给你一个示例，展示你可以做什么。所以也有其他方案，比如为什么我们不直接复制数据，如果你能承担得起的话。
- en: Right， so you don't have to petition it this way I mean we can if we have enough。
    And also memory we can just copy the data such that everybody is getting like
    you know the entire copy of the whole relation on its own。 Right if that's the
    case and it definitely makes a career processing much easier because everybody
    already has the entire relation。 But obviously that means we need to pay more
    in terms of this story and also memory as well right。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对，所以你不必像这样进行分区，我是说如果我们有足够的内存，我们可以直接复制数据，让每台机器都拥有整个关系的副本。对，如果是这样，确实会让并行处理变得更容易，因为每台机器已经拥有了整个关系。但显然，这意味着我们在存储和内存上需要付出更多的代价。
- en: So that's one of the photos。 So after petitioning we started talking about different
    ways of running our now familiar set of operations that we want to run on the
    tools。 For instance hashing。 So what I did here went through last time was this
    two phase scheme right where we want to be able to do parallel hashing。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是其中一种方式。在分区之后，我们开始讨论运行我们现在熟悉的操作集的不同方法。比如哈希操作。所以我上次提到的是这个两阶段方案，我们希望能够并行哈希。
- en: The idea is to first what we call shuffle the data across the different machines
    using a particular hash function。 What that means is we're basically going to
    just like you know decide on which machine to actually hold on to a particular
    piece of data。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是首先使用特定的哈希函数将数据在不同机器之间进行“洗牌”。这意味着我们基本上会决定将特定的数据片段分配给哪台机器来保存。
- en: And then we're just going to stand it over to that to that machine， we're using
    a hash function。 And then after that we are just going to like you know build
    an internal hash table。 And then you know you can now use our favorite algorithm
    if you like right to build up that hash table。 So it fits all in memory then we
    just like you know build it entirely using a hash function and then we're done。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们就把它交给那个机器，我们使用哈希函数。接着我们就像你知道的那样构建一个内部哈希表。然后你知道，现在如果你愿意的话，可以使用我们最喜欢的算法来构建那个哈希表。所以它全部都适合放进内存，然后我们就像你知道的那样，完全使用哈希函数构建，之后就完成了。
- en: And then like you know if in a case where a single bucket does not actually
    takes up more space than needed。 Then we just do the two phase on the multi phase
    positioning that we already talked about earlier before mid term one right in
    terms of this out of core algorithms for doing in memory。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后像你知道的那样，如果某个桶没有占用比需要的更多空间，那么我们就执行我们之前提到的多阶段分区方案，就像我们在期中前讨论过的内存外算法一样。
- en: So do people remember why we need like separate hash functions for doing this
    so to see like you know we now have different hash functions here right as opposed
    to the initial hash function here H of N。 Do people remember why we need that
    why not just use the same hash function all the way to。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所以大家记得为什么我们需要不同的哈希函数来做这件事吗？就像你知道的，我们现在有不同的哈希函数，而不是最初的哈希函数H of N。大家记得为什么需要这样做吗？为什么不直接用同一个哈希函数？
- en: So part of that was also the reason why we talked about our course right。 Yeah
    exactly so because if we just use the same hash function let's say H and right。
    Then everything will be everything that gets ended up on the same the blue disc
    right we'll just be hash the same bucket。 So that's not good right I mean it's
    not really distributing it into different buckets so like you know in that's in
    the sense of career processing we're actually not helping that much。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分也是我们讨论课程的原因之一。是的，正是因为如果我们只是使用相同的哈希函数（比如 H），那么所有最终出现在同一个蓝色磁盘上的数据将被哈希到同一个桶里。这就不好了，意味着它们并没有被分配到不同的桶中。所以在并行处理的意义上，这样做其实没有多大帮助。
- en: So we actually want to separate the two goals if they do have different values
    right into different buckets such that we can run。 Let's say like a join later
    on right easily。 So for that reason and the same reason why we have different
    hash functions or our core algorithms we want to make sure that we actually pick
    a different hash function as the one that we used in the first step。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们实际上希望将两个目标，如果它们的值不同，分到不同的桶中，这样我们就可以轻松地进行后续的连接操作。所以出于这个原因，以及我们使用不同哈希函数或核心算法的同样原因，我们需要确保在第一步中使用的哈希函数和这一步使用的哈希函数是不同的。
- en: Of course this is still subject to the same problem which is what happens if
    all the two goals actually are exactly the same。 Right so remember the let's say
    like I think the example that we use for our core algorithms was the case of gender。
    So in that case then like you know we basically need a separate mechanism to check
    whether like it is the case that everything is just the same。 The same deal there。
    Okay so now that we understand how to do hashing the next part in the lecture
    I want to basically go through how to use these different opera。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这仍然存在同样的问题，那就是如果两个目标完全相同会发生什么？记得我们在讲核心算法时使用的例子是性别。在这种情况下，我们基本上需要一个单独的机制来检查是否所有的值都是相同的。情况是一样的。好，现在我们了解了如何进行哈希，接下来的部分，我将讲解如何使用这些不同的操作。
- en: how to use these different basic operations to implement the relational operators
    that we all know about。 And namely like you know the things that are listed here
    on this line。 Okay so first one join。 Right so how do we do parallel join。 So
    scenario here is just the same as when we were talking about our core algorithms。
    We have two relations RNS and we want to join them across some value right some
    some some attributes。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用这些基本操作来实现我们熟悉的关系操作符。特别是这里列出的一些操作。首先是连接。如何进行并行连接？这里的场景和我们讨论核心算法时是一样的。我们有两个关系
    R 和 S，想要基于某个值或者属性进行连接。
- en: So here's one way of doing this hash join across multiple machines。 So at first
    shuffle one of the relations let's say are across the different machines that
    we have。 And then we're going to build a hash table after each of these machines
    receive its own petition。 So that's what is happening here on the right hand side
    right so I use H of N to shuffle to both of our across multiple machines in this
    case we have three。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里是如何在多台机器之间执行哈希连接的一种方式。首先，我们将其中一个关系（假设是跨越我们拥有的不同机器的关系）进行洗牌。然后，在每台机器接收到自己的数据后，我们会构建一个哈希表。所以这里右侧发生的就是这样，我使用
    H of N 来将数据洗牌到我们这三台机器上。
- en: And then we're going to use like you know our our hash table building mechanism
    to basically build up the hash table that corresponds to the tools that we have
    received。 We wait for the hash table to finish building。 And then we subsequently
    use the same mechanism to shuffle the two posts from the other relation across
    the network。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将使用我们构建哈希表的机制，基本上构建出一个对应于我们收到的工具的哈希表。我们等待哈希表的构建完成。接着，我们使用相同的机制将另一方关系中的两个数据项通过网络洗牌。
- en: So here we use the same hash function right H of N to shuffle all the as to
    both across the network。 So to post as opposed to join we'll basically ended up
    on the same machine。 Right。 So。 and what happens when we receive as to post on
    like you know after we have wrapped after we have built up the hash table for
    our。 Well we just check the hash table that we have already built up and see if
    any of the two posts would actually match with two posts on our。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里我们使用相同的哈希函数，H of N，将所有的操作洗牌到网络中。与连接不同，我们基本上会把数据放到同一台机器上。对吧？那么，当我们收到数据时，会发生什么呢？你知道，在我们已经构建了哈希表之后，我们只需要检查我们已经构建好的哈希表，看看是否有任何两个元素在哈希表中匹配。
- en: And if so we're just right the output to the disk。 And if not we're just basically
    don't generate any output。 Okay。 Because that's it。 So in this case most of the
    steps actually parallel except for the first step where we need to build up the
    hash table。 For instance right writing to the disk that you're seeing here on
    the far right that just wrote the error on this part is completely parallel。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有匹配项，我们就将结果写入磁盘。如果没有匹配项，我们就基本上不生成任何输出。好吧，就这样。所以在这个过程中，大部分步骤实际上都是并行的，除了第一个步骤，我们需要构建哈希表。例如，写入磁盘的部分，你看到最右边的部分，写入磁盘是完全并行的。
- en: So each of the disk basically just do its own thing as it receives to both of
    us。 Right。 Just probes the hash table that is already a memory。 And then if there's
    anything match。 then like you know just dumb into the depth right all that stuff
    is completely can be done completely in parallel so we don't need to do anything
    there。 In terms of coordination across the different machines。 Right。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所以每个磁盘基本上都会做自己的事情，当它收到数据时，对吧？它只需要在已经加载到内存中的哈希表中进行查找。如果有匹配项，就将其存入磁盘，所有这些操作完全可以并行完成，因此我们在不同机器之间不需要做任何协调。
- en: But then notice that we do have to wait for the hash table to first build up
    on our。 So that is the step that takes time that may take time right and then
    in case there are。 Straplers that we need to wait for the last hash table to be
    built before we can do the streaming of。 So there's a variation on this scheme
    that does not actually require waiting for the hash table to be built that we'll
    talk about actually later on in a few slides。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但请注意，我们确实需要等待哈希表首先在我们这里构建起来。所以，这是需要时间的步骤，可能会花时间对吧？然后如果有一些需要等待的情况，我们就需要等到最后的哈希表构建完成，才能进行流式处理。所以有一种变种方案，实际上不需要等待哈希表构建完成，我们稍后几张幻灯片中会讨论这个。
- en: But then I can already tell you I have time that says nothing is free right
    again no such thing as free lunch。 So therefore like you know that that particular
    algorithm is actually going to use up more space and memory in order to do that。
    But before then like you know any questions about this particular scheme。 Before
    we move on。 So this is basically like the simplest way you can imagine running
    a parallel has joint right so which is shuffle one of the one of the relations
    across the different machines with petition it basically。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但我可以告诉你，我已经有时间可以说没有什么是免费的，没这回事什么免费午餐。因此，你知道，那个特定的算法实际上会使用更多的空间和内存来实现这个目标。但在此之前，你知道，关于这个方案有任何问题吗？在我们继续之前。这基本上是你能想象到的最简单的并行连接方式，就是把其中一个关系洗牌到不同的机器上，并进行分区。
- en: We let each of these machines。 You know construct their hash tables and memory。
    And then we're just like you know send the other two polls from the other from
    the from the relation to be joined across these different machines and then let
    it do a business so to speak。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让每台机器自己构建哈希表并存入内存，然后我们就像你知道的那样，把要连接的其他数据从其他关系发送到不同的机器上，然后让它去完成任务。
- en: Completely independently。 Make sense。 So now we ask the usual question right
    so what if there's actually not sufficient memory to build up this hash table
    for our that you see here like you're on the right hand side right。 What if the
    whole hash table does not fit in memory so what do we do。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 完全独立地进行。明白了吗？所以现在我们问一个常见的问题，对吧？那就是如果没有足够的内存来构建这个哈希表呢？你看右边那个，假设我们无法把整个哈希表放进内存里，那我们该怎么办？
- en: What do you think we should do。 Recursive。 Well you actually already learned
    this particular algorithm known as the greatest hash join right remember that。
    Or you will remember that when we talk about mid term to us opposed。 So there
    there is this algorithm that allows us to actually do this like you know。 Mac
    to this hashtag right up on this hash table or do has joint right without forcing
    that the whole hash table with fit and memory。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为我们应该怎么做？递归？其实你已经学过这个算法了，叫做Greatest Hash Join，记得吗？或者你会在我们讨论期中考试时记得。当时有一种算法可以让我们像这样操作，比如说在这个哈希表上做Hash
    Join，而不需要强制要求整个哈希表都能够适应内存。
- en: So we're just doing the same thing here。 So first step right in this case we
    just use grace has joint to try to fill up the hash table across multiple steps。
    The last one is to basically just write out the buckets as we have them onto the
    disc as you may remember。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们这里做的其实是相同的事情。首先在这种情况下，我们只是使用Grace Hash Join来尝试跨多个步骤填充哈希表。最后一步基本上就是把我们已经有的桶写入磁盘，正如你可能还记得的那样。
- en: Except that in this case we need to do it multiple times。 Basically we want
    to do do the same thing but for both of the relations。 And as we know that the
    entire hash table that corresponds to our does not fit in memory。 So and in the
    case that if asked also doesn't fit right then we basically need to do this using
    multiple passes by first writing out individual buckets to the disc。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 只是，在这种情况下，我们需要多次进行操作。基本上我们想做的事情是对两个数据集都进行相同的操作。正如我们所知道的，整个哈希表不能完全放入内存中。如果数据集A也放不下，那么我们基本上就需要通过多次传递来实现，首先将单个桶写入磁盘。
- en: And then like after that right we can then retrieve the buckets that corresponds
    to our and the matching bucket from us and then do the memory has joint just like
    how we were doing the grace has joint algorithm。 So hopefully this is just review
    for most of you right the only thing here is really just this initial shuffling
    step or petitioning step using this new hash function here that we are calling
    it a band。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在那之后，我们可以检索与数据集A对应的桶，以及数据集B中匹配的桶，然后进行内存中的Hash Join，就像我们执行Grace Hash Join算法时一样。所以希望这对大多数人来说只是复习，唯一不同的地方其实是这个初步的洗牌步骤，或者说是使用我们称之为Band的新哈希函数来进行分配。
- en: But effectively it's just a way of petitioning the two posts across all the
    machines that we have。 So here's like the grace joint has joint parallel version
    in text form right so the first pass we do petitioning by shuffling the two posts
    across the machines that we have。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，这只是一种方式，用来将两个数据集分配到我们所有的机器上。所以这里是Grace Hash Join算法并行版本的文本形式，首先我们通过在机器间洗牌两个数据集来进行分配。
- en: And then after that we kind of just run local grace has joint on the individual
    note。 Namely we write out the individual buckets to the disc as they fill in。
    And then after that we go across multiple passes right as needed as you remember
    what a grace has joint。 And then after that we just like you know read in the
    bucket for from the corresponding relationship we joined。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在此之后，我们基本上就可以在各个节点上执行本地的Grace Hash Join。也就是说，我们将单个桶写入磁盘，直到它们填满。然后，根据需要进行多次传递，就像你记得的Grace
    Hash Join一样。之后，我们就像之前一样，从相应的关系中读取桶并进行连接。
- en: and then we perform the joint locally。 Again， this is nearly perfect speed up
    right because you know once again we both of the steps actually can be run and
    complete independence of independently from each other。 except the first step
    in terms of shuffling the to goals across the network right。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在本地执行连接。再次强调，这几乎是完美的加速，因为你知道，一旦两步都能够在相互独立的情况下执行和完成，除了第一步涉及将目标通过网络洗牌的步骤之外，其他都可以独立进行。
- en: The subsequent steps is basically just like you know your favorite grace has
    joint algorithm。 So you can just run each of the machines and let them run in
    parallel。 And again。 there's also a variant of this that does not require waiting。
    It's called the extra and we don't actually have time to cover that in this class
    so I invite you to check out this particular keyword or the paper corresponding
    to if you're interested。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 后续的步骤基本上就像你知道的你最喜欢的Grace Hash Join算法一样。你可以运行每台机器，让它们并行运行。还有一个变种是不需要等待的，它叫做Extra，我们实际上没有时间在这门课上讲解，所以如果你感兴趣，我邀请你查阅这个关键词或相关的论文。
- en: But that's basically I've already introduced two different ways that we can
    run parallel joint right。 namely this so called naive joint by just shuffling
    all the data for corresponding to the two different relations。 Or in the case
    where it doesn't fit everything doesn't fit a memory then we just do this parallel
    grace has joint。 Actually， we'll be talking about cement symmetric hash joint
    later on it's just at this particular variant of the parallel grace hash joint
    that we won't have time to cover in this class。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 但基本上，我已经介绍了两种不同的方式来执行并行连接。即所谓的天真连接，通过对两个不同关系的所有数据进行打乱。或者在内存不足以容纳所有数据的情况下，我们执行并行的Grace哈希连接。实际上，我们稍后会讨论对称哈希连接，只是在这种并行Grace哈希连接的特定变体中，我们没有时间在这节课上覆盖。
- en: So far so good。 Okay。 Right， so now let's talk about sorting right which is
    yet another one of these relational operators that we have been dealing with。
    Now I want to be able to run this across model machines。 How do we do that。 So
    we're fairly straightforward so we basically just do something very similar so
    we shuffle the shuttle to post across all the machines that we have。 And then
    we just like you know， figure out what range of records that each of the machines
    should have。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止一切顺利。好的。那么现在我们来谈谈排序，它是我们一直在处理的关系操作之一。现在我希望能够跨多个机器运行这个操作。我们该怎么做呢？其实很简单，我们基本上做类似的操作，将数据打乱并分配到所有机器上。然后我们就知道每台机器应该处理哪些范围的记录。
- en: And then you can run your favorite sort algorithm after that。 Right。 So for
    instance。 in this case like you know I have randomly petitioned the range of to
    close by one of the attributes。 and it turns out to the numeric numeric。 So I
    just arbitrarily assigned three different ranges。 or the three machines that I
    have。 So the first， the blue machine would get everything between negative infinity
    to 10。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以在之后运行你喜欢的排序算法。所以例如，在这种情况下，我已经根据某个属性随机分配了数据范围，结果发现它是数值型的。所以我随意地为三个机器分配了三个不同的范围。第一个，蓝色的机器会处理从负无穷到10之间的所有数据。
- en: And then the second machine the green machine here will get like everything
    between 11 to 100。 And then everything else will go on to the orange machine。
    So we first do this petitioning or shuffling step by just using this range based
    petitioning。 And then after that， like you know how we want to proceed in terms
    of running the local sort。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后第二台机器，即绿色的机器，将处理从11到100之间的所有内容。其余的则会被分配到橙色的机器上。所以我们首先通过基于范围的分配进行这种分配或打乱步骤。然后，接下来，我们知道如何在运行局部排序时进行处理。
- en: It's up to us。 And run any of your favorite sorting algorithm once everything
    has been located to a bigger machine。 Right。 Yeah， so that's why I'm calling like
    you know the other n minus one passes right because it might depend on what。 what，
    what sort of algorithm we ended up using so that might end up being multi passes
    as well。 Yeah， but that's it。 So that gives us the correct result right because
    like each of the brain。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这取决于我们。一旦所有数据被分配到更大的机器上，我们可以运行任何你喜欢的排序算法。对吧？是的，这就是为什么我称之为其他的n-1次排序，因为它可能依赖于我们使用的排序算法，这可能最终会导致多次排序。是的，但就是这样。所以这给我们带来了正确的结果，因为每个数据范围都会得到处理。
- en: each range of two goals we sort it on the corresponding machines right。 But
    a problem， however。 is my， is performance。 So this is the same thing that we talked
    about when we were talking about how to distribute the tools across different
    machines。 So how can we avoid data skew， because for instance。 maybe all the tools
    were like you know having most of them were having values between like 11 to 100
    for instance。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个范围的两组数据我们会在相应的机器上进行排序。但是有一个问题，那就是性能。所以这其实和我们之前谈论如何将工具分布到不同机器上的问题类似。那么我们如何避免数据倾斜呢？因为例如，可能所有的工具大部分值都在11到100之间。
- en: So in that case the green machine will get most of the tools and therefore get
    most of the work to be done。 So if we don't want that to happen。 How can we do
    something to this scheme right such that we avoid having data skills。 Anyone has
    any idea。 And you're not allowed to pick in subsequent lectures life slice。 Okay。
    how is that histogram。 What is our。 You can do round robin but like you know the
    problem around Robin is the second and the subsequent and everything and other
    steps are no longer independent right because if we do round robin。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种情况下，绿色机器会获得大部分的工具，从而承担大部分的工作。如果我们不想让这种情况发生，我们该如何调整这个方案呢？这样可以避免数据倾斜。有人有想法吗？而且你不允许在随后的讲座中选择切片。好吧，这个直方图怎么样？我们的目标是什么？你可以使用轮询方法，但问题在于第二步和后续步骤就不再是独立的了，因为如果我们进行轮询。
- en: Then the blue machine will get like it can potentially get to go from all the
    possible values right。 And so is it the case for the other two machines。 So if
    that's the case if we have these parts partial sorted things right on each of
    the different machines。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后蓝色的机器就可以像它能够从所有可能的值中获取一样去执行。所以对于其他两台机器也是如此。如果是这种情况，假设我们在每台不同的机器上都有这些部分排序的内容。
- en: we need a way to merge them。 Yeah， so what if we use merge sort instead so that's
    kind of like what we'll be getting at。 Right， but first let's like make sure that
    we understand the problem if we just like you do round robin and then try sorting
    out sort things out that way right if we do that。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一种方法来合并它们。那么如果我们使用归并排序呢？这就是我们要探讨的方向。首先，我们需要确保我们理解问题，如果我们只是进行轮询，然后尝试通过那种方式来排序。如果我们这么做的话。
- en: Then we need another round of mergers right a potentially multiple rounds of
    mergers in order to get the full sort of result。 So one thing at a time right
    so let's try to go through like for example let's use histogram right as Charlie
    was mentioning。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要再进行一轮合并，实际上可能需要多轮合并，才能得到完整的排序结果。所以一项一项地进行，我们可以先试着用直方图，就像Charlie提到的那样。
- en: So what does that mean right so if we somehow have a this histogram of all the
    tools right and their corresponding camps or frequencies like the ones and that
    like the one that I'm showing here on the right hand side。 We can now divide up
    the x ranges or the domain right in this case， not evenly across the machines。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 那这意味着什么呢？如果我们 somehow 有一个所有工具的直方图以及它们对应的频率（像我在右边展示的那样），我们现在就可以把x轴的范围或域划分开，在这种情况下，并不是均匀地分配到各台机器上。
- en: We can divide them up based on the total number of tools that we're going to
    get right for each of these ranges。 and then assign them accordingly to the different
    machines such that each machine will end up having the same amount of things to
    sort。 Well how to choose， or should be fairly easy right because we already know
    if we know the frequency of each of the each of the two。 each of the two， each
    of the two values， then you know we just look at the distribution。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以根据我们将要获得的工具总数来划分这些范围，然后根据这些范围将其分配到不同的机器上，以确保每台机器最终拥有相同数量的内容进行排序。那么如何选择呢？其实应该比较容易，因为如果我们知道每个值的频率，那么我们只需要查看分布情况。
- en: and then we just make sure that like all the machines have the same number of
    two。 values to begin with。 This is easy to do if the number of tuples is small
    right name like for example we only have 10 tuples and it's easy to complete this
    histogram here。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们确保每台机器一开始都有相同数量的两个值。这在元组数量较少时容易做到，比如说我们只有10个元组，完成这个直方图就很简单。
- en: But it's not the case when the data is not that small right。 and that is actually
    typically the case right because the reason why we have parallel machines is because
    we have a lot of tuples that we need to process。 If we only have 10 tuples and
    I'm not just running on your local laptop right I mean that doesn't require any
    parallelism。 Or like you even if we run in parallel it's not going to be things
    up that much right。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但是当数据量不小的时候就不再是这种情况了。其实这也是通常的情况，因为我们使用并行机器的原因是我们有大量的元组需要处理。如果我们只有10个元组，而我只是运行在本地的笔记本电脑上，那么就不需要并行处理了。即使我们进行并行化，也不会加速很多。
- en: It's only the case if we have like you know a million and there'd be like a
    billion tuples。 and if that's the case， then constructing this like you know histogram
    right it's not going to be easy。 unless we have somehow been keeping track of
    the histogram on it like itself as data has。 originally ingested into the system。
    So one idea that you might have right instead of actually constructing this whole
    histogram maybe we can just sample it。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在我们有像千万级或者甚至亿级的元组时，这种情况才会发生。如果是这种情况，那么构建这样的直方图就不会容易，除非我们已经以某种方式在数据最初被导入系统时，便在跟踪该直方图。所以，你可能有一个想法：与其构建整个直方图，不如我们直接进行采样。
- en: Right so let's say we just like you know sample like randomly picked right basically
    from the input relation a few of the tuples or as many of the tuples that you
    would like and then construct the histogram based on the samples。 And then you
    know basically making this hypothesis that the sample histogram is going to reflect
    on what the overall histogram is going to look like。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，假设我们就像这样进行采样：从输入关系中随机挑选一些元组，或者你想挑选多少个元组，然后基于这些样本构建直方图。然后，你知道，我们基本上假设样本直方图会反映出整体直方图的样子。
- en: So if you believe in that hypothesis that we can use the histogram that is constructed
    from the samples and then use that to petition the tuples across the different
    machines and then go on with my business that way。 Now of course we have basically
    just when you're kicking the can down the road here right because in this case
    you might ask okay how can we do a sampling such that things are fair and things
    are even right because if we somehow has a bias in how we do the sampling。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你相信这个假设：我们可以利用从样本构建的直方图，然后用它来将元组分配到不同的机器上，然后继续进行我的工作。现在，当然我们基本上就是在把问题推迟到以后了，因为在这种情况下，你可能会问，好吧，我们怎么才能做到采样是公平的，事情是均匀的呢？因为如果我们在采样的过程中有偏差。
- en: then we might just end up creating a histogram that doesn't reflect all the
    tuples and therefore like you know the histogram that we created will be a skew。
    So this turns out to be a way way more tricky a problem than we can actually talk
    about in this class。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们可能最终会创建一个不能反映所有元组的直方图，因此你知道，我们创建的直方图将会是偏斜的。所以这实际上是一个比我们在这门课上能讲解的要复杂得多的问题。
- en: There's actually a lot of different statistical techniques that you can learn
    let's say in the statistics class they can take for doing different types of sampling
    to make sure that is actually unbiased。 And like you know happy to talk to you
    guys about that if you're interested about it offline。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，有很多不同的统计技术可以学习，比如在统计学课程中，你可以学习如何进行不同类型的采样，以确保采样是无偏的。如果你对这方面有兴趣，我也很乐意在课外和你们讨论。
- en: But the general idea here is if we do have an unbiased， if we do have an unbiased
    sample。 then we can basically construct histogram based on that unbiased。 sample
    and then use that to petition the tuples across different machines。 and therefore
    do sort it that way。 Does that make sense。 Okay。 Yeah。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这里的一般思路是，如果我们有一个无偏的样本，那么我们基本上可以基于这个无偏的样本构建直方图，然后用它来将元组分配到不同的机器上，因此可以按这种方式进行排序。明白了吗？好的，是的。
- en: so let's say like you know we did do you know based on either like creating
    a histogram on all the tuples or do the sampling based technique。 Now let's talk
    about like you know what can we do after we have received the tuples on each of
    them individual machines。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，假设我们做了基于创建所有元组的直方图或者基于采样技术的采样。现在，让我们谈谈在我们接收到每台机器上的元组后，我们可以做什么。
- en: One way we can do that right is to basically use our favorite sort merge join
    let's say we want to do a joint right。 So we know how to do sorting now。 So let's
    now talk about how we can use sorting to carry out joint which as we learned in
    the sort merge case。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做到的一种方式是基本上使用我们最喜欢的排序合并连接，假设我们想要做一个连接操作。那么我们现在已经知道如何做排序了。现在让我们讨论一下如何利用排序来执行连接，就像我们在排序合并的案例中学到的那样。
- en: that is indeed possible。 So it's actually turns out to be similar to what we
    talked about earlier。 except that again now we have this extra process of doing
    this petitioning。 and then sorting things out right。 Except that now we need to
    sort both of the relations just like when we were talking about sort merge join
    the beginning。 Right。 So remember the idea and sort merge joint is to basically
    have both of the both sets of tuples sorted such that we just we've been like
    you know the tuples one at a time from the two from the two relations that we
    need to join them on。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是可能的。所以实际上这变得和我们之前讨论的类似。只是现在我们又多了一个额外的过程，就是进行分区，然后正确地对其进行排序。只是现在我们需要对两个关系进行排序，就像我们在谈论排序合并连接（sort
    merge join）时所说的那样。对吧？所以记住，排序合并连接的核心思想是将两个元组集排序，使得我们可以从这两个关系中一次处理一个元组进行连接。
- en: And then we've performed the joint that way。 Right。 I hope you remember what
    a sort merge join is right。 Or I'm sure you will buy the final comes。 All right
    so yeah so like you know in this case we want to run things in parallel。 So if
    we can basically just petition the two folks across the different machines that
    we have。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们就用这种方式执行连接。对吧？希望你还记得什么是排序合并连接。或者我相信你最终会理解的。好吧，所以在这种情况下，我们希望并行执行操作。如果我们能够将两个数据集分发到不同的机器上就可以实现这一点。
- en: then the rest of the process is just the same thing as what we talked about
    earlier。 So again the sort， the sort merge the sorting might actually take multiple
    faces right because of the fact that like you know。 if we might need multiple
    rounds of sorting and also get everything sorted because all the tuples might
    not fit everything。 We might not be able to fit all the tuples in memory at once。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后其余的过程就和我们之前讨论的完全一样。所以再次强调，排序合并排序可能实际上需要多次迭代，因为我们可能需要多轮排序来确保一切排序完成，因为所有元组可能无法一次性全部放入内存。
- en: So we might go through multiple rounds。 The only thing that we're doing here
    is like you know we just need to process our and as individually at first。 and
    then do the merging part after that。 And again。 the merging part can be run completely
    independently across all the different machines。 So we kind of get perfect parallelism
    that way to accept that again first we have to first petition the tuples across
    the machines。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可能会经历多轮处理。我们在这里要做的唯一事情就是首先独立地处理每个元组，然后再做合并部分。而且，合并部分可以完全独立地在不同的机器上进行。因此，这样我们能够实现完美的并行处理，唯一的前提是我们首先需要将元组分发到不同的机器上。
- en: So that is again the blocking。 Does that make sense so now we have learned three
    different ways right to do parallel joint the naive way the grace has joined way
    and then also in this case the sort merge way right so except for the first one
    the second and the third one。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是我们所说的阻塞。这样讲明白了吗？现在我们已经学习了三种不同的方式来进行并行连接：朴素方式、哈希连接方式和排序合并方式。除了第一种方式，第二种和第三种方式都可以使用。
- en: is that we have already learned about earlier when we were talking about our
    core algorithms。 The only difference here is like you know how do we decide on
    petitioning in the very beginning where we need to。 when we need to petition or
    shuffle the tuples across the， machines。 So actually see even more joint outcomes
    later on right because as I said earlier joints is one of these problems and they
    are processing that just keeps coming back over and over again。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们之前在讨论核心算法时已经学到的内容。唯一的区别是，我们如何在一开始决定是否需要进行分区，或者何时需要将元组跨机器进行分发。所以实际上，之后你会看到更多的连接结果，正如我之前所说，连接是其中一个反复出现的问题，需要不断处理。
- en: So it's one of these like you know core problems and data career processing
    that everyone is still working on even today。 So you still hear people talking
    about new joint outcomes precisely because of this reason。 And basically that
    also means that like you know no one size at all right so it's not like someone
    one single magic joint out that works all the way。 And it's always going to be
    the best。 That's why we're talking about all these different options here。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是数据处理中的核心问题之一，至今仍然是大家在不断研究的领域。所以你现在依然会听到人们讨论新的连接结果，正是因为这个原因。这也意味着没有一种通用的解决方案，不是说某个单一的连接方法就能一直表现最好。因此，我们才会讨论所有这些不同的选项。
- en: Okay so let's leave join for a few minutes we'll get back to that actually。
    In a few slides still so you still hear more more like you know different joint
    outcomes。 But for now let's also talk about how we want to run aggregates in parallel。
    Aggregates I mean things like you know computing counts and sums and all the good
    stuff that we already learned。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，先暂停一下连接，过一会儿我们会回到这个话题。接下来的几张幻灯片中你还会听到更多关于不同连接结果的内容。但现在，我们也来讨论一下如何在并行中运行聚合操作。所谓聚合，就是像计算计数、求和等我们已经学过的那些操作。
- en: Right。 So the approach here is going to do this in a hierarchical manner。 So
    we're going to do this in a hierarchy for each of the aggregate function we basically
    decompose the operation into a local。 it's a local aggregate， and a global， solution。
    What do I mean。 For instance if we want to compute some across like a million
    tuples that's same。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对。所以这里的方法将采用分层的方式来进行。我们会为每个聚合函数分层执行操作，将操作分解为局部聚合和全局聚合两部分。是什么意思呢？举个例子，如果我们要计算一百万个元组的和，这就很适用。
- en: I can decompose the sum by first shuffling or partitioning the tuples across
    different machines and compute the local sum。 And subsequently I'm going to compute
    the global sum by asking each of the individual machines to send us。 you know
    the sum that they have got so far。 So this sounds intuitive right so we have a
    bunch of different machines we just asked each individual machines to compute
    the local sums after we decided on how to partition the data across them。 And
    then after they have completed the local sums we just add the local sums together
    and then we get the global one。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以通过首先对元组进行洗牌或分区，分发到不同的机器上，然后计算局部和。接着，我会计算全局和，方法是要求每个机器把它们已经计算的和发送给我们。这个听起来很直观吧？我们有很多不同的机器，只需要让每台机器计算它们各自的局部和，在决定如何将数据分配到各台机器后。然后，在每台机器完成局部和计算后，我们只需把局部和加起来，就能得到全局和。
- en: Okay。 Counting is pretty much the same thing right so we asked each of the individual
    machines to count their set of tuples that's the lowercase here lowercase s。 And
    then we're just going to add up all the local counts afterwards and then that's
    the global count number that we want。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，计数其实是一样的操作，我们只需要让每台机器计算它们自己那一组元组的计数值，这里是小写的s。然后我们会把所有机器的局部计数加起来，最后得到的就是我们需要的全局计数。
- en: So you can basically see a pattern here right so that's exactly what I meant
    by decomposing the operation into global and a local version。 So for average right
    so we're just going to compute the sum and also compute the count and then the
    global average is going just going to be the global sum divided by the global
    count。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你基本上可以看到一个模式，这就是我所说的将操作分解为局部和全局两个版本的意思。比如在计算平均值时，我们首先计算总和和计数，然后全局平均值就等于全局总和除以全局计数。
- en: So on so far if you can figure out how we want to run。 let's say maximum or
    minimum in a similar fashion right。 So this is just a pictorial illustration of
    how we want to do some for example。 So that's how we can do some in a parallel
    way so again right module the part that we need to partition the data across the
    different machines。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，如果你能弄清楚我们如何运行操作，譬如说最大值或者最小值，类似的方式对吧？这张图只是一个示意，展示我们如何进行一些操作。例如，这就是我们如何以并行的方式进行求和。所以，再一次强调，我们需要对数据进行分区，使其能够分布到不同的机器上。
- en: The rest of it is basically a completely independent right each of the machines
    can just run the aggregates locally independently。 And then we just collect the
    number after that and then compute the global version。 What about group by。 So
    grouping and grouping and aggregation all kind of like you know comes hand in
    hand right as we learn in pre-processing。 So how do you want to compute group
    by of a large number of tuples。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的部分基本上是完全独立的，每台机器可以在本地独立运行聚合操作。之后我们将收集这些结果，然后计算全局结果。那么，关于分组呢？分组和聚合通常是一起进行的，就像我们在预处理阶段学到的一样。那么如何处理大量元组的分组计算呢？
- en: One version is like similar in vain right so we do local aggregation。 So you
    know we keep track of the group key that is being computed and then we keep local
    aggregates in the hash table based on the partition of data that we have。 And
    then similarly after each of the local group by having computed on each of the
    individual machines。 then we just do a shuffling step where we forward the local
    aggregated results to a single machine that is supposed to be。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个版本类似于空洞的方式，我们进行本地聚合。你知道，我们会追踪正在计算的组键，然后根据我们拥有的数据分区，在哈希表中保留本地聚合结果。接着，在每台机器上计算完本地的分组之后，我们就进行一次洗牌步骤，将本地聚合结果转发给一台应该接收的单一机器。
- en: So for instance maybe the blue machine in this case is responsible for all the
    groups like you know from negative infinity to 10。 And then the green machine
    is responsible for all the groups from 11 to like 100 or something right。 So and
    then and so on and so forth for the orange one。 So in that case we just asked
    the local machine to first compute the local group by regardless of what they're
    supposed to be computing ultimately。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设在这种情况下，蓝色机器负责所有从负无穷到 10 的组，绿色机器负责从 11 到 100 之间的所有组，依此类推，橙色机器也负责相应的组。在这种情况下，我们首先要求本地机器计算本地的分组，无论它们最终应该计算的内容是什么。
- en: And then just shuffle the partially computed result across the machines based
    on the range that they're supposed to compute。 So therefore the blue machine at
    the top will get all the groups corresponding to like negative infinity to 10
    from the green machine and the orange machine after the first step。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们只是根据它们应该计算的范围，在机器之间洗牌部分计算的结果。因此，最上面的蓝色机器会收到所有对应于负无穷到 10 的组，这些组来自绿色机器和橙色机器，经过第一步之后。
- en: And then it would just compute the final aggregate for that for that particular
    group after receiving the local accounts。 Any question about this so far。 Oh，
    right， so that's like you know I leave it as a challenge right to figure out like
    you know what happens if we have so large number of groups such that it doesn't
    fit in memory on the individual machine。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它会在接收到本地计算结果后，为该特定组计算最终聚合结果。到目前为止有任何问题吗？哦，对了，这是一个挑战，弄清楚如果我们有如此多的组，以至于它们无法在单一机器的内存中存放，会发生什么。
- en: You can do something similar to grace hash space hash join right and now and
    actually trying to figure that out。 And not to solve that particular problem and
    you should be able to do that exercise。 but I will tell you how time that that
    is relatively rare in practice。 Because it's usually the case that we have millions
    of two posts。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做类似于 Grace 哈希空间哈希连接的操作，实际上你可以尝试弄清楚该怎么做。而且不是为了直接解决这个特定问题，你应该能够完成这个练习。但我会告诉你，这种情况在实际中是相对罕见的。因为通常情况下，我们有数百万个二元组。
- en: but it's unlikely the case that we have millions of groups。 Right。 because we're
    unless you're grouping on like a unique identifier like student ID right。 but
    if you're grouping on student ID then I think the first question that you want
    to answer that case is why you writing that query。 I mean why are you grouping
    by something that you know that's not form any group right besides a single tool。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们不太可能有数百万个组。对吧？因为除非你在像学生ID这样的唯一标识符上进行分组。如果你在学生ID上进行分组，我想你首先要回答的问题是，为什么要写这个查询？我的意思是，为什么你要按某个你知道不会形成任何组的内容进行分组，除了一个单独的工具。
- en: Okay， so that you know but then other than that right if you really get into
    that that regime right of having so many different groups that they don't fit
    into a single machine then like you know we can。 you can think about how you want
    to use something similar to the grace john has drawn out with them for solving
    that problem。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，你知道了，但除此之外，如果你真的进入那种情况，即拥有如此多不同的组，以至于它们无法适配到单一机器上，那么你知道，我们可以。你可以考虑如何使用类似
    Grace 哈希连接的方式来解决这个问题。
- en: So what we have learned so far right it's basically how to run these most many
    of these different relational operators in parallel。 and the focus has been on
    joins because that is the one that we know like you know a different number of
    algorithms exist。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止我们学到的基本上是如何并行运行这些不同的关系操作符。重点放在连接操作上，因为我们知道有不同的算法可以实现。
- en: So that's， that's now try to round up the picture by talking about like you
    know different types of joint algorithms。 besides the one that they're talking
    about so far。 which is one the naive version to the grace hash john version。 and
    then three the smart merge version right。 Okay。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就让我们通过讨论不同类型的连接算法来总结这个图景。除了他们目前讨论的那些算法，分别是：一是朴素版本，二是Grace哈希连接版本，三是智能合并版本，对吧？好的。
- en: so now that we also learn about sorting and all the other different ways so
    now let's see if there are other ways that we can also run the parallel joins
    as well。 So the first one is what sometimes you will call one side of shuffle。
    So that is a special case where if we know that one of the relations is already
    petitioned。 Then we don't have to petition that relation again。 Right。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们也学习了排序和其他不同的方法，那么让我们看看是否还有其他方法可以运行并行连接操作。第一个是有时你会称之为“单边洗牌”。这是一个特殊情况，如果我们知道其中一个关系已经被分区，那么我们就不需要再次对该关系进行分区了，对吧？
- en: So let's say if we already know that our is range petition across the three
    different machines。 So we need to shuffle right the other relation that needs
    to be petition。 If it is not already also petition。 And then we can just run those
    join locally right。 so you might say well this is kind of like a cheating case
    right why will you have such a situation happening。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经知道我们的关系跨越了三台不同的机器。那么我们需要进行数据洗牌，即对其他需要分区的关系进行洗牌。如果它还没有被分区的话。然后我们可以在本地运行这些连接操作。所以你可能会说，这有点像作弊的情况，对吧？为什么会发生这种情况呢？
- en: But remember I mean these are queer operators， these queer operators run in
    a tree right。 So。 you know it might be the case that we have already done， like
    sorting on it。 So therefore like one of the relation might have already been sorted。
    So if that's the case then why not just piggyback on that。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 但请记住，这些是“奇异”操作符，这些奇异操作符在树形结构中运行。所以，你知道，可能的情况是我们已经对其进行了排序。因此，某个关系可能已经排序好了。如果是这种情况，那为什么不直接利用这一点呢？
- en: And then like you know only need to shuffle one of the other。 the other relation
    and also run the joint， as opposed to needing needing to shuffle both。 Okay。 So
    sometimes you do get a situation like that and then if that's the case then you
    can just do we can just do it one side of shuffle。 which is what this slide is
    talking about。 Another case that you might encounter is like you're in a case
    where one of the relation is really small compared to the other one。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你只需要对另一个关系进行洗牌，并运行连接操作，而不需要同时对两个关系进行洗牌。好吧，有时候确实会出现这种情况，如果是这样的话，我们就可以做单边洗牌。这个幻灯片正在讨论的就是这个情况。你可能遇到的另一个情况是，当其中一个关系与另一个关系相比非常小。
- en: So let's say if like you are so small such that it can actually just fit in
    the main memory of an individual machine。 What can we do in that case。 Well if
    we what we can do in that case is we can simply just like you'll send the entire
    relation of our to the different machines。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 假设如果你非常小，以至于它实际上可以完全适应单台机器的主内存。那么在这种情况下我们能做什么呢？嗯，如果是这样的话，我们可以简单地将整个关系传送到不同的机器上。
- en: So forget about sorting forget about like running hash functions to try to figure
    out how to petition things。 We just sent the entire copy of our to all the machines
    and then ask them to run their favorite local joint algorithm out。 Why is this
    beneficial because we saved the time right so actually figure out what how to
    do petitioning whether we want to construct histogram and all that stuff basically
    goes away。 We simply just replicate the entire relation across the multiple different
    machines that we have。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 忘记排序吧，忘记运行哈希函数来试图弄清楚如何进行分区。我们只是将整个关系复制到所有机器上，然后让它们运行各自喜爱的本地连接算法。为什么这样做有好处呢？因为我们节省了时间，实际上不需要去琢磨如何进行分区，是否要构建直方图之类的东西，这些基本都不再需要。我们只需将整个关系复制到多个机器上。
- en: So this actually happened more frequent than you think。 Big just because like
    you know there's no guarantee that when we join something there's no guarantee
    that the two relations are equal size right or even off relatively equal size。
    I mean one can be really small compared to the other one。 And if we actually run
    into that case。 And if it is actually also the case that it will fit into the
    main memory of these of the individual machines。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这种情况发生的频率比你想象的要高。主要是因为，当我们连接两个关系时，并不能保证这两个关系的大小相等，甚至相对相等。一个关系可能比另一个关系小得多。如果我们遇到这种情况，并且如果它恰好也能适配这些独立机器的主内存。
- en: Why not just do this broadcast join mechanism as opposed to figuring out how
    to shuffle data。 And then finally let's also talk about like you know I've been
    telling you guys about there's some joint there are joints where we basically
    need to wait right for one of the steps to complete。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不直接使用这种广播连接机制，而不是解决如何洗牌数据的问题。最后，让我们再谈谈你们知道的，有些连接操作是我们基本上需要等待的，直到某个步骤完成。
- en: And that is usually like one of the first steps right either that means the
    petitioning case or the sort merge join case is basically the sort right to be
    completed before we can actually do the merge。 And then in the case of the hash
    building when we were talking about grace has joined we have to wait for the hash
    table to be first built on one of the relations before we can shuffle the other
    one。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通常这是最初的步骤之一，要么意味着分区情况，要么意味着排序合并连接的情况，基本上是排序必须完成后，我们才能实际进行合并。而在哈希构建的情况下，当我们谈论到优雅哈希连接时，我们必须等待哈希表在其中一个关系上首先构建完成，才能对另一个进行洗牌。
- en: So I call them pipeline breakers in this case because those are exactly the
    places where we need to wait。 We cannot proceed with the rest of the joint until
    that pass until that pass is done。 Whether that means starting or that that means
    a compute of creating the hash table and memory。 Is there a joint scheme that
    actually pipelines entirely。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种情况下我称它们为管道中断点，因为它们正是我们需要等待的地方。在完成那个阶段之前，我们不能继续执行其余的连接操作。无论这意味着开始，还是意味着创建哈希表并存储在内存中。是否存在一种连接方案可以完全实现流水线处理？
- en: we need that we don't have to wait for the first pass to actually finish before
    we can carry out join。 As I have alluded to earlier there's something called symmetric
    pipeline hash join which basically prevents us from needing to wait。 The way that
    it works is we basically going to construct two hash tables in each of the individual
    machines。 One hash table for our and one other hash table for us which is the
    relation that we want to join on。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要这样做是因为我们不需要等到第一次通过结束后再进行连接。正如我之前提到的，有一种叫做对称管道哈希连接的技术，基本上它避免了我们需要等待的情况。它的工作方式是，我们基本上会在每台独立的机器上构建两个哈希表。一个哈希表用于我们自己，另一个哈希表用于我们要连接的关系。
- en: Why， because now when a tool from our shows up， we're basically going to build
    a hash table just like what we would have been doing。 Okay， but then when， and
    then when a tool from s actually shows up。 we're actually going to just probe
    the hash table that we have constructed for our just like when we were doing has
    joined。 The only difference is we also need to compute a hash table for us。 Why。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么呢，因为现在当一个工具从我们的端口到来时，我们基本上会像我们之前做的那样构建哈希表。好的，但当一个工具从s端口到来时，我们实际上会查询我们已经构建好的哈希表，就像我们进行哈希连接时一样。唯一的不同是，我们还需要为我们自己构建一个哈希表。为什么呢？
- en: because next time we receive a tool from our， we are going to not only construct，
    you know。 put that particular tool into the hash table for our。 but we are also
    going to probe the hash table for us to figure out if there's any match。 So here's
    the animation that correspond to that。 So when a hash went， sorry。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因为下次我们从我们的端口接收到一个工具时，我们不仅要构建哈希表并将该工具放入其中，还需要查询另一个哈希表，看看是否存在匹配项。这里是与此对应的动画。所以，当哈希表出现时，抱歉。
- en: when a tool from our shows up， we're going to put that to go into the our hash
    table hash table。 and then check whether there's any match in the as hash table。
    And if so。 I'll put the join to goals as desired。 And then similarly， when a tool
    from s shows up。 we're just going to do the same thing in reverse。 So notice there's
    some trade off here right so instead of creating one single hash table for our。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的（our）数据出现时，我们会把它放入我们的哈希表中，然后检查是否在我们的（us）哈希表中有匹配项。如果有，我会进行所需的连接。类似地，当我们的（us）数据出现时，我们会反向操作，进行同样的操作。所以注意，这里有一个权衡——所以不是为我们的（our）数据创建一个单一的哈希表。
- en: Now we are going to create two different hash tables one for our and one for
    us。 both of them are supposed to reside in memory。 The first question that you
    might ask is why does this even work work in a sense of computing the right results。
    And you can see why this actually works because all the output to post that needs
    to be that needs to be generated is only generated exactly once。 which is when
    it's corresponding part of rights right。 So if lowercase。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建两个不同的哈希表，一个是为我们的（our）哈希表，另一个是为我们（us）哈希表。它们都应该驻留在内存中。你可能会问的第一个问题是，为什么这个方法在计算正确结果时有效？你可以看到为什么这个方法确实有效，因为所有需要生成的输出只会生成一次。那就是当它对应的部分已经生成时。所以下面如果是小写字母。
- en: so if to a supposed to join to be， then depends on whether a shows up first
    or B shows up first。 The second to go that shows up is going to basically join
    with the other one because the other one is already put into his corresponding
    hash table。 Does that make sense。 Right， so if it hasn't shown up yet it's just
    because like you know the part that is supposed to join with just hasn't hasn't
    been streamed into memory。 So that's the only reason why this algorithm is come
    entirely streaming meaning that like we're not waiting for any phase to be completed
    across different machines。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果要进行连接，则取决于 A 是否先出现或者 B 是否先出现。第二个出现的将与另一个连接，因为另一个已经放入了它对应的哈希表中。这样说有道理吗？对，所以如果它还没有出现，那只是因为你知道，应该与之连接的部分还没有被流入内存。这就是为什么这个算法完全是流式处理的原因——意味着我们不需要等待不同机器上任何阶段完成。
- en: You know， we can always just pull all these different different tools from RNS。
    bring out how to petition it across different machines and then like you know
    go on separately completely independently from each other。 So this particular
    scheme is useful for what is known as stream career processing engines， namely。
    we're not talking about a finite sized relation。 So let's say I want to join like
    you know to post I'm seeing from Twitter or something。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道，我们可以随时从 RNS 拉取这些不同的工具，带着它们如何在不同机器间划分，然后你知道，彼此独立地进行工作。所以这个特定的方案对于所谓的流处理引擎非常有用，即我们不在谈论一个有限大小的关系。所以，假设我想连接像你知道从
    Twitter 等看到的帖子。
- en: So we're basically getting new to post every second as we speak。 So we're really
    talking about an unbounded relation here。 So if that's the case。 we can afford
    to run any of the algorithms from before where we're basically waiting for like
    you know the entire hash table to be constructed for our。 for example， because
    in the case of like an infinite relation。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们基本上每秒都会得到新的数据。因此，我们实际上是在谈论一个无限的关系。如果是这种情况，我们可以承受运行之前的任何算法，在这些算法中，我们基本上是在等待你知道，整个哈希表构建完成。例如，对于我们的（our）哈希表，因为在无限关系的情况下，
- en: That the hash table is never going to be completely built right。 So the only
    hope that we have this is basically run these so called streaming based algorithm
    where we don't need to wait for a particular phase of the algorithm to finish
    before we can go on with the rest of the job。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表永远不会完全构建完成。所以我们唯一的希望是运行这些所谓的流式算法，在这些算法中，我们不需要等待某个特定阶段完成才能继续进行剩下的工作。
- en: And this is one example of this。 So again you can see the。 the trade out here
    right we are basically spending extra memory to construct two hash tables in memory。
    not just one。 So now we have even a higher chance that like you're the hash table
    will not fit in memory。 So therefore we need to， like you know， write out the
    individual buckets just like how we're doing the grace algorithm and then like
    you bring back the corresponding bucket when the to go after that。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是其中一个例子。所以你再次可以看到这里的权衡，对吧，我们基本上是在内存中构造两个哈希表，而不是一个。因此我们有更高的可能性，哈希表将无法装入内存。因此我们需要像你知道的那样，写出单独的桶，就像我们在进行Grace算法时一样，然后当处理完成后，再将对应的桶带回来。
- en: arrives， and all the other nice things that we might need to worry about。 Again。
    no such thing as free life right there's always going to be a trade off here。
    The upside here is we don't need to worry about like you know。 we don't need to
    wait for a face to finish so all the individual machines can process can make
    process can make progress completely independently from each other。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 到达，和我们可能需要担心的所有其他好事情。同样的，没有免费的午餐，对吧，总是会有权衡。在这里的好处是，我们不需要担心像你知道的那样。我们不需要等待一个阶段完成，以便所有的单独机器可以完全独立地进行处理和进度。
- en: The downside is that we need more memory here。 So yeah so that's all we want
    to say for parallel pre processing。 So across these two lectures we're talking
    we talked about topics like you know how to petition the two posts across mother
    machines。 we talked about different architectures that you might have for running，
    the low pre processing。 And in this class we focus exclusively on the share nothing
    approach because it's cheap is scarce well。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点是我们需要更多的内存。因此，是的，这就是我们想要说的关于并行预处理的所有内容。所以在这两节课中，我们讨论了像如何在母机之间划分两个帖子的话题。我们讨论了运行低级预处理时可能采用的不同架构。在这门课中，我们专注于“无共享”方法，因为它既便宜又稀缺。
- en: we basically just adding commodity hardware。 In that case right。 And then we
    talk about different types of parallelism across operators across different queries
    so on so forth。 And then we talk about how to implement our relational operators
    in parallel using the basic moving blocks that were discussed last time or hashing。
    and then for this time or sorting sorting。 And then you can imagine how we want
    to do a parallel pre processing by constructing a similar pre processing plan。
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们基本上只是添加了商品硬件。那样的情况下，对吧。然后我们讨论了不同类型的并行性，包括操作符之间、不同查询之间的并行性，等等。接着我们讨论了如何利用上次讨论的基本构建块（例如哈希）在并行中实现关系运算符。然后这次是排序。接着你可以想象我们如何通过构建类似的预处理计划来进行并行预处理。
- en: just like how we talked about earlier。 So like you know how you might want to
    think about doing career optimization that way。 So it's basically I can already
    tell you that it's a similar process so we basically do a cost based estimation
    to figure out what is the cost for each of the different career plans that we
    have and then we just choose the best one。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前讨论的那样。所以你知道，你可能会考虑如何通过那样的方式进行职业优化。所以基本上我可以告诉你，这是一个类似的过程，我们基本上会做一个基于成本的估算，找出不同的职业计划的成本，然后选择最优的一个。
- en: just like how we were talking about earlier， or career optimization。 So here
    comes another fun part right， what about transactions。 which is also what we talked
    about in this class right now that we know how to run the queries in parallel
    across different machines。 how about running transactions in parallel across different
    databases。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前讨论过的，或者说是职业优化。那么这里有一个有趣的部分，对吧，事务呢？这也是我们现在在这门课中讨论的内容。现在我们知道如何在不同机器之间并行执行查询，那么如何在不同数据库之间并行执行事务呢？
- en: So we need distributed blocks somehow right we were talking about to be out。
    So like you know does that mean we started to get lots across the model machines
    before we can run a transaction。 How do we do a bad luck。 Now when we have multiple
    machines involved。 And I can already tell you that we need new protocols because
    what we learned earlier in terms of two PL and all the different ways of doing
    transactions is not going to be directly applicable in a case where we have parallel
    machines。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们以某种方式需要分布式块，对吧？我们之前提到过。那这是否意味着我们开始在模型机器之间获取大量数据，然后才能执行事务？我们该如何处理运气不好？现在当有多台机器参与时。并且我可以告诉你，我们需要新的协议，因为我们之前学到的关于两阶段锁定（2PL）以及其他不同方式执行事务的知识，在我们有并行机器的情况下无法直接应用。
- en: And in fact that is what we'll be talking about right after the break。 But before
    we take a break。 Are there any questions about this part of the lecture。 If not
    maybe we can just switch over to the break at it here。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这就是我们在休息后要讨论的内容。但是在休息之前，关于这部分讲座有什么问题吗？如果没有，或许我们可以直接进入休息时间。
- en: '![](img/36def6d6b9866c9c33a169a2bce65f2c_5.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36def6d6b9866c9c33a169a2bce65f2c_5.png)'
- en: I'll share screen。 Yeah。 Okay， so if you are this is for those who missed the
    video。 If you'd like to see the video， please come to class。 We miss you。 There's
    just like 40 students in class and we have to。 we just have five people whose
    faces we can see。 So please come to class。 We miss you。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我来共享屏幕。好的，这个是给错过视频的人看的。如果你们想看视频，请来上课。我们想念你们。教室里只有40个学生，我们只能看到五个人的面孔。所以请来上课，我们想念你们。
- en: We'd love to see you。 Okay， anyway。 And of course you're missing out on all
    the videos。 So。 so that's。 So， Tegan asks whether it is 1115。 You may be right。
    I think I haven't updated this slide。 So， can it defeat the purpose of this admin
    announcement but there is an exam prep session coming that's either on 1113 or
    1115。 because I think I brought 1113 originally and then I was corrected later
    so Gabe has the updated info。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很乐意见到你们。好的，不管怎样，你们错过了所有的视频。所以，Tegan问是否是1115。你可能是对的。我想我还没有更新这个幻灯片。所以，这可能会削弱这个管理通知的目的，但确实有一个考试准备会，即将在1113或1115举行。因为我原来定的是1113，后来我被纠正了，所以Gabe有最新的信息。
- en: Okay， so 1115 it is。 And so the other thing that I wanted to announce was the
    fact that we've started doing verbal exams for those who had issues with the recordings
    from mid to。 And again， this is just for fairness sake， right， so you want to
    make sure that no one is sort of those who took the exam and had no issues。
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，1115就是这样。那么我还想宣布的另一件事是，我们已经开始为那些在中期考试中有录音问题的同学进行口头考试了。而且，这完全是为了公平起见，对吧？这样做是为了确保那些参加了考试且没有问题的同学不会受到影响。
- en: They are not at the disadvantage。 Those who had issues with the recording。 There
    were no recordings at all。 For example， they are not at the disadvantage either。
    I mean。 they just come in。 We are not， we're not like， we're not giving them a
    hard time。 Right。 you just are asked to explain a few answers and basically that's
    it。 So。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 他们并不处于劣势。那些有录音问题的人，根本就没有录音。例如，他们也不处于劣势。我是说，他们只要进来就行。我们不会，咱们不会，咱们不是要为难他们。对吧？你只需要解释几个答案，基本上就是这些。就这样。
- en: they're not meant to be stressful。 It's just a simple check so that we can be
    sure that you did the exam diligently and that's about it。 And I think Alvin conducted
    some verbal exams today。 There are still others that are scheduled。 So。 anything
    to add to that， Alvin？ No， yeah。 Okay。 Okay。 So the midterms are graded。 There'll
    be out soon again。 We are waiting for these verbal exams to get done before we
    can release the midterm grades。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些口头考试并不是为了让你们感到有压力。它只是一个简单的检查，目的是确保你们认真参加了考试，差不多就是这样。我知道Alvin今天进行了几场口头考试，还有一些已经安排好的。所以，Alvin，有什么要补充的吗？没有，对吧？好的。好的。那么期中考试已经评分了，成绩很快就会公布。我们正在等待这些口头考试结束，然后才能发布期中成绩。
- en: And please get started on project five。 I know some of you are still dealing
    with the project for。 but hopefully you are done with that or close to done with
    that and you're。 you're starting to work on project five。 So， and it that any
    issues。 Sort of let us know and make use of office hours。 I'm lonely in my office
    are so you should show up。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请开始做第五个项目。我知道你们中的一些人还在处理第四个项目，但希望你们已经完成了，或者快完成了，并且开始着手做第五个项目。所以，如果有任何问题，请告诉我们，并充分利用办公时间。我在办公室很孤单，你们应该来。
- en: Okay。 All right。 Any other announcements， Alvin， no， right。 Okay。 let me move
    on to distributed transactions。
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。好吧，其他通知还有吗，Alvin，没有吧？好的，那我继续讲分布式事务。
- en: '![](img/36def6d6b9866c9c33a169a2bce65f2c_7.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36def6d6b9866c9c33a169a2bce65f2c_7.png)'
- en: Okay， so I'm in alluded to this already right so we talked about sort of taking
    sort of traditional relational data processing operators and and sort of figuring
    out how to do it in parallel。 Now， that's just very processing。 What happens from
    the transaction perspective。
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，既然我已经提到过了，我们谈论的是如何将传统的关系数据处理操作符进行并行处理。现在，这只是处理过程。从事务的角度来看会发生什么呢？
- en: If you have data that spread across many machines， how do you deal with transactions？
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据分布在多台机器上，怎么处理事务呢？
- en: How do you guarantee acid in that context is a challenge。 And that's。 that's
    what we're going to be dealing with。 So first， a note on sort of terminology。
    So。 notice that the previous lecture talked about parallel query processing this
    lecture or this set of slides are talking about distributed query processing what's
    really the difference。 And so， I mean， at least from a parallel database standpoint，
    we talked about three。
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在这种情况下保证ACID是一个挑战。这就是我们将要处理的问题。所以首先，关于术语的说明。请注意，上一讲讲了并行查询处理，而这一讲或这一组幻灯片讨论的是分布式查询处理，实际上有什么不同吗？至少从并行数据库的角度来看，我们讨论了三种。
- en: three sort of mechanisms shared memory shared disk and shared nothing distributed。
    So。 we're saying a distributed databases basically nothing but share nothing parallel
    databases。 But in many cases， this is also has a slower network。 Okay。 so the
    distinction between parallel and distributed is not substantial。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 三种机制：共享内存、共享磁盘和无共享分布式。我们说，分布式数据库基本上不过是无共享并行数据库。但在许多情况下，这也意味着网络较慢。好吧，所以并行和分布式之间的区别并不显著。
- en: It's just that distributed is usually has a slower network。 And so this distributed
    could really mean geographically distributed right could be across multiple continents
    even。 Okay。 And that does has that does have repercussions for the kinds of ways
    we'll need to handle transactions。 Right。 So if things are spread across two ends
    of a continent right West Coast East Coast or USA and China。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 只是分布式通常有较慢的网络。所以这个分布式实际上可能意味着地理上的分布，可能甚至跨越多个大陆。好吧，这确实会对我们需要处理事务的方式产生影响。所以，如果东西分布在一个大陆的两端，比如西海岸和东海岸，或者美国和中国。
- en: right。 I mean， network delays could be a huge factor。 So it's important to sort
    of think about the worst case scenario of stuff being truly distributed。 So what's
    special about distributed computing。 So inherited from shed nothing parallel computation
    that we already know you have parallel computation。 as well as no reliance on
    shared memory or this we basically have these commodity machines， which。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对吧，我的意思是，网络延迟可能是一个巨大的因素。所以考虑到分布式计算的最坏情况是很重要的。那么分布式计算有什么特别之处呢？它继承了我们已经知道的无共享并行计算，你有并行计算，以及不依赖共享内存，基本上我们有这些商品化的机器。
- en: have their own memory and disk and they communicate via shared a network， right。
    So the network is what is shared across all of these machines and these machines
    come communicate via that network。 And so the networks， especially in a distributed
    setting stuff where stuff is really far away from each other these networks could
    be really unreliable。 So you could have delays。 So packets take a long time to
    get transmitted。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 它们有自己的内存和磁盘，并通过共享网络进行通信，对吧。所以网络是所有这些机器共享的东西，这些机器通过该网络进行通信。因此，网络，尤其是在分布式环境下，设备彼此相距甚远，这些网络可能非常不可靠。所以你可能会遇到延迟。数据包传输需要很长时间。
- en: And then there's a lot of different ways to get into the network。 So you could
    have a lot of different ways to get into the network。 And then you could have
    a lot of different ways to get into the network。 And then you could have different
    ways to get into the network。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后有很多不同的方式进入网络。所以你可以有很多不同的方式进入网络。然后你可以有很多不同的方式进入网络。然后你可以有不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。然后你可以有不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 And then you could have different ways to get into
    the network。
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。
- en: And then you could have different ways to get into the network。 And then you
    could have different ways to get into the network。 And then you could have different
    ways to get into the network。 So we're going to be focusing on transactional concurrency
    control and recovery as algorithm alluded to the last set of slides and many of。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 然后你可以通过不同的方式进入网络。 所以我们将重点关注事务并发控制和恢复，正如算法在上一个幻灯片中提到的那样，还有很多内容。
- en: And so you'll end up figuring out many of the lessons of distribution。 Sorry。
    you do already know many of the lessons of distributed processing。 You'll now
    know the lessons of distributed transaction process。 Okay。 let's start with distributed
    locking。 Okay。 So， as before we are talking about shared nothing distributed database
    system。
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你最终会弄明白很多关于分布式的课程。 对不起，你已经知道了很多分布式处理的课程。 现在你将会知道分布式事务处理的课程。 好的，我们从分布式锁开始。
    好的，像之前一样，我们讨论的是共享无分布式数据库系统。
- en: And for today we're going to be assuming partitioning but no replication so
    I've been alluded to this where he said that in order to make sort of queries
    run faster you could potentially make multiple copies of your data。 That's not
    something we're going to be worrying about so we're only going to be worrying
    about partitioning again something that Alvin and I spoke about in the battle
    computing part。
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们将假设是分区而没有复制，我之前提到过这点，他说为了让查询运行更快，你可能会复制数据的多个副本。但这不是我们要担心的问题，所以我们只会关心分区，这是我和Alvin在并行计算部分谈到的。
- en: So each transaction you can imagine arrives at some node and this node may be
    designated as the coordinator for that transaction is responsible for coordinating
    the transaction and then communicating back to。 let's say the application server
    saying， Hey， this transaction committed this transaction about it was heavy。
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所以每个事务你可以想象它会到达某个节点，而这个节点可能被指定为该事务的协调员，负责协调事务并将结果反馈给。例如，反馈给应用服务器，说：“嘿，这个事务已经提交，这个事务出了问题。”
- en: Okay， so this coordinator can be designated so there could be a centralized
    coordinator for all transactions or could be assigned on the fly based on some
    scheme like around around。 drop it for example。 Okay。 So one question is where
    is if you want to do distributed concurrency control where does a lock table recite。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以这个协调员可以被指定，因此可以为所有事务指定一个集中式协调员，或者可以根据某些方案动态分配，比如“环绕分配”。比如丢弃它。好的。那么问题是，如果你想进行分布式并发控制，锁表应该放在哪里？
- en: And so usually the locks are partitioned along with the data so you keep the
    locks along with the data。 And so basically each node ends up managing its own
    lock table and contains entries for all of its pertinent objects so basically
    stuff like pages and tuples would have their lock table entries associated with
    that node。
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，锁是与数据一起分区的，所以你将锁与数据保留在一起。因此，基本上每个节点都会管理自己的锁表，并包含所有相关对象的条目，基本上像页面和元组这样的东西会有与该节点相关的锁表条目。
- en: Now， what happens with sort of course trained objects right so in those cases
    so let's say tables relations or entire databases。 So usually you end up assigning
    a home node for those objects。 And。 and those home nodes would contain the course
    train locks。 So the object being locked so it's either table or a database。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，关于那些训练过的对象会发生什么情况呢？在这种情况下，假设是表、关系或整个数据库。那么通常你最终会为这些对象分配一个主节点。而且，这些主节点将包含训练锁。因此，被锁定的对象，无论是表还是数据库。
- en: This may exist across nodes but there is a home node for them。 So for example。
    individual tuples of boats reserves and sailors and individual pages that are
    could reside in different。 different nodes， and could have lock table entries
    for each state。 Two or each page in those nodes。 but where do we have the course
    trained。 Lock table entries for the relations themselves。
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能存在于不同的节点之间，但它们有一个主节点。例如，单独的元组（比如船只、预定和水手）以及可以驻留在不同节点中的页面，它们可能为每个状态或每个页面在这些节点中拥有锁表条目。但是，我们在哪里为关系本身拥有训练过的锁表条目呢？
- en: And so there are a couple of options。 So one is these course screen locks can
    be partitioned across the nodes。 So for example， this node was designated as holding
    the lock table entry for the sailors relation。 This one is holding the entry for
    boats and this one is holding the entry for itself。 So this could be half this
    this partitioning could happen。
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 因此有几种选择。一个是这些训练锁可以在节点之间分区。例如，这个节点被指定为持有水手关系的锁表条目，这个节点持有船只的条目，另一个节点持有其他的条目。所以这种分区可以发生。
- en: by a hash partitioning around Robin partitioning so basically this course screen
    locks are assigned to the other option is it's centralized。 So you have master
    node that that handles all of these course screen locks。 Okay。 so and there's
    no sort of one scheme that that is a winner here I mean there are pros and cons
    for both。 Okay， so let's ignore these global course clean locks for a second。
    And let's talk about the rest。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过哈希分区或轮询分区，所以基本上这些训练锁会被分配到其他节点，另一种选择是它是集中式的。所以你会有一个主节点，负责处理所有这些训练锁。好的。因此，没有一种方案是赢家，意思是两者各有优缺点。好的，那么让我们暂时忽略这些全局训练锁，来讨论剩下的部分。
- en: So each node does its own locking。 It locks sort of the elements that you may
    be referring to in a transaction。 So the tuples， the pages。 And this is nice。
    Right。 It's kind of clean and efficient and generalizes that single node setting。
    So each single node can simply worry about itself and not worry about others because
    it's each single node has a set of tuples has a set of pages as it's responsible
    for。
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 所以每个节点都进行自己的锁定。它会锁定你可能在事务中引用的元素。所以这些元组，页面。而且这是不错的，对吧。这种方式既干净又高效，并且将单个节点的设置进行了泛化。所以每个单独的节点只需要关心自己，而不需要关心其他节点，因为每个节点都有一组元组和一组页面是它负责的。
- en: and it has all of the lock table entries for all of those objects。 However。
    there are global issues that remain right so issues that deal with dead locks
    so how do you detect dead locks。 especially when there are multiple nodes that
    are participating in a transaction。 How do you deal with committing and a body
    again if there are multiple nodes that are participating in that transaction。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 它拥有所有这些对象的锁表条目。然而，依然存在一些全局性的问题，对吧，例如处理死锁的问题。那么，如何检测死锁呢？特别是当有多个节点参与同一个事务时，如何处理提交和回滚的问题呢？如果有多个节点参与这个事务，该如何处理？
- en: Right。 So those are what we're going to be focusing on。 Any questions so far。
    Okay。 so let's start with distributed deadlock detection。 Okay。 so we talked about
    deadlock detection in a single node case which is basically just constructing
    this weights for graph。 And so that sort of approach， you may think let's try
    to apply that to this distributed setting and see what happens。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对。所以这些就是我们要重点讨论的内容。到目前为止有什么问题吗？好的。那么我们就从分布式死锁检测开始。好的，我们讨论过单节点情况下的死锁检测，这基本上就是构建这个等待图。所以你可能会想，尝试将这种方法应用到分布式环境中，看会发生什么。
- en: So you could imagine that every node maintains a weight for graph based on the
    transactions that are performing changes。 whatever holding onto locks at the corresponding
    node。 Right， so for example。 this node may have these three transaction T one
    T three and T two。 and you have a wait for relationship between them。
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以想象，每个节点根据其正在执行的事务维护一个等待图，事务可能会对相应的节点上的锁进行修改。对，比如说，这个节点可能有这三个事务 T1、T3 和
    T2，并且它们之间存在等待关系。
- en: So T two is waiting for T three T one is waiting for the two in this case。 So
    this is a scenario where zooming in might actually help。 Okay。 No two here T one
    is waiting for T three。 And T two is not waiting for anything in node three T
    three is waiting for T two and so on。 Okay， so you have basically these weights
    for graphs at each of these nodes。 Now。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 T2 正在等待 T3，T1 正在等待 T2。在这种情况下，放大可能会有帮助。好的，T1 在等待 T3，T2 在节点 3 中没有等待任何东西，T3
    正在等待 T2，依此类推。好的，所以你基本上在这些节点上都有这些等待图。现在。
- en: one challenge here obviously is that you may not detect a cycle。 If you are
    at a single node without sort of looking at the weights for graphs at other nodes。
    Right。 So， so here basically each machine doesn't have a cycle， but there is a
    global cycle。 And to see this， if you start from this particular graph。
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，存在一个挑战，那就是如果你只在一个节点上而不查看其他节点上的等待图时，可能无法检测到循环。对吧。所以这里基本上每台机器没有循环，但存在一个全局循环。为了看清这一点，如果你从这个特定的图开始
- en: and then add in the edges from the other graphs。 So I added in the other edges
    and you have a cycle。 right。 So you have at least one cycle here。 There are other
    local cycles as well。 So。 so there are multiple cycles in this graph in the global
    graph。 but at any individual node or any individual machine， there are no cycles。
    Right。
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将来自其他图的边加入进去。所以我加入了其他的边，然后你就有一个循环，对吧。所以在这里至少有一个循环。还有其他的局部循环。所以，在这个图和全局图中有多个循环。但在任何单独的节点或任何单独的机器上，都没有循环，对吧。
- en: So how do you deal with this。 So it doesn't seem like each individual node would
    be able to realize that there is a deadlock and then deal with the deadlock by
    possibly aborting some transaction。 So it doesn't look like each node will be
    able to do that with just the information that it has locally。
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你如何处理这个问题呢？所以看起来每个单独的节点似乎不能意识到存在死锁，然后通过可能中止某个事务来处理死锁。所以看起来每个节点无法仅凭它自己本地的信息做到这一点。
- en: So the solution is pretty simple。 Actually， it's basically you periodically
    send your weights for graph to a designated coordinator。 That designated coordinator
    gets all of these weights for graphs and sees if there is a deadlock。 If there's
    a deadlock， it may say， Hey， you， this particular transaction needs to abort。
    And then it will communicate that with all of its machines and then all the machines
    will realize that。
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 所以解决方案很简单。实际上，就是定期将你的图形权重发送给指定的协调者。这个指定的协调者收到所有这些图形权重后，查看是否存在死锁。如果有死锁，它可能会说，嘿，你，这个特定的事务需要中止。然后它会与所有机器进行通信，所有机器就会意识到。
- en: Hey， maybe that transaction is so bad。 Okay， so there is a designated coordinator
    that that sort of is dealt dealing with this deadlock detection。 because it has
    complete information this information that's sent by all of these nodes。 So one
    question， some of you may be thinking is， Hey。 what if in the time that the information
    that is sent to this coordinator in that time。
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 嘿，也许那个事务真的很糟糕。好吧，确实有一个指定的协调者，负责处理死锁检测。因为它有所有这些节点发送的信息。所以，有些人可能会想，嘿，假如在发送给协调者的信息传送期间发生了什么呢？
- en: maybe some transaction decided to commit at some node and therefore the graph
    has changed at some node。 That might certainly happen in those cases， you may
    end up aggressively aborting some transaction you didn't need to。 And that's probably
    okay that's not that's not a bad scenario。 And if there are new deadlocks that
    come up。 So if there are new deadlocks that happen in the interim between the
    time that a node shipped their weights for a graph to this coordinator。
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 也许某个事务在某个节点决定提交，因此图形在某个节点发生了变化。这种情况当然有可能发生，在这种情况下，你可能会不必要地强制中止某个事务。这可能没问题，这不是一个坏的情况。如果在此期间出现新的死锁，发生死锁的时间恰好是在某个节点将其图形的权重发送给协调者之后。
- en: And if there are new deadlocks that happen because of that gap， they will be
    detected later。 So let's not worry about that。 I mean， again， we'll handle that
    later。 So overall。 even though this may be a little aggressive， this may be a
    little stale。 It overall does an okay job。 So that's deadlock detection。 So。
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于这个间隔导致出现新的死锁，它们会在稍后被检测出来。所以我们现在不用担心这些。我的意思是，反正我们稍后会处理它们。所以总体来说，尽管这可能有点激进，可能有点过时，但整体上还是做得不错。所以，这就是死锁检测。
- en: we have a protocol which is called two phase commit， but let's work up to that。
    Okay。 So。 as I mentioned before， each transaction has a coordinator node。 Okay。
    so let's say that my strongman approach is that this coordinator is going to make
    the decision as to whether this transaction is going to commit or it's going to。
    be a good scenario。 And then once the transaction。
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个协议，叫做两阶段提交，但我们先一步步来。好吧。如我之前提到的，每个事务都有一个协调节点。好吧，假设我的强人策略是，这个协调者将决定这个事务是提交还是继续执行。然后，一旦事务。
- en: once this coordinator has made this made this determination， it'll let all the
    other nodes know。 Right。 So it's basically going to inform all the other nodes
    that hate this transaction is going to commit or abort。 Any thoughts on why this
    scheme may be problematic。 Coordinator goes down that's certainly a challenge。
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦协调者做出决定，它会通知所有其他节点。对吧？所以，它基本上会通知所有其他节点，这个事务将会提交或中止。对于这个方案可能存在的问题，你有什么看法吗？协调者崩溃无疑是一个挑战。
- en: But let's assume for now that the coordinator doesn't crash， but that is a challenge。
    What if two nodes come to different conclusions exactly right so as Nicholas says。
    there could be a node that wants to commit and another node that wants to abort。
    What's a scenario where one node might want to commit while another one step board。
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 但假设现在协调者没有崩溃，但这也是一个挑战。如果两个节点得出不同的结论怎么办？正如Nicholas所说，可能有一个节点想提交，另一个节点想中止。在哪种情况下，一个节点可能想提交，而另一个节点想中止呢？
- en: One node crashes that's yet another challenge it's not related to the abort
    thing but it's also another issue so there could be a transaction that touches
    data at a node that is not crashed right so that's you're done for you can't make
    that change for example。
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某个节点崩溃，那又是另一个挑战，虽然这与中止事务无关，但它也是一个问题。比如，可能有一个事务涉及到某个未崩溃的节点上的数据。因此你就无法进行变更了。
- en: A local deadlock is probably a good reason to try to abort a transaction at
    a specific node so that might be a good reason while a node wants to abort a transaction。
    But are there other reasons。 Yeah， like Nicholas you could have a scenario where
    there is a local in the local wait for graph at a node you determine a cycle and
    then decide that you want to abort。
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本地死锁可能是尝试在特定节点中止事务的一个很好的理由，这可能是一个节点希望中止事务的原因。但是否还有其他原因呢？是的，比如尼古拉斯，你可能会遇到这样一种情况，在某个节点的本地等待图中，你发现了一个循环，然后决定中止事务。
- en: A transaction。 Maybe the user just wants to abort the user is not really involved
    in this right you have these machines the user is the one who requested a transaction。
    So at least this is a case where the user said， I want this transaction to commit
    right latency as taken says yes that could be an issue you could have a node that
    is really delayed。
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一个事务，可能用户只是想中止，用户并没有直接参与其中，实际上这些机器是用户请求了事务的提交。所以至少这是一个用户说，“我希望这个事务被提交”的情况，对吧？延迟，正如之前所说的，确实可能成为问题，可能会有一个节点延迟很长时间。
- en: It wants to abort but it's not able to tell the coordinate。 Anyway。 so another
    issue that I so all great points another issue that I wanted to bring up before
    I sort of summarize is possibly a node that says。 I want to abort because the
    insert insertion that you're making to me is going to violate some consistency。
    So it's going to violate violate some integrity constraint like primary key constraint
    so that node has that local information it can make that determination and it
    can say I don't want this transaction to proceed。
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 它想中止，但无法告诉协调者。总之，另外一个问题是，所有这些观点都很好，但我在总结之前还想提一下一个问题，可能有一个节点会说：“我想中止，因为你正在对我进行的插入会违反某些一致性。”所以它会违反一些完整性约束，比如主键约束。这个节点有本地信息，它可以做出这个决定并且说：“我不希望这个事务继续。”
- en: But if the coordinator is making a decision unilaterally that's kind of a dictatorship
    you don't want that right I mean you want the nodes to be able to communicate
    their displeasure at this transaction commitment。 So， I sort of saying no right。
    So the problem with this strongman scheme is that it doesn't take into account
    the input from all of the notes that may be participating in this transaction。
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果协调者单方面做出决定，那就像是独裁统治，你不希望那样，对吧？你是希望节点能够传达它们对事务提交的不满。所以说“不行”。这个强人方案的问题就在于，它没有考虑到所有可能参与该事务的节点的输入。
- en: Okay， so among other things like I said， one of the nodes may want to abort
    even the coordinator wants to commit some notes may actually be down。 So any notes
    transactions touching the data shouldn't proceed。 Okay。 so let's summarize all
    of this and talk about what in general could go wrong。 So the first type of thing
    that could go wrong is basically failures and delays that come from notes。
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，除了这些情况，如我所说，其中一个节点可能希望中止，即使协调者希望提交，某些节点实际上可能已经宕机。因此，任何涉及数据的节点事务都不应继续。好了，那么让我们总结一下这些内容，并谈谈通常会发生什么问题。首先可能出问题的类型基本上就是来自节点的故障和延迟。
- en: Right， so for example， if we haven't heard from a node we don't know if the
    node is alive or dead。 And the decision may hinge on this node， right， so imagine
    that there's a potential foreign key evaluation that could happen at that node。
    We do need to hear from them before we decide whether we want to commit this transaction
    or not。 And unfortunately we might not even know that a node is alive or dead。
    And then。
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，如果我们没有收到某个节点的消息，我们就不知道该节点是活着还是死了。这个决定可能会影响到该节点，因此假设在那个节点上有可能发生外键评估。我们确实需要听到该节点的消息，然后才能决定是否提交这个事务。不幸的是，我们甚至可能不知道一个节点是否还活着。
- en: if the node was dead。 How does the node actually recover in a world where multiple
    transactions may have committed after that right so there's a challenge in sort
    of supporting recovery when a node has failed。 and then has to recover。 Okay，
    so I'll then we'll talk about recovery schemes in this protocol data。
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点已经崩溃，节点是如何恢复的呢？在一个可能有多个事务已经提交的世界里，恢复又该如何支持呢？所以当一个节点失败后需要恢复时，这就形成了一个挑战。好了，那么接下来我们将讨论本协议数据中的恢复方案。
- en: So that's what could go wrong in terms of failures and delays for nodes。 What
    could go wrong in terms of failures and delays for messages。 So the first thing
    is that you can have non deterministic reordering on a per channel basis and interleaving
    across channels。 Okay， so， and the other issue is that you could have some very。
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是在节点出现故障和延迟时可能出错的情况。那么在消息出现故障和延迟时，可能出错的情况是什么呢？首先，可能会在每个通道的基础上发生非确定性的重排序，并且在通道之间发生交错。好的，另外一个问题是，可能会有一些非常。
- en: very delayed messages and the challenge there is how long should we wait for
    a delayed message。 This is a message simply delayed or is the node down it's hard
    to sort of decouple the two。 So in terms of the non deterministic reordering per
    channel。 deleting across channels and lost messages here's an animation that illustrates
    all of the three。
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 非常延迟的消息，挑战在于我们应该等多久才能处理一个延迟的消息。这条消息仅仅是延迟了吗，还是节点宕机了？很难将两者区分开来。所以，关于每个通道的非确定性重排序、通道间的删除以及丢失的消息，下面有一个动画，展示了这三种情况。
- en: So here I have four messages green red yellow and purple。 And so as you can
    see。 The red and the yellow are going to get reordered。 The green one is going
    to get interleave between the two and the purple one is going to get dropped。
    Okay， so and that could certainly happen。 This is this is a scenario that could
    certainly happen。
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我有四条消息，分别是绿色、红色、黄色和紫色。正如你所看到的，红色和黄色的消息会被重新排序，绿色的消息会在两者之间交错，而紫色的消息将被丢弃。好的，这确实可能发生。这是一个可能发生的场景。
- en: So given all of this it's it's tricky to figure out how all of these nodes are
    going to decide to agree to commit or abort。 Okay， so I think I will stop at this
    point since we're at six 29。 And then I will talk about this distributed voting
    protocol and two phase commit in the next lecture。 Any questions about this so
    far。 If your questions please stay otherwise I think we're going to stop reporting
    here and have a great weekend everyone。
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 所以考虑到这一切，要弄清楚所有这些节点如何决定同意提交还是中止，确实是一个难题。好的，我想我将在此停下来，因为现在是六点二十九分。接下来，我将在下一堂课中讲解分布式投票协议和二阶段提交。到目前为止有任何问题吗？如果有问题，请留下来，否则我想我们将在这里停止报告，祝大家周末愉快。
- en: Bye folks。 Bye。 [BLANK_AUDIO]。
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 再见，大家。再见。[BLANK_AUDIO]
- en: '![](img/36def6d6b9866c9c33a169a2bce65f2c_9.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36def6d6b9866c9c33a169a2bce65f2c_9.png)'
