# 渐近复杂性的回顾

* * *

<menu>*   渐近分析*   最坏情况和平均情况分析*   增长顺序和大 O 符号*   比较增长顺序*   二叉搜索树*   练习</menu>

* * *

## 渐近分析

在分析程序的运行时间或空间使用率时，我们通常尝试估计时间或空间作为输入大小的函数。例如，当分析对数字列表进行排序的函数的最坏情况运行时间时，我们将关注它随着输入列表长度的增长而需要多长时间。例如，我们说标准插入排序的时间是*T(n)*，其中*T(n)=c*n*²+k*，对于某些常数*c*和*k*。相比之下，归并排序的时间是*T'(*n*)*=c'***n*log*2+k'*。

函数*f(n)*（例如*f(n)=c*n*或*f(n)=c*n²*等）的**渐近行为**指的是*n*增大时*f(n)*的增长。我们通常忽略*n*的小值，因为我们通常只关心对大输入估计程序的速度有多慢。一个好的经验法则是：渐近增长率越慢，算法越好（尽管这通常不是全部）。

按照这个标准，一个线性算法（*即，f(n)=d*n+k*）在渐近上总是比二次的好（*例如，f(n)=c*n²+q*）。这是因为对于任何给定的（正）*c，k，d*和*q*，总会有一些*n*，在这个*n*处，*c*n²+q*的量级会超过*d*n+k*。对于适度的*n*值，二次算法很可能比线性算法需要更少的时间，例如如果*c*显著小于*d*和/或*k*显著小于*q*。然而，对于足够大的输入，线性算法总是更好的。在处理渐近增长率时，请记得**展望未来**。

## 最坏情况与平均情况分析

当我们说一个算法的运行时间是*T(n)*时，我们的意思是*T(n)*是对运行时间的一个上界，对于所有大小为*n*的输入都成立。这称为**最坏情况分析**。该算法在某些大小为*n*的输入上可能需要更少的时间，但这无关紧要。如果一个算法对每个大小为*n*的输入只需步骤*T(n)=c*n²+k*，并且对其余输入只需*n*步，我们仍然说它是一个二次算法。

替代最坏情况分析的一种流行方法是*平均情况分析*。在这里，我们不限制最坏情况的运行时间，而是尝试计算在随机选择的输入上花费的期望时间。这种分析通常更难，因为它涉及概率论论证，并且通常需要对输入分布进行难以证明的假设。另一方面，它可能更有用，因为有时算法的最坏情况行为会误导性地很差。一个很好的例子是流行的快速排序算法，其在长度为*n*的输入序列上的最坏情况运行时间与*n*²成正比，但其期望运行时间与*n* log *n*成正比。

## 增长顺序和大 O 表示法

在估计`insert_sort`（或任何其他程序）的运行时间时，我们不知道常数*c*或*k*是多少。我们知道它是一个中等大小的常数，但除此之外并不重要；我们有足够的证据来知道`merge_sort`（见下文）比二次的`insert_sort`更快，即使常数可能有所不同。（这并不总是成立；常数有时会产生影响，但一般来说这是一个非常好的经验法则。）

我们甚至可能无法直接测量常数*c*。例如，我们可能知道语言中的给定表达式，比如`if`，需要常数个机器指令，但我们可能不知道究竟有多少。此外，相同的指令序列在 Pentium IV 上执行的时间将比在 Pentium II 上少（尽管差异大致是一个常数因子）。因此，这些估计通常只准确到一个常数因子。出于这些原因，我们通常忽略比较渐近运行时间中的常数因子。

计算机科学家已经开发了一个方便的符号来隐藏常数因子。我们写成*O(n)*（读作：“阶 *n*”）而不是“*cn*是某个常数 *c*”。因此，如果存在一个固定的常数*c*，对于所有足够大的*n*，算法在大小为*n*的输入上最多花费*cn*的时间，则称算法为*O(n)*或*线性时间*。如果存在一个固定的常数*c*，对于所有足够大的*n*，算法在大小为*n*的输入上最多花费*cn²*的时间，则称算法为*O(n²)*或*二次时间*。*O(1)*意味着*常数时间*。

*多项式时间*意味着*n^(O(1))*，或者*n^c*，其中*c*是某个常数。因此，任何常数、线性、二次或三次（*O(n³)*）时间算法都是多项式时间算法。

这被称为*大 O 表示法*。它简洁地捕捉了函数渐近增长率之间的重要差异。

大 O 表示法的一个重要优点是它使得算法分析变得更加容易，因为我们可以方便地忽略低阶项。例如，一个运行时间为

*10n³ + 24n² + 3n log n + 144*

仍然是一个三次算法，因为

*10n³ + 24n² + 3n log n + 144*

<= 10n³ + 24n³ + 3n³ + 144n³

<= (10 + 24 + 3 + 144)n³

= O(n³)*。

当然，由于我们忽略了常数因子，任何两个线性算法在这个度量标准下都会被认为是同样好的。甚至可能存在一些情况，线性算法中的常数太大，以至于在实践中，即使是具有较小常数的指数算法也可能更可取。这是对渐近分析和大 O 符号的一个有效批评。然而，作为一个经验法则，它已经为我们服务得很好。只需注意它*仅仅*是一个经验法则--渐近最优算法不一定是最好的。

在复杂度分析中经常见到的一些常见增长阶数是

| *O(1)* | 常数阶 |
| --- | --- |
| *O(log n)* | 对数阶 |
| *O(n)* | 线性阶 |
| *O(n log n)* | "n log n" |
| *O(n²)* | 二次阶 |
| *O(n³)* | 立方阶 |

这里的*log*表示*log[2]*或以 2 为底的对数，尽管对数的底实际上并不重要，因为不同底的对数之间只相差一个常数因子。还要注意*2^(O(n))*和*O(2^n)*并不相同！

## 比较增长阶数

**O**

设*f*和*g*是从正整数到正整数的函数。如果*g*是*f*的上界：存在一个正常数*c*和一个正整数*n*[0]，使得对所有*n≥n*[0]，

*f(n) ≤ cg(n)*。

同样，如果函数*f(n)/g(n)*被某个常数上界限制，则*f*是*O(g(n))*。

**o**

我们说*f*是*o(g(n))*（读作：“f 是 g 的小 o”），如果对于所有正常数*c*，存在一个正整数*n*[0]，使得对所有*n≥n*[0]，

*f(n) ≤ cg(n)*。

同样，如果函数*f(n)/g(n)*随着*n*趋向无穷而趋向于 0，则*f*是*o(g)*。也就是说，f 相对于 g 来说很小。如果*f*是*o(g)*，那么*f*也是*O(g)*。

O 和 o 的定义之间的主要区别在于，O 中的上界对于*某个*常数*c*成立，而 o 中的上界对于*所有*常数*c*成立。

**Ω**

我们说*f*是Ω(*g*(*n*))（读作：“f 是 g 的 omega”），如果*g*对于大的*n*是*f*的下界。形式上，如果存在一个固定常数*c*和一个固定的*n*[0]，使得对所有*n*>*n*[0]，

*c**g*(*n*) *≤* *f*(*n*)

例如，任何最高指数为*n^k*的多项式都是Ω(*n^k*)。如果*f*(*n*)是Ω(*g*(*n*))，那么*g(n)*是 O(*f*(*n*))。如果*f*(*n*)是*o*(*g*(*n*))，那么*f(n)*不是Ω(*g*(*n*))。

**Θ**

我们说*f*是Θ(*g(n)*)（读作：“f 是 g 的 theta”），如果*g*对于大的*n*是*f*的准确描述：它可以被缩放，使其既是*f*的上界又是下界。也就是说，*f*既是 O(*g*(*n*))又是Ω(*g*(*n*))。展开Ω和*O*的定义，如果存在固定常数*c*[1]和*c*[2]以及固定的*n*[0]，使得对所有*n*>*n*[0]，

*c*[1]*g*(*n*) *≤* *f*(*n*) *≤* *c*[2] *g*(*n*)

例如，任何最高指数为 *n^k* 的多项式都是 Θ(*n^k*)。如果 *f* 是 Θ(g)，那么它是 *O*(*g*) 但不是 *o*(*g*)。有时人们有点非正式地使用 *O*(*g*(*n*)) 来表示更强的性质 Θ(*g*(*n*))；然而，这两者是不同的。

这里有一些例子：

+   *n + log n* 是 *O(n)* 和 Q(*n*)，因为对于所有 *n > 1*，*n* < *n + log n < 2n*。

+   *n¹⁰⁰⁰* 是 *o(2^n)*，因为 *n¹⁰⁰⁰/2^n* 随着 *n* 趋向无穷大而趋向于 0。

+   对于任意固定但任意小的实数 *c*，*n log n* 是 *o(n^(1+c))*，因为 *n log n / n^(1+c)* 趋向于 0。为了看到这一点，取对数

    *log(n log n / n^(1+c))

    = log(n log n) - log(n^(1+c))

    = log n + log log n - (1+c)log n

    = log log n - c log n*

    并观察它趋向于负无穷大。

像 *O*(*n*²) 这样的表达式的含义实际上是一组函数：所有 *O*(*n*²) 的函数。当我们说 *f(n)* 是 *O(n*²*)* 时，我们的意思是 *f(n)* 是这个集合的一个成员。通常也写成 *f*(*n*) = *O*(*g*(*n*))，虽然它不是真正的等式。

现在，我们介绍一些方便的规则来操作涉及顺序符号的表达式。这些规则，我们不加证明地陈述，对于处理增长顺序非常有用。它们实际上是关于函数集合的陈述。例如，我们可以把 #2 看作是说，在 *O*(*f*(*n*)) 和 *O*(*g*(*n*)) 中任意两个函数的乘积也在 *O*(*f*(*n*)*g*(*n*)) 中。

1.  *cn^m = O(n^k)* 对于任何常数 *c* 和任何 *m ≤ k*。

1.  *O(f(n)) + O(g(n)) = O(f(n) + g(n))*。

1.  *O(f(n))O(g(n)) = O(f(n)g(n))*。

1.  *O(cf(n)) = O(f(n))* 对于任何常数 *c*。

1.  对于任何常数 *c*，*c* 是 *O(1)*。

1.  *log[b]n = O(log n)* 对于任何基数 *b*。

所有这些规则（除了#1）也适用于 Θ。

* * *

## 练习

1\. 使用列表编写堆栈的实现。每个操作的大 O 运行时间是多少？堆栈的签名是：

```
module type STACK =
  sig
    type 'a stack
    val empty : unit -> 'a stack
    val push : ('a * 'a stack) -> 'a stack
    val top : 'a stack -> 'a option
    val pop : 'a stack -> ('a stack) option
  end

```

2\. 使用列表编写队列的实现。每个操作的大 O 运行时间是多少？队列的签名是：

```
module type QUEUE =
  sig
    type 'a queue
    val empty : unit -> 'a queue
    val insert : ('a * 'a queue) -> 'a queue
    val first : 'a queue -> 'a option
    val rest : 'a queue -> 'a option
  end

```

3.  手写 List 结构中出现的一些函数（例如，rev、@、map、foldl 等），并分析它们以确定它们的大 O 运行时间。**
