# „ÄêÂèåËØ≠Â≠óÂπï+ËµÑÊñô‰∏ãËΩΩ„ÄëMIT 6.042J ÔΩú ËÆ°ÁÆóÊú∫ÁßëÂ≠¶ÁöÑÊï∞Â≠¶Âü∫Á°Ä(2015¬∑ÂÆåÊï¥Áâà) - P96ÔºöL4.5 Expectation - ShowMeAI - BV1o64y1a7gT

We ask about averages all the timeÔºå and in the context of random variables„ÄÇ

 As get abstracted into a lovely concept called the expectation of the random variable„ÄÇ

 Let's begin with a motivating exampleÔºå whichÔºå as is often the caseÔºå will come from gambling„ÄÇ

So there's a game that's actually played in casinos called Carnival dice„ÄÇ

 where you have three dice and the way you play is you pick your favorite number from one to6„ÄÇ

 whatever it happens to beÔºå and then you roll the three diceÔºå the dice assumed to be fair„ÄÇ

 so each one of them has one in six chance of coming up with any given number„ÄÇ

 and then the payoff goes as follows for every match of your favorite numberÔºå you get a dollar„ÄÇ

And if if none of the dies show your favorite numberÔºå then you lose a dollar„ÄÇOkay„ÄÇ

 let's do an example„ÄÇ Suppose your favorite number was 5„ÄÇ

 You announced that to to the house or the dealer and then the dice start rolling„ÄÇ Now„ÄÇ

 if your role happened to come up with the numbers 2Ôºå3 and 4Ôºå wellÔºå there's no  fives there„ÄÇ

 So you've lost a dollar„ÄÇ On the other handÔºå if your roles came outÔºå5Ôºå4Ôºå6Ôºå there's 1Ôºå5„ÄÇ

 you've won a dollar„ÄÇ If it came out 5Ôºå4Ôºå5Ôºå there's 2Ôºå5sÔºå you've won a dollar„ÄÇ

 And if it was all fiveÔºå you've actually won $3„ÄÇ Now„ÄÇ

 real carnival dice is often played where you either win or lose a dollar depending on whether there's any match at all„ÄÇ

 But we're playing a more generous game where if you double matchÔºå you get $2„ÄÇ If you triple match„ÄÇ

 you get $3„ÄÇ So the basic question about this is„ÄÇIs this a fair game„ÄÇ

 is this worth playing and how can we think about that„ÄÇ

 well we're going to think about it probabilistically„ÄÇ

So let's think about the probability of rolling„ÄÇNo fives„ÄÇ If5 is my favorite number„ÄÇ

 What's the probability that I roll None of them„ÄÇ Well„ÄÇ

 there's a five out of six chance that I don't roll a 5 on the first die„ÄÇ

 And on the second die and on the third die„ÄÇ And since the die rolls are assumed to be independent„ÄÇ

 The dies are independent„ÄÇ The probability of no 5s is 5Ôºå6 to the thirdÔºå which comes out to be 125„ÄÇ

216s„ÄÇ I'm writing this out because we're going to put all the numbers over 216 to make them easier to compare„ÄÇ

 OkayÔºå what's the probability of 1Ôºå5„ÄÇ WellÔºå the probability of any single sequence of die rolls with a single five is5„ÄÇ

6 of no 5 times 5Ôºå6 of no 5 times 1Ôºå6 of 1Ôºå5„ÄÇ And there are three choose„ÄÇ

1 possible sequences of dice rolls with1Ôºå5Ôºå and the other nonfis„ÄÇ likewiseÔºå for twoÔºå5s„ÄÇ

 there's three choosesÔºå2 times 5Ôºå6 to the one„ÄÇWhich is„ÄÇOne way of choosing the„ÄÇ

Place that does not have a5 and16 times 1Ôºå6Ôºå which is the probability of getting fives in the other places„ÄÇ

I didn't say that wellÔºå but you can get it straight„ÄÇ OkayÔºå the probability of 3„ÄÇ

5s is the probability of 1Ôºå6 of getting a 5 on the first dieÔºå16 of getting a five on the second die„ÄÇ

16 of getting a five on the third dieÔºå simply 16 cubed„ÄÇ Okay„ÄÇ

 so we can easily calculate these probabilities„ÄÇ This is a familiar exercise„ÄÇ

 let's put them in a chart„ÄÇ So what we figured out is that0 matches has a probability of 125 over 216„ÄÇ

 And in that caseÔºå I lose a buck„ÄÇOne match turns out to have a probability of $75 out of 216„ÄÇ

 and I win a dollarÔºå two matches is 15 out of 216„ÄÇ I win $2 and three matches„ÄÇ

 there's one chance in $216 that I win the $3„ÄÇ so now I can ask about what do I expect to win„ÄÇ

 suppose I play 216 games and the game split exactly according to these probabilities„ÄÇ

 then what I would expect is that I would wind up with0 matches about 125 times„ÄÇ

 That is the probability of there being no matches„ÄÇ It was 125Ôºå216„ÄÇ So if I play 2Ôºå16 games„ÄÇ

 I expect about 125 we' I'm going to win nothing„ÄÇ or I'm going to get no matches„ÄÇ

 which actually means I'll lose a dollar on each„ÄÇ1 matchÔºå I expect about 75 times  two matches„ÄÇ

15 times  three matches once„ÄÇSo my average win is going to be  a hundred 25 times -1Ôºå75 times 1„ÄÇ

15 times 2 plus 1 times 3Ôºå divided by 216„ÄÇSo these numbers on the top were have the 216 rolls split among my choices of losing a dollar„ÄÇ

 winningning a dollarÔºå winning $2 and winning $3„ÄÇ And it comes out to be slightly negative„ÄÇ

 It's actually -8 cents- to 17216 of a dollarÔºå which is about -8 cents„ÄÇ

 So I'm losing on the average 8 cents per rollÔºå this is not a fair game„ÄÇ

 It's really biased against me„ÄÇ And if I keep playing long enough„ÄÇ

 I'm going to find that I average out a kind of steady loss of about 8 cents a play„ÄÇSo„ÄÇ

We would summarize this by saying that you expect to lose 8 cents„ÄÇ

 meaning that your average loss is 8 cents„ÄÇ and you expect that that's going to be the phenomenon that comes up If you keep playing the game repeatedly repeatedly„ÄÇ

 It's important to noticeÔºå Of courseÔºå you never actually lose 8 cents on any single play„ÄÇ

 So what you this notion of yourre expecting to lose 8 cents„ÄÇ It never happens„ÄÇ

 It's just your average loss„ÄÇ No every single play you're either going lose a dollar win a dollar and win$2 win $3„ÄÇ

 There's no $8 cents at all showing up„ÄÇ

![](img/00b650f2b98a1e5bb437e59db93183ee_1.png)

Okay„ÄÇ

![](img/00b650f2b98a1e5bb437e59db93183ee_3.png)

So now let's abstract the expected value of a random variable R„ÄÇ

 so random variables is the thing that probabilistically takes on different values with different probabilities„ÄÇ

 and its expected value is defined to be its average value where the different values are weighted by their probabilities„ÄÇ

We can write this out as a precise formula„ÄÇ The expectation of a random variable R is defined to be the sum over all its possible values„ÄÇ

 it doesn't indicate what the summation isÔºå but that's over all possible values V of V times the probability that V comes up the probability that R equals v„ÄÇ

 So this is the basic definition of the expected value of a random variable„ÄÇ

 Now let me mention here that this sum works because since we're assuming accountable sample space„ÄÇ

 R is defined on only countably many outcomesÔºå which means it can only take countably many values„ÄÇ

 So this is accountable sum over all the possible values that R takes because there are only accountably many accountably many of them„ÄÇ

And what we've just concluded then is the expected win in the carnival dice game is -17Ôºå216s„ÄÇ

 Check this formal definition of the expectation of a random variable versus the random variable defined to be how much you win on a given play of carnival dice„ÄÇ

 and it comes out to be that average-17 over 216„ÄÇNow there's a technical result that's useful in some pros and that says that there's another way to get the expectation„ÄÇ

 the expectation can also be expressed by saying it's the sum over all the possible outcomes in the sample space„ÄÇ

 as is the sample space of the value of the random variable at that outcome times the probability of that outcome„ÄÇ

YeahÔºå so this is another an alternative definition of compared to saying that it's the the„ÄÇ

The sum over all the values times the probability of that value here„ÄÇ

 It's the sum over all the outcomes of the the value of the random variable„ÄÇ

 of the outcome times the probability of the outcome„ÄÇ

 It's not entirely obvious that those two definitions are equivalent„ÄÇ

 This form of the definition turns out to be technically helpful in some proofs„ÄÇ

 although outside proofs„ÄÇ don' don't use it so much an applications„ÄÇ

 but it's not a bad exercise to prove this equivalence„ÄÇ So I'm going to walk you through it„ÄÇ

 But if it's boringÔºå it's kind of a boring series of equations on slides and you're welcome to skip past it„ÄÇ

 it is a derivation that I expect you to be able to carry out„ÄÇ

 So let's just carry out this derivation„ÄÇ I'm going to prove that the expectation is equal to the sum over all the outcomes of the value of the random variable„ÄÇ

 the outcome times the probability of the outcome„ÄÇ And let's prove it„ÄÇIn order to prove it„ÄÇ

 let's begin with one little remark that's useful„ÄÇ OkayÔºå remember that this notation„ÄÇ

 R equals V describes the event that the random variable takes the value V„ÄÇ

 which by definition is an event is the set of outcomes where this property holds„ÄÇ

 So it's the set of outcomesÔºå Oomega where R of omega is equal to V„ÄÇ So let's just remember that„ÄÇ

 That brackets R equals V is the event that R is equal to V„ÄÇ

 meaning the set of outcomes where that's true„ÄÇüòäÔºåSo what that tells us in particular is that the probability of R equals v is by definition the sum of the probabilities of the outcomes in the event„ÄÇ

So it's the sum over all those outcomes„ÄÇNowÔºå let's go back to the original definition of the expectation of R„ÄÇ

 The original definition isÔºå and the standard one is it's the sum over all the values of the value times the weight times the probability that the random variable is equal to the value„ÄÇ

 NowÔºå on the previous slideÔºå we just had a formula for the probability that R is equal to V„ÄÇ

 It's simply the sum over all the outcomes of where R is where R is equal to V of the probability of that outcomes„ÄÇ

 So I can replace that term by the sum over all the outcomes of the probability of the outcome„ÄÇOkay„ÄÇ

 so I'm trying to head towards an expression that's only outcomes„ÄÇ

 which is kind of the top level strategy here„ÄÇ So the first thing I did was I got rid of that probability of V and replaced it by the sum of all these probability of the probabilities of all the outcomes where R is V„ÄÇ

WellÔºå next step is I'm going to just distribute the v over the inner sum„ÄÇ

 and I get that this thing is equal to the sum over again„ÄÇ

 over all those outcomes in R equals v of v times the probability of the outcome„ÄÇBut lookÔºå the out„ÄÇ

 these outcomes are the outcomes where R is equal to V„ÄÇ So I can replace that V„ÄÇBye„ÄÇR of Oomega„ÄÇ

Look that one slipped sideways a little bit„ÄÇ So let's watch that This V is simply going to become an R of omega„ÄÇ

Where I'm still summing over the same set of omegas„ÄÇ

 But now I've gotten rid of pretty much everythingÔºå but the omegas„ÄÇ

 So I've got this inner sum of over all possible omegas in R of V of R of omega times the probability of omega„ÄÇ

 and I'm summing over all possible V„ÄÇ But if I'm summing over all possible v„ÄÇ

 And then all possible outcomes where R is equal to v„ÄÇ I wind up suming over all possible outcomes„ÄÇ

 And so I finished the proof„ÄÇ that the expectation of R is equal to the sum over all the outcomes of R of omega times the probability of omega„ÄÇ

NowÔºå I'd never do a proof like this in a lecture because I think watching a lecturer write stuff on the board a whole bunch of symbols and manipulating equations is really insipid and boring„ÄÇ

 Most people can't follow it anyway„ÄÇ I'm hoping that in the video where you can go back if you wish and replay it and watch it more slowly or at your own speed„ÄÇ

 the derivation will be of some value to you„ÄÇ But let's step back a little bit and notice some top levell technical things that we never really paid attention to in the process of doing this manipulative proof„ÄÇ

 So the top level observationÔºå first of allÔºå is that this proof like many proofs in basic foundations of probability theory and random variables in particular involves taking sums and rearranging the terms in the sums a lot„ÄÇ

 So the first question is why sums„ÄÇRemember hereÔºå we were summing over all the possible variables„ÄÇ

 all the possible values of some random variable„ÄÇ Why is that a sum„ÄÇ WellÔºå it's a sum„ÄÇ

 because we were assuming that the sample space was countable„ÄÇ

 There were only accountable number of values R of omega 0 R of omega 1 R of omega and and so on„ÄÇ

 And so we we can be sure that the sum over all the possible values of the random variable is accountable sum„ÄÇ

 It's a sum„ÄÇ and we don't have to worry about integrals„ÄÇ

 which is the main technical reason why we're doing discrete probability and assuming that there are only accountable number of outcomes„ÄÇ

 There's a second very important technicality that's worth mentioning All the proofs involved rearranging terms in sums„ÄÇ

 freely and without care„ÄÇBut that means that we're implicitly assuming that it's safe to do that and that in particular„ÄÇ

 that they're defining some for expectations„ÄÇNeeds to be absolutely convergent„ÄÇ

 and all of these sums need to be absolutely convergent in order for that kind of rearrangement to make sense„ÄÇ

 So remember that absolute convergence means that the„ÄÇ

 that the sum of the absolute values of all the terms in the sum converge„ÄÇ

So if we look at this definition of expectationÔºå it said it was the sum over all the values in the range„ÄÇ

 We know that's accountable sum of the value times the probability that R was equal to that value„ÄÇ

 But the very definition never specified the order in which these terms V times probability R equals V got added up„ÄÇ

 it better not make a difference„ÄÇ So we're implicitly assuming absolute convergence of this sum in order for the expectation to even be well defined„ÄÇ

 As a matter of factÔºå the terrible pathology that happens„ÄÇ

 And you may have learned about this in first time calculus„ÄÇ

 and we actually have a problem in the text about it is that you can have sums like this that are not absolutely convergent„ÄÇ

 and and then you pick your favorite value and I can rearrange the terms in the sum so that it converges to that value„ÄÇ

When you're dealing with non absolute value sumsÔºå rearranging is a no no the sum depends crucially on the order in which the terms appear„ÄÇ

 and all of the reasoning and probability theory would be inapplicable„ÄÇ

 so we are implicitly assuming that all of these sums are absolutely convergent„ÄÇÂïä„ÄÇ

Just to get some vocabulary in placeÔºå the expected value is also known as the mean value or the mean or the expectation of the random variable„ÄÇ

NowÔºå let's connect up expectations with averages in a more precise way„ÄÇ

 We said that the expectation was kind of an abstraction of averages„ÄÇ

 but it's more intimately connected to averages than that„ÄÇ even„ÄÇ let's take an example„ÄÇ

 where're suppose you have a pile of graded exams„ÄÇ And you pick one at random„ÄÇ

 Let's let S be the score of the randomly picked exam„ÄÇ So I'm turning this process„ÄÇ

 this random process of picking an exam from great from the pile is defining a random variable S„ÄÇ

 where by definition of picking one at randomÔºå I mean uniformly„ÄÇ

 So S is actually not a uniform random variableÔºå but I'm picking the exams with equal probability„ÄÇ

 And then they have different scores„ÄÇ So the outcomes are of uniform probability„ÄÇ

 but S is not because there might be a lot of outcomesÔºå a lot of exams of the same score„ÄÇ All right„ÄÇ

 S is a random variable defined by this process of picking a random exam„ÄÇ

 So and then you can just check„ÄÇThe expectation of S now exactly equals the average exam score„ÄÇ

 which is the typical thing that students want to know when the exam is done„ÄÇ

 what's the average score„ÄÇ ActuallyÔºå the average score is often less informative than median score„ÄÇ

 the middle scoreÔºå but people somehow or other always want to know about the averages„ÄÇ

 The reason why the average may not be so informative„ÄÇ

 is because well it has some weird properties that I'll illustrate in a second„ÄÇ

 but the point here of what we did where we took we got it at the average score on the exam by defining a random variable based on picking a random exam„ÄÇ

 So that's a general processÔºå we can estimate averages in some population of things by estimating the expectations of random variables„ÄÇ

Based on picking random elements from the thing that we're averaging over„ÄÇ that's called sampling„ÄÇ

 And it's a basic idea of probability theory that we're going to be able to get a hold of averages by abstracting„ÄÇ

The calculation of an average into takingÔºå defining a random variable and„ÄÇ

Calculating its expectationÔºå let's look at an example„ÄÇ

It's obviously impossible for all the exams to be above average„ÄÇYeah„ÄÇ

 because then the average would be above average„ÄÇ That's absurd„ÄÇ

 So if you translate that into a formal statement about expectationsÔºå it translates directly„ÄÇ

 By the wayÔºå I don't know how many of you listen to the Prairie home companion„ÄÇ

 But one of the sign offs there is at the town of Lake Wobaon in Wisconsin„ÄÇ

 where all the children are above average„ÄÇ WellÔºå Tat possible„ÄÇ

That translates into this technical statement that the probability that a random variable is greater than its expected value is less than one„ÄÇ

 It can't always be greater than its expected value„ÄÇ That's absurd„ÄÇOn the other hand„ÄÇ

 it's actually possible for the probability that the random variable is bigger than its expected value to be as close to one as you want„ÄÇ

And one way to think about that is thatÔºå for example„ÄÇ

 almost everyone has an above average number of fingers„ÄÇThink about that for a second„ÄÇ

 Almost everyone has an above average number of fingers„ÄÇ WellÔºå the explanation is really simple„ÄÇ

 It's simply because amputation is much more common than polyactileism„ÄÇ

And if you can't understand what I just saidÔºå look it up and think about it„ÄÇ

So for practice with expectationÔºå let's calculate the expected number of heads in end coin flips„ÄÇAnd„ÄÇ

Just working directly from the definition because we have tools to do that„ÄÇ

So we're imagining an independent flips of a coin with bias P„ÄÇ

 so the coins might not be fair the probability of heads is P„ÄÇ

It would be biased in favor of heads if P is greater than half and and biased against heads„ÄÇ

 if P is less than a half„ÄÇ And we want to know how many heads are expected„ÄÇ

 This is a basic question that will come up again and again when we look at random variables in probability theory„ÄÇ

So what's the expected number of heads„ÄÇ WellÔºå we already know we've examined the binomial distribution B N P„ÄÇ

 B N P is telling us how many heads there are and independent flips„ÄÇ

 So we're asking about the expectation of the binomial variable B And P„ÄÇ Well„ÄÇ

 let's look at the definition„ÄÇThe definition of that of B andP is it's the sum over all the possible values of being namely„ÄÇ

 all the numbers from0 to n„ÄÇThat's K of the probability of getting K heads„ÄÇ

 And this formula here is the probability of getting K K heads„ÄÇ

 which we've worked at previously and choose K times P to the K1 minus P to the n minus k„ÄÇ Well„ÄÇ

 let's introduce an abbreviation„ÄÇ a standard abbreviation„ÄÇ Let's replace 1 minus P by  Q„ÄÇ

 where so P plus Q equals 1„ÄÇ And they're both not negative„ÄÇ and between 0 and 1„ÄÇ

And when I express the expectation this wayÔºå it starts to look like something a little bit familiar„ÄÇ

 And our strategy is going to be to use the binomial theorem„ÄÇ

 And then the trick of differentiating it is going to wind up giving us a closed formula for this expression for the expectation of the binomial„ÄÇ

We're in a variable„ÄÇSo let's remember the binomial theorem says that the n power of x plus y is the sum o from k equals 0 to n of n choose k x to the K Y to the n minus k„ÄÇ

And if I differentiate thisÔºå what happens is that on the left hand side„ÄÇ

 if I differentiate with respect to xÔºå I get x plus y to the n -1 times n„ÄÇ

And if I differentiate the right hand sideÔºå let's differentiate term by term„ÄÇ

 And differentiating with respect to x is going to turn this and choose K x to the K Y to the n minus K into an x to the K -1 times K term„ÄÇ

But I'd like to keep the N and the the K here and the K there matching„ÄÇ So that after differentiate„ÄÇ

 after differentiating that becomes an x to the K -1Ôºå let's multiply it by x to make it x to the K„ÄÇ

 AndÔºå of courseÔºå I have to undo that multiplication by dividing the whole thing by one over x„ÄÇ

 So by differentiating the binomial„ÄÇFormulaÔºå we get the following formula for this sum that is starting to look just like the expectation of B And P1 over x times the sum from k equal 01 of K times n K X to the K Y to the n minus K„ÄÇ

 WellÔºå let's compare the two term„ÄÇ So here's this term„ÄÇ There's this one„ÄÇ

 I'm going to replace this line by the formula for expectation of the binomial random variable„ÄÇ

 So this is what we're trying to evaluate„ÄÇ And I have this great theem„ÄÇ

 You can see how they match up„ÄÇSo what I'm going to do is replace P and Q replace X and Y in this general formula that I got by differentiating the binomial theorem with P and Q and what happens„ÄÇ

 So I just plug in the P and Q„ÄÇ Now the left hand side P plus Q is1„ÄÇ

 So the left hand side is going to become„ÄÇBen„ÄÇAnd„ÄÇThis right hand side now is exactly the expectation of B N P„ÄÇ

 this part of it anyway„ÄÇ So what I'm going to wind up with is that n is equal to the1 over P times the expectation of BM P„ÄÇ

 In other wordsÔºå the expectation of B N P is N times P„ÄÇ

 And that is the basic formula that we were deriving by first principles without using any general properties of expectation„ÄÇ

 just the definition of expectation and the stuff that we had already worked out in terms of the binomial theorem„ÄÇ

The law of total expectation will give us another important tool for reasoning about expectations„ÄÇ

And it's basically a rule like the law of a total probability closely related to it really„ÄÇ

 for reasoning by cases about expectation„ÄÇ So it requires a definition of what's called conditional expectation„ÄÇ

 So the expectation of a random variable R given event A is simply what you get by thinking of replacing the probability that R equals V by the probability that R equals V given a„ÄÇ

 So it's the sum over all the possible values that R might take of the probability that R takes that value given A„ÄÇ

OkayÔºå with that definitionÔºå we can state the basic form of the law of total expectation„ÄÇ

 which says if you want to calculate the expectation of R„ÄÇ

 you can split it into cases according to whether or not a occurs„ÄÇ

 It's simply the conditional expectation of R given a times the probability of a plus the conditional expectation of R given not a times the probability of not A„ÄÇ

 So it really looks has the same format as the law of total probability„ÄÇNowÔºå of course„ÄÇ

 it generalizes to many casesÔºå so the general form would say that I can calculate the expectation of R by breaking it up into the case that A1 holds times the probability of A1„ÄÇ

 the case that A2 holds times the probability of A2 through A N„ÄÇ

 and this could very well and typically is an infinite sum where the AIsÔºå of course„ÄÇ

 are a partition of the sample space„ÄÇ So they are all the different casesÔºå either A1 or A2 or a3„ÄÇ

 they're disjoint and altogetherÔºå they cover the entire set of possibilities„ÄÇWell„ÄÇ

 let's use this as to get a nice different and simpler way„ÄÇ

 more elementary way of calculating the expected number of heads and n flips„ÄÇ

 so let's let E of N be the expected number of heads in N flips just shorthand because the notation will be easy to work with then writing capital E brackets of HN„ÄÇ

So what do we know about expectation of NÔºå WellÔºå I can express it in terms of the expectation of the remaining flips„ÄÇ

 So if I if I have n flips to perform they' independent„ÄÇ Then if I perform the first flip„ÄÇ

 something happens„ÄÇ And after thatÔºå I'm going to do n more flips and the expected number of flips is going to be the expected number on the remaining n -1 plus what happened now„ÄÇ

 WellÔºå if I flip ahead firstÔºå then I've got a one as adding to my total number of heads„ÄÇ

 And then I'm going to do n more flips„ÄÇ So the expected number of flips is going to be that one plus the expected number on the rest of them„ÄÇ

If the first flip was not aheadÔºå it was a tailÔºå then the total expected number of heads is simply the expected number of heads on the rest of the flips„ÄÇ

And these are two cases where I can apply total expectation„ÄÇ So by total expectation„ÄÇ

 the expected number in n flips is1 plus E N -1 times the probability of a head plus E N -1 times the probability of a tail„ÄÇ

WellÔºå now it can do a little algebra multiply through here by P„ÄÇ That becomes a P„ÄÇ

 and this becomes a P times E N and -1„ÄÇ So I've got E N -1 times p and E N -1 times  Q„ÄÇ

 Remembering that P plus Q is 1„ÄÇ This simplifies into being simply E N -1 plus p„ÄÇWell„ÄÇ

 this is a very simple kind of recursive definition of E N„ÄÇ

 because you can see what's going to happenÔºå subtracting one from an Anze P„ÄÇSo if I subtract2 from n„ÄÇ

 I add another PÔºå I get two p and continuing all the way to the end„ÄÇ By the time I get to 0„ÄÇ

 I've gotten n times p„ÄÇ And I've just figured out what I was familiar with already„ÄÇ

 which we previously derived by differentiating the binomial theorem„ÄÇ

 the expected number of heads in n flips„ÄÇIs n times P„ÄÇ But this time„ÄÇ

 I got it in a somewhat more elementary way by appealing to total expectation„ÄÇ

We're constantly asking how long we have to wait for things and„ÄÇIn the context of probability theory„ÄÇ

 it turns into the technical question called the expected time to failure or the mean time to failure„ÄÇ

 Some examples might be that an insurance company wants to know for a given policyholder or the expected time before that policyholder dies„ÄÇ

 a mechanical engineer wants to know the expected time before a button that's being pushed once per second is expected to fail„ÄÇ

 And I want to know when the part that my body shop has been waiting for is expected to come in„ÄÇOkay„ÄÇ

The mean to failure problemÔºå we can formalize in terms of flipping coins„ÄÇ

 So we're going to flip a coin until a head comes up„ÄÇ

 and we're going to think of a head as being a failure„ÄÇ and a tail is a success„ÄÇ

So let's assume the probability of getting aheadÔºå the probability of failure is P again„ÄÇ

 this is not a fair coinÔºå it's a coin that may be biased in either direction„ÄÇ

And let's let F be the number of flips until the first head comes up„ÄÇ

 the number of flips until the first failure„ÄÇ And if we're counting as flips as time„ÄÇ

 it's the time to fail„ÄÇSo what wed like to know is what's the expectation of FÔºå what's the expected„ÄÇ

Number of flips before a head comes up„ÄÇ WellÔºå let's do someÔºå in order to calculate that expectation„ÄÇ

 we need to know some probabilities„ÄÇ So what's the probability that F equals  one„ÄÇ Well„ÄÇ

 that's the same as saying that that's getting head on the first flip„ÄÇ

 It's the probability until you get an H that you get just an H on the first flip and that has probability P„ÄÇ

What's the probability that F equals 2Ôºå WellÔºå that's the probability that you flip a tail and then a head„ÄÇ

 And that has probability Q times pÔºå because we're assuming the flips are independent„ÄÇ

 So it's the probability of a tailÔºå which is Q times the probability of a headÔºå which is p„ÄÇ

 SimilarlylyÔºå the probability of F equals 3 is the same as the probability of flipping tail tail head and its  Q squared p„ÄÇ

 AndÔºå of courseÔºå the probability density function of F„ÄÇ

 the number of steps until youd flip ahead at n„ÄÇ the probability that you have to flip n times before you get the first head is  Q to the n -1 p„ÄÇ

 By the wayÔºå a random variable with whose probability density function has is this value is called a geometric distribution„ÄÇ

 They come up all the time„ÄÇAll right„ÄÇ So what's the formula for the expectation of F„ÄÇ It's simply„ÄÇ

 of courseÔºå by definition„ÄÇ It's the expectÔºå it the sum overÔºå the possible values of F„ÄÇ

 which in this caseÔºå are integers n greater than 0 of n times the probability that F equals n„ÄÇ

 We figured out that the probability that F equals n is Q to the n -1 times p„ÄÇ

And now I'm going to observe that we really do know how to evaluate this sum easily enough„ÄÇ

 I'm going to factor out the pÔºå and it becomes a sum over n greater than 0 of q to the n -1 times n„ÄÇ

 And then I can simplify matters if I replace n by n -1„ÄÇ And then I get a  Q to the n power„ÄÇ

 So this is equivalent to p times the sum over n greater angled to 0 of n plus1 Q to the n„ÄÇ Now„ÄÇ

 this is a familiar generating function„ÄÇ It's simply equal to one over one Q squared„ÄÇ

 as we've seen already„ÄÇSo in shortÔºå the expectation of f is P times1 over the square of1 minus Q„ÄÇ

 Well so let's pull them together there„ÄÇ of courseÔºå1 minus Q is P„ÄÇ

So it's P times  one over p squared or one over P„ÄÇAnd we get this really very clean answer„ÄÇ

 The expected number of flips before you get a head is one over the probability of a head„ÄÇ So„ÄÇ

 for exampleÔºå with a fair coin where P is a halfÔºå the expected number of flips until you get the first head is 2„ÄÇ

 It's one over a half„ÄÇ If you had a biased coin where the probability of getting a head was one in three„ÄÇ

1 thirdÔºå thenÔºå in factÔºå the expected number of flips until you got a head was 3„ÄÇOkay„ÄÇThat's a nice„ÄÇ

 clean answerÔºå but we got it in this way that doesn't really give much intuition„ÄÇ

So let's look at another naive way to derive the expected time to the first head without having to worry about generating functions and all that sophisticated stuff about series„ÄÇ

 which is easy to forget„ÄÇSo let's look at the outcome tree that describes this experiment of flipping until you get the first head„ÄÇ

 so starting at the root with probability PÔºå you flip ahead immediately and you stop„ÄÇ

Or with probability QÔºå you flip a tail„ÄÇ and then with probability pay„ÄÇ

 you finally flip the head and stop„ÄÇ If you haven't flipped the head by the end of the first second step„ÄÇ

 then that is a possibility that youÔºå with probability Q„ÄÇFlip a tail„ÄÇ

 And then there's a possibility that you stop after the third step with a head and so on„ÄÇ

 That's how this tree goes„ÄÇMo„ÄÇlooking at the structure of this treeÔºå it's an infinite tree„ÄÇ

 but it's very repetitive„ÄÇ In factÔºå if we call the tree B„ÄÇ

 then what we're seeing is that this whole subtre is a copy of B„ÄÇ

 So now I have a nice recursive but very finite description of this whole infinite tree„ÄÇ

 B is a tree that has a left branch of P that that ends in a leaf or a right branch with probability Q followed by a repeat of the tree B„ÄÇ

 So now I can apply total expectation to find the expectation of F„ÄÇ

 F is the expected number of steps I make in this tree until I finally make the left branch to an H„ÄÇ

üòäÔºåHow do I figure out what the expected time in the tree is until I make that left branch of flipping ahead finally„ÄÇ

WellÔºå using total expectationÔºå what I can do is branch on whether or not the first flip is ahead„ÄÇ

So the expectation of fÔºå according to probabilityÔºå a total expectation is going to be the expectation of F given that the first flip is ahead times the probability P that it is ahead„ÄÇ

And the other term is that it's the expectation of FÔºå given that the first flip is a tail times Q„ÄÇ

 The probability that the first flip is a tail„ÄÇWellÔºå let's look atÔºå wellÔºå first of all„ÄÇ

 let's look at this term„ÄÇ What is the expected number of flips until you get ahead„ÄÇ

 given that you got ahead„ÄÇ WellÔºå it's one„ÄÇSo this term is easily taken care of if we understand that one„ÄÇ

What about this termÔºå This is the expected number of flips until you get the first tail„ÄÇÂóØ„ÄÇSorry„ÄÇ

 it's it's the expected number of flips until you get the first head„ÄÇ

 given that your first step was a tail„ÄÇ WellÔºå what that means is that we are here after the tail„ÄÇ

 and we're askingÔºå what's the expectation of FÔºå The number of flips that you get starting at B when you do one flip that takes you to the start of B again„ÄÇ

And the answer isÔºå obviouslyÔºå one plus the expected number of flips in B„ÄÇ

 which is expected expectation of F„ÄÇ In shortÔºå this termÔºå the expectation of F„ÄÇ

 given that the first flip is a T is a tail is simply one plus the expected number of flips that we're trying to figure out„ÄÇ

 NowÔºå look at this„ÄÇ I have a very simple arithmetic formula Now„ÄÇ

 expectation of F is one times P plus 1 plus F times Q„ÄÇThere it is„ÄÇ And now I can solve for E of F„ÄÇ

 WellÔºå just taking a quick look at this„ÄÇ This is going to be Q„ÄÇ This is going to yield a Q term„ÄÇ

 And p plus Q is1„ÄÇ And this is going to be Q times E of F„ÄÇ and there's an E of F there„ÄÇ

 if I pull the E of F over„ÄÇ I'm going to do a little arithmetic„ÄÇ

 I'm going to leave the rest to you and realize againÔºå that the answer is what we had before„ÄÇ

 The expectation of F is equal to1 over P„ÄÇSo let's do one more almost silly example for fun to remember what the significance of one over P is„ÄÇ

 Supp Im think about the a space station mirror„ÄÇ Now„ÄÇ

 it's spinning around and there's a lot of garbage out there that it's likely to hit a lot of space junk„ÄÇ

 And suppose that based on our previous statistics and estimations of the small sort of small stuff that has been hitting mirror that it could survive„ÄÇ

 that we estimate that there's about a one in 150000 chance that in any given hour it's going to run into some intolerable collision with with space junk or a meteor that's going to destroy it„ÄÇ

 So suppose the space station mirror has a one in 150000 chance of destruction in any given hour„ÄÇ

 So how many hours do we expect until destruction„ÄÇ WellÔºå it's one over 150000 or 150000 hoursÔºå which„ÄÇ

So much facility space station examples„ÄÇ Let's wrap up with an intuitive argument that could be made rigorous„ÄÇ

 but I'm not going to because I think it's clearer just left in this informal way that makes it intuitive why you would expect that„ÄÇ

 of courseÔºå the expected time to failure is one over the probability of failing on a given flip„ÄÇWell„ÄÇ

 how many failures do we expect in one tryÔºü WellÔºå by definition„ÄÇ

 it's the expectation of getting ahead on the first flipÔºå It's P„ÄÇOkayÔºå now if you flip n times„ÄÇ

 you expect to get„ÄÇN times as many„ÄÇFailuresÔºå as you'd expect in one try„ÄÇ

 So the expected number of fails in n tries is n times P„ÄÇ Now That's an intuitive argument„ÄÇ In fact„ÄÇ

 it's the rigorously correct argument„ÄÇ Remember that if we flip n times„ÄÇ

 We're counting the number of heads in N flips„ÄÇ That's a binomial distribution„ÄÇ

 We already figured out in a couple of ways that itss expectation is n PÔºå But never mind that„ÄÇ Oh„ÄÇ

 it's just sort ofÔºå I think it's intuitively clear that if you expect P heads in one try and you do n tries that are all independent„ÄÇ

 you're going expect to get n times P„ÄÇ failures„ÄÇ OkayÔºå or heads„ÄÇNow„ÄÇ

What's the expected number of tries between failuresÔºå WellÔºå if you think about that„ÄÇ

 I've done N tries„ÄÇAnd I've got N P failures„ÄÇ So if I divide the number of tries by the number of failures„ÄÇ

 that by definitionÔºå is the average time between the failures„ÄÇ It's the expected time to a failure„ÄÇ

 So I divide the number of tries by the number of failuresÔºå whichÔºå by definition„ÄÇ

 is the average number of tries between failuresÔºå and it's equal to N over„ÄÇAnd P„ÄÇ

 which is equal to 1 over p„ÄÇ And that's an argument that I hope you will remember„ÄÇ

So we have been saving for last the property that makes expectation calculating really easy and short circuits„ÄÇ

 a lot of the ingenious methods that we've used up until nowÔºå namelyÔºå expectation is linear„ÄÇ

So what that means is that if you have two random variablesÔºå R and S and two constants A and B„ÄÇ

 the expectation function is linear„ÄÇ That is you take a linear combination of R and SÔºå A R plus B S„ÄÇ

 and that's equal to the corresponding linear combination of the expectation„ÄÇ So I'll read it again„ÄÇ

 Expation of A R plus B S is equal to A times the expectation of R plus B times the expectation of S„ÄÇ

 expectationation is linear„ÄÇ okay„ÄÇThat's an absolutely fundamental formula that you should be comfortable with„ÄÇ

 And rememberÔºå it extends actually not only to any finite number of variables„ÄÇ

 but with some convergence conditionsÔºå it actually extends even to accountable sum of variables„ÄÇ

 But let's just settle for the two random variable case for today„ÄÇNow„ÄÇ

 the crucial thing that makes it so powerful and useful is that this fact has nothing to do with independence„ÄÇ

 whether R and S are independent or equal„ÄÇ It doesn't matter„ÄÇ This linearity holds„ÄÇ

The proof is not terribly informative„ÄÇ It's just manipulating terms and rearranging terms in a sum„ÄÇ

 but let's go through the exercise„ÄÇ againÔºå something I would never do in lecture„ÄÇ

 But in a video where you can skip it or fast forward or replay it„ÄÇ

 Ill I think it might be worth doing„ÄÇ SoÔºå and it is and it is a proofÔºå by the way„ÄÇ

 that I think you should be responsible for„ÄÇ So let's go through it„ÄÇOkay„ÄÇ

 we're interested in the expectation of the random variable that you get by multiplying the random variable A by a„ÄÇ

 little A and the random variable B by little B„ÄÇAll right„ÄÇ

By one of the definitions of expectation is that you„ÄÇ

Get this expectation at by taking the sum over all the outcomes of the value of this linear combination at the outcome omega times the probability of omega„ÄÇ

 So what's the value of the linear combinationÔºå A A plus BÔºå B at omega„ÄÇ

 It's simply a times a of omega plus B times B of omega„ÄÇOkayÔºå now I got a sum of of these terms„ÄÇ

 summing over omega„ÄÇ I can split them into two groups„ÄÇ

 I can take the sum over over the A A's at omega times probability of omega and B„ÄÇ

 B of omega times probability of omega„ÄÇ In other words„ÄÇ

 I'm multiplying through by probability of omega here to get a sum of two terms„ÄÇ

 And then I'm rearranging all of the capital A terms first followed by all the capital B terms„ÄÇ

 The result is that I wind up with the sum over omega of the a terms times the probability of omega„ÄÇ

 and I've factored out the little a plus B times the sum over all omega of B of omega times the probability of omega„ÄÇ

 It's just rearranging the terms in this sum after I've multiplied through by probability of omega„ÄÇ

WellÔºå of courseÔºå this is equal by definition to a times the expectation of a„ÄÇ

 notice this is the expectation of aÔºå and that's the expectation of B times B„ÄÇ And the proof is done„ÄÇ

Not inspiringÔºå but routine„ÄÇ If you use the alternative definition of„ÄÇ

Expectation in terms of summing over the outcomesÔºå It's a messier proof„ÄÇ

 If you have to use the definition of the expectation being the value times the probability that the variable takes that value„ÄÇ

 you wind up having to convert that formula into this formula in order to carry through the proof nicely„ÄÇ

And we're done„ÄÇOkayÔºå let's make use of it„ÄÇ And in order to do thatÔºå let's make a really trivial„ÄÇ

 but a very important remark about the expectation of an indicator variable„ÄÇ So remember„ÄÇ

 I sub a is the random variable„ÄÇ that's equal to one if the event A occurs and 0 if the event A doesn't occur„ÄÇ

 So what is the expectation of the indicator variable„ÄÇ WellÔºå by definition„ÄÇ

 it's one times the probability that it equals 1 plus 0 times the probability that it equals 0„ÄÇ

 those are the only two values it can take„ÄÇ WellÔºå we can forget this term at's 0 times something„ÄÇ

 but what is the probability that I a is equal to1„ÄÇ That's exactly the probability of a„ÄÇ

 and that's the fundamental formula that we want to notice the expectation of the indicator variable for the event a is nothing but the probability that a occurs„ÄÇ

 F that away„ÄÇ We're about to use it multiple times„ÄÇ



![](img/00b650f2b98a1e5bb437e59db93183ee_5.png)

![](img/00b650f2b98a1e5bb437e59db93183ee_6.png)

So let's go back to the expected number of heads and n flips„ÄÇ

 which we've now seen at least two ways to do one by generating function argument„ÄÇ

 another by a recursive argument using a total expectation„ÄÇ Now„ÄÇ

 we're going to knock it off very elegantly using linearity„ÄÇ

Because let H I be the indicator variable for having a head on the I flip„ÄÇ

 So we look at the eye flip„ÄÇ H is one„ÄÇ If the I flip comes up head and H of 0Ôºå if is 0„ÄÇ

 if the I flip does not come up head„ÄÇ Then we can make the following crucial remark„ÄÇ

 And this is a trick that we'll use regularly by expressing some quantity that we're interested in as a sum of indicator variables„ÄÇ

 the total number of headsÔºå the random variable equal to the total number of heads in N flips is equal to the sum of the indicator variables for whether there's a head on the first flip plus whether there's a head on the second flip up through„ÄÇ

 whether there's a head on the end flip„ÄÇSo suddenly„ÄÇ

 the random variable that I want to compute is a sum of n random variables„ÄÇ In fact„ÄÇ

 n indicator variables„ÄÇ All right„ÄÇ WellÔºå that tells me that the expectation of the number of heads is this is the expectation of this sum after it's equal to the sum„ÄÇ

 But the expectation of the sum is going to be the sum of the expectation by linearity„ÄÇ

 So it's simply the expectation of H1 plus the expectation of H2 out through the expectation of H N„ÄÇ

But what's the expectation of getting a head on the eye flipÔºå or the flips are independent„ÄÇ

 It's simply the expectation of a head„ÄÇ So what I have is each of these is equal to the probability of a head„ÄÇ

 and there is n of them„ÄÇ So the total is n times the probability of head or N P„ÄÇ

 which is a formula that we had derived two other ways previously„ÄÇ

 And now it really falls out very elegantly with hardly any ingenuity„ÄÇ

 other than the wonderful idea of expressing the number of heads as a sum of indicators„ÄÇ

Let's look at or one related one example in a very related example of asking about the probability of the expected number of hats that are returned when N men check their hats at a hat check at a hat check and then the hats get all scrambled up by incompetent staff so that and they're given out again and in such a way that the probability that the Ithe man gets his own hat back is one over n„ÄÇ

 What you could say is that all possible permutations of the n hats are equally likely and we ask among with all permutations equally likely how many of them is it the case that the Ithe man gets his own hat back and there's a one out of n chance that the I man is going to get his own hat back because there's N hats and he's equally likely to get all of them„ÄÇ

ÂóØ„ÄÇHow many men do we expect will get their hat back in this setting„ÄÇ Well„ÄÇ

 let's let R I be the indicator variable for whether or not the Ithe man got his hat returned„ÄÇ

 R I for hat returned to the Ethe man„ÄÇNowÔºå notice that R I and R J are not independent„ÄÇ

 In the previous caseÔºå those H's were independent because the coin flips were independent„ÄÇ But here„ÄÇ

 if I knowÔºå for exampleÔºå that R1 got his hat backÔºå the probability that R 2 got his hat back has changed from1 over n to1 over n -1„ÄÇ

 because1 is out of the picture„ÄÇ and R 2 is going to get his hat back among the remaining hats2 through N2 through n is n -1 of them„ÄÇ

 and he's got a11 over n-1 chance of getting his hat„ÄÇ His probability is changed„ÄÇ

 given that R 1 got his hat back„ÄÇ So they're not independent„ÄÇAll right„ÄÇ NeverthelessÔºå independence„ÄÇ

 it doesn't matter for linearity„ÄÇ So I can still say that the expected number of hats returned is equal to the expectation of the sum of the indicator variables for each man getting his hat back„ÄÇ

AndÔºå of courseÔºå theÔºå the the expectation of that sum is the sum of the expectations and the expectation of each of these we figured out was one over n„ÄÇ

 and there's n of them„ÄÇ So it's n times one over n or one„ÄÇ

I expect when all the hats are scrambled and all permutations of the hats are equally likely that one man is going to get his hat back„ÄÇ

 and none of the others will„ÄÇOkayÔºå now let's change the situation a little bit and think instead of scrambling the hats in a way that all possible permutations of hats are equally likely„ÄÇ

 let's think about a Chinese banquet„ÄÇ So Chinese banquets are traditionally done with a table of 9 in a circle„ÄÇ

 and there's a lazy Susan that spins around where there's dishes of food in front of each person„ÄÇ

 But let's generalize it to N„ÄÇ Suppose that end people are sitting around a spinning table„ÄÇ

 a lazy Susan with n different dishesÔºå one dish in front of each person„ÄÇ

 And now we spin the lazy Susan randomly„ÄÇüòäÔºåAnd we ask„ÄÇ

 how many people do we expect will wind up with the same dish that they started with after the spin„ÄÇ

WellÔºå now we can let our I indicate that the artÔºå the Ih person got the same dish back„ÄÇAnd now„ÄÇ

 these RsÔºå which are different from the previous ones about hat returns„ÄÇ

 These Rs are totally dependentÔºå much more so than the other ones were„ÄÇ

 because they're all one or they're all 0„ÄÇ If one person gets their hat back„ÄÇ

 It means that the spin the spinning table got back to where it used to be and everybody has their hat back„ÄÇ

 And if one person doesn't have their hat backÔºå then the table is shifted off where it was originally„ÄÇ

 and and nobody has their dishÔºå the original dish„ÄÇ I said Has I met the dish that they started with„ÄÇ

 So everybody gets the same dish back or nobody gets the same dish back„ÄÇ

 these variables are as dependent as they possibly could be„ÄÇ but it doesn't matter„ÄÇ

 because linearity still holds„ÄÇAnd that means that the previous argument about the expected number of people or the expected number of dishes that get back to the person that they started with is still one„ÄÇ

 even though all the Rs are equal„ÄÇWellÔºå that's so much for the lovely rule about linearity of expectation„ÄÇ

 which holdsÔºå regardless of assumptions about independence or notÔºå there is a rule for products„ÄÇ

 but it requires independent„ÄÇ So the independent product rule says sure enough that the expectation of a product of two random variables X and Y is the expectation is the product of their expectation„ÄÇ

 Pro that they are independent„ÄÇ And this extends to many variables if they are mutually independent„ÄÇ

AgainÔºå the proof is by rearranging terms in the defining sum for the expectation of XÔºå Y„ÄÇ

 Let's go through it„ÄÇ And againÔºå you can fast forward or skip this part if you don't want to watch equations being manipulated„ÄÇ

 So by definitionÔºå the expectation of the product X„ÄÇ

 Y is the sum over all the possible values of X and Y„ÄÇ of the value of the product X„ÄÇ

 Y times the probability that the first variable X„ÄÇ

 capital X equals little X and the second variable Y is equal to little Y„ÄÇ This is the„ÄÇ

 by definition the expectation of the product by the first definition„ÄÇ

Not the one in terms of outcomes„ÄÇ NowÔºå using independence„ÄÇ

 this term here can be split to a product of x equals x and y equals y„ÄÇ So let's do that„ÄÇ

 So this is the sum of x Y times the probability that x equals x times the probability that y equals Y„ÄÇ

 NowÔºå I'm going to do a fairly standard trickÔºå which is„ÄÇ

 I'm going to organize this sum in a clean way„ÄÇ right now„ÄÇ

 it's an unordered sum over all possible pairs of x and y in in the range of of the variables x and y„ÄÇ

 So I'm going do the sum„ÄÇ So I first sum over all the y's„ÄÇ And then for each y„ÄÇ

 I'm going sum over all the x's„ÄÇ So this is tantem„ÄÇ this is an unordered sumÔºå really„ÄÇ

 there theres no order here„ÄÇ But now I'm giving you an arrangement„ÄÇ

 which says that I'm going lump together the sums over all the x's„ÄÇ And then for each of those„ÄÇ

 I'm going sum up over the Y's„ÄÇWellÔºå when I do it this way„ÄÇ

 what I've got is that interesting thing here„ÄÇ I've got a sum over x„ÄÇ

 and there's some y terms here that don't depend on x„ÄÇ

 I can factor them out because they don't change with X„ÄÇ

 So if I factor out this y and probability of y equals Y„ÄÇ

 I wind up with the sum over Y of this factored out term„ÄÇ

 Y times probability Y equals y times the sum over x is of x times the probability that x equals x„ÄÇüòä„ÄÇ

NowÔºå this is the same term that is the coefficient of every one of these Y terms that depends on why„ÄÇ

 and this term does not depend on why„ÄÇ so I can factor it out„ÄÇAnd if I do that„ÄÇ

 I wind up with the sum over x's of x times the probability that x equals x times the sum over y of y times the probability that y equals y„ÄÇ

 And guess whatÔºå this is by definitionÔºå the expectation of x„ÄÇ and this isÔºå by definition„ÄÇ

 the expectation of Y„ÄÇ And by that chain of equalities I've proved sure enough that the expectation of x„ÄÇ

 Y is equal to the expectation of x times the expectation of Y„ÄÇ Q E D„ÄÇ

 So the key step here was where independence was used at the very first step„ÄÇ

 When I split up the probability that x equaled x and y equals Y into the product of the corresponding probabilities„ÄÇ

NowÔºå let me just end with a warning about a couple of blunders that people make all the time„ÄÇ So„ÄÇ

 first of allÔºå don't forget independence as as a crucial condition on the product rule for expectations„ÄÇ

 It can hold in some cases where the variables are dependent„ÄÇ In is not a necessary condition„ÄÇ

 It's sufficient„ÄÇ but you need some kind of a condition that in order for the product rule to hold„ÄÇ

 So if you're not careful that won'tÔºå if you forget to check for independence or something that it's tantamount to it„ÄÇ

 So let's just take an easy example to remember what happens if independence fails„ÄÇ

 supposeuppose I have a variableÔºå xÔºå a random variable x„ÄÇ

 which takes positive and negative values with equal probability„ÄÇ

 So it it takes one and minus-1 with equal probability„ÄÇ

 It takes pi and minus pi with equal probabilityÔºå I don't really care what those values are as long as it's taking some positive and negative values„ÄÇ

 and it takes a positive value with the same probability that it takes that value negated„ÄÇWell„ÄÇ

 that automatically means that the expectation of x is 0 because when I add up all these terms„ÄÇ

 the positive and negative terms cancel because they have the same probability„ÄÇ

 So any such x thats symmetric about0 has expectation 0„ÄÇOn the other handÔºå if I square x„ÄÇ

 then all of those positive and negative terms of values become positive„ÄÇ

 and so I'm taking the expectation of a variable that's strictly positive„ÄÇ

 at least with nonzero probability at a bunch of outcomes„ÄÇ

 and therefore the expectation of x squared is positive„ÄÇüòäÔºåSo the expectation of x is 0„ÄÇ

 but the expectation of x squared is positive„ÄÇ of course„ÄÇ

 if I multiply expectation of x times expectation of xÔºå that's still0„ÄÇ

 So here's a counter exampleamp„ÄÇ expectation of x times expectation of x is equal to 0„ÄÇ

 which is less than the expectation of the square of x„ÄÇ Of course„ÄÇ

 this is about as dependent as it could possibly be because it's the same random variable„ÄÇ

 but it illustrates the failure of the product rule when if you don't have some kind of a condition like independence around„ÄÇ

There's a second blunder that's more interesting„ÄÇ and that people can fall in because there's a temptation to assume that if the product rule holds for independence„ÄÇ

 then so should the reciprocal ruleÔºå that isÔºå you might think that the expectation of x over Y is equal to the expectation of x over the expectation of y when x and y are independent„ÄÇ

 but it's not true„ÄÇ even when they're independentÔºå the expectation of x divided by y is in general„ÄÇ

 not equal to the expectation of x divided by the expectation of yÔºå In fact„ÄÇ

 the counter example is if x is the constant one„ÄÇ the expectation of one over y„ÄÇ

Sisk complex instruction set code was better than risk„ÄÇ So I won't mention names„ÄÇ

 but prominent people have made this blunder„ÄÇ You shouldn't„ÄÇ



![](img/00b650f2b98a1e5bb437e59db93183ee_8.png)