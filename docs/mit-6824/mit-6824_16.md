# Facebook 上的 Memcache

# 6.824 2015 年第 16 讲：Facebook 上的 Memcache

**注意：** 这些讲义笔记是从 2015 年春季的 6.824 [课程网站](http://nil.csail.mit.edu/6.824/2015/schedule.html) 上稍作修改的。

## 介绍

Facebook Memcached 论文：

+   一个经验论文，而不是研究结果论文

+   你可以将其视为一篇胜利的论文。

+   你可以将其视为一篇警示论文：当你不考虑可扩展性时会发生什么。

+   你可以将其视为一篇权衡的论文。

## 扩展一个 Web 应用程序。

任何 Web 应用程序的初始设计都是一个单个 Web 服务器机器，其中运行一个数据库服务器。

图表（单台机器：Web 服务器和数据库服务器）

```
Single machine
-------------------
| Web app         |
|                 | 
|                 |
|                 |
|       | DB | <-----> |Disk|
------------------ 
```

+   最终他们发现他们在这台机器上使用了 100% 的 CPU。

+   `top` 告诉他们 CPU 时间正流向 Web 应用程序

图表（多个 Web 服务器机器，单个数据库机器）：

```
Web app -----
Web app      \ -----> |DB| <-> Disk
...
Web app 
```

+   接下来他们将面临的下一个问题是数据库将成为瓶颈

    +   数据库 CPU 是 100% 或磁盘是 100%

+   他们决定购买一堆数据库服务器

图表：

```
Web app             |DB1| <-> Disk  (users A-M)
Web app             |DB2| <-> Disk  (users N-T)
...                 |DB3| <-> Disk  ...
Web app             ... 
```

+   现在他们得想办法如何在数据库上 *分片* 数据

+   现在应用软件必须知道要与哪个数据库服务器通信。

+   我们不能再跨整个数据库进行事务了。

+   我们不能再对整个数据集进行单个查询了。

    +   需要向每个服务器发送单独的查询。

+   你不能把这一点推得太远，因为过了一段时间，分片会变得非常小，你会得到成为热点的数据库服务器

接下来，你注意到数据库中的大多数操作都是读取操作（如果是这样的话。在 Facebook 上是这样的）。

+   原来你可以构建一个非常简单的内存缓存，可以每秒服务五十万个请求。

+   然后你可以减少数据库上的 90% 的负载。

图表：

```
Web app -> |MC| --> |DB1| <-> Disk  (users A-M)
Web app    |MC|     |DB2| <-> Disk  (users N-T)
...         ..      |DB3| <-> Disk  ...
Web app             ... 
```

+   如果你不断扩展你的服务，下一个瓶颈将是数据库写入。

观察：你可以使用数据库只读副本，而不是自己定制的 memcache（MC）节点。Facebook 没有这样做，因为他们想将缓存逻辑与数据库部署分开：

> 这是在有限的工程资源和时间内做出的最佳选择。此外，将缓存层与持久性层分开允许我们根据工作负载的变化分别调整每个层。

## Facebook 的用例

**非常重要：** 他们并不太在意所有用户对系统的一致视图。

当 Web 应用程序客户端读取自己的写入时，唯一关心新鲜度和一致性的情况。

他们的高层次图片：

```
Regions (data centers):
    Master region (writable)
   ----------------- 
  | Web1 Web2 ...   |
  | MC1  MC2  ...   |
  | DB1  DB2  ... <--- complete copy of all data
   -----------------

    Slave regions (read only)
   ----------------- 
  | Web1 Web2 ...   |
  | MC1  MC2  ...   |
  | DB1  DB2  ... <--- complete copy of all data
   ----------------- 
```

拥有多个数据中心的原因：全球范围内的并行性

+   也许也是为了备份目的（论文没有详细说明太多）。

## 大的教训

### 边缘缓存可能会棘手

这种看到缓存中有什么的边缘缓存样式对于现有系统非常容易添加。

+   但是当缓存层不知道数据库中发生的情况时，会出现一些讨厌的一致性问题。

### 缓存是关于吞吐量而不是延迟的。

这不是为了减少用户的延迟。他们使用缓存来增加吞吐量并减轻数据库的负载。

+   数据库无法处理负载，负载是数据库可以访问的 10 倍或 100 倍

### 他们可以容忍过时的数据

### 他们希望能够读取自己的写入

你可能认为这可以很容易地在应用程序中修复。有点惊讶的是，这并没有通过应用程序记住写入来修复。不清楚为什么他们以不同的方式解决了这个问题。

### 最终一致性已经足够好了

### 他们有巨大的扇出

他们提供的每个网页可能会生成数百次读取。有点令人惊讶。所以他们必须做一些技巧。并行发出读取请求。当单个服务器这样做时，它会收到一堆响应，交换机和 web 服务器中的缓冲区限制有限，因此如果他们不小心，他们可能会丢失数据包，从而在重试时降低性能。

## 性能

+   论文中有很多关于一致性的内容

+   但实际上他们迫切需要性能，这导致了一些技巧，也导致了一致性问题

+   性能来自于能够并行提供大量的`Get`请求

实际上只有两种策略：

+   分区数据

+   复制数据

+   他们两者都使用

如果键大致都一样受欢迎，分区就有效。否则，某些分区会更受欢迎并导致热点。复制有助于处理受欢迎键的需求。此外，复制有助于来自世界各地的请求。

你不能简单地在 web 应用程序服务器中缓存键，因为它们会很快填满内存，而且会重复存储大量数据。

## 他们处理的具体问题

每个集群都有一整套 memcache 服务器和一整套 web 服务器。每个 web 服务器都与其自己集群中的 memcache 服务器通信。

### 添加一个新的集群

有时，他们想要添加一个新的集群，这显然会有空的 memcache 服务器。

+   新集群中的所有 web 服务器在每个请求上都会缺失，并且必须关闭并联系数据库，而数据库无法处理增加的负载

+   新集群不会联系数据库，而是会联系其他集群的 memcache 服务器，直到新集群的缓存被预热

**问：** 添加新集群会给他们带来什么好处？而不是增加现有集群的大小？

+   一个可能性是有一些非常受欢迎的键，因此过度分区一个集群对此没有帮助

+   另一个可能性是通过添加新集群更容易添加更多的 memcache 服务器，因为数据移动问题

### Memcache 服务器宕机

如果一个 memcache 服务器宕机，请求将被重定向到一个沟槽服务器。沟槽机器最初会错过很多，但至少它会为未来缓存结果。

### 作业问题：

**问：** 为什么写入时不使沟槽失效？

在写入时，数据库通常会向所有可能拥有该键的内存缓存服务器发送使其无效的消息。因此，大量的删除消息被发送到大量的内存缓存服务器。也许他们不想用所有的删除消息淹没槽沟服务器。

注意，槽沟键会在一定时间后过期，以应对键永远不变的情况。

如果槽沟服务器崩溃，会发生什么并不清楚。

**问：** 如果数据库服务器发送新值而不是使其无效，会不会更好。

+   在内存缓存中缓存的内容可能不是数据库值，而可能是数据库值的某些函数，数据库层不知道。

    +   思考一下朋友列表在数据库中是如何存储的，与在内存缓存中是如何存储的。

### 针对雷鸣般的奔袭的租约

一个客户端向数据库发送更新请求，并使一个热门键失效。因此现在有很多客户端向内存缓存生成获取请求，但该键已被删除，这将导致大量的数据库查询，然后是大量的结果缓存。

如果内存缓存收到一个未找到的键的获取请求，它将在该键上设置一个租约，并说“你可以去询问数据库这个键，但请在 10 秒内完成。”当后续的获取请求到达时，它们会被告知“没有这样的键，但有另一个人正在获取它，所以请等待他而不是查询数据库”。

租约在 10 秒后或所有者设置键之后取消。

每个集群将生成一个单独的租约。

# 6.824 笔记

```
Scaling Memcache at Facebook, by Nishtala et al, NSDI 2013

why are we reading this paper?
  it's an experience paper, not about new ideas/techniques
  three ways to read it:
    cautionary tale of problems from not taking consistency seriously
    impressive story of super high capacity from mostly-off-the-shelf s/w
    fundamental struggle between performance and consistency
  we can argue with their design, but not their success

how do web sites scale up with growing load?
  a typical story of evolution over time:
  1\. one machine, web server, application, DB
     DB stores on disk, crash recovery, transactions, SQL
     application queries DB, formats, HTML, &c
     but the load grows, your PHP application takes too much CPU time
  2\. many web FEs, one shared DB
     an easy change, since web server + app already separate from storage
     FEs are stateless, all sharing (and concurrency control) via DB
     but the load grows; add more FEs; soon single DB server is bottleneck
  3\. many web FEs, data sharded over cluster of DBs
     partition data by key over the DBs
       app looks at key (e.g. user), chooses the right DB
     good DB parallelism if no data is super-popular
     painful -- cross-shard transactions and queries probably don't work
       hard to partition too finely
     but DBs are slow, even for reads, why not cache read requests?
  4\. many web FEs, many caches for reads, many DBs for writes
     cost-effective b/c read-heavy and memcached 10x faster than a DB
       memcached just an in-memory hash table, very simple
     complex b/c DB and memcacheds can get out of sync
     (next bottleneck will be DB writes -- hard to solve)

the big facebook infrastructure picture
  lots of users, friend lists, status, posts, likes, photos
    fresh/consistent data apparently not critical
    because humans are tolerant?
  high load: billions of operations per second
    that's 10,000x the throughput of one DB server
  multiple data centers (at least west and east coast)
  each data center -- "region":
    "real" data sharded over MySQL DBs
    memcached layer (mc)
    web servers (clients of memcached)
  each data center's DBs contain full replica
  west coast is master, others are slaves via MySQL async log replication

how do FB apps use mc?
  read:
    v = get(k) (computes hash(k) to choose mc server)
    if v is nil {
      v = fetch from DB
      set(k, v)
    }
  write:
    v = new value
    send k,v to DB
    delete(k)
  application determines relationship of mc to DB
    mc doesn't know anything about DB
  FB uses mc as a "look-aside" cache
    real data is in the DB
    cached value (if any) should be same as DB

what does FB store in mc?
  paper does not say
  maybe userID -> name; userID -> friend list; postID -> text; URL -> likes
  basically copies of data from DB

paper lessons:
  look-aside is much trickier than it looks -- consistency
    paper is trying to integrate mutually-oblivious storage layers
  cache is critical:
    not really about reducing user-visible delay
    mostly about surviving huge load!
    cache misses and failures can create intolerable DB load
  they can tolerate modest staleness: no freshness guarantee
  stale data nevertheless a big headache
    want to avoid unbounded staleness (e.g. missing a delete() entirely)
    want read-your-own-writes
    each performance fix brings a new source of staleness
  huge "fan-out" => parallel fetch, in-cast congestion

let's talk about performance first
  majority of paper is about avoiding stale data
  but staleness only arose from performance design

performance comes from parallel get()s by many mc servers
  driven by parallel processing of HTTP requests by many web servers
  two basic parallel strategies for storage: partition vs replication

will partition or replication yield most mc throughput?
  partition: server i, key k -> mc server hash(k)
  replicate: server i, key k -> mc server hash(i)
  partition is more memory efficient (one copy of each k/v)
  partition works well if no key is very popular
  partition forces each web server to talk to many mc servers (overhead)
  replication works better if a few keys are very popular

performance and regions (Section 5)

Q: what is the point of regions -- multiple complete replicas?
   lower RTT to users (east coast, west coast)
   parallel reads of popular data due to replication
   (note DB replicas help only read performance, no write performance)
   maybe hot replica for main site failure?

Q: why not partition users over regions?
   i.e. why not east-coast users' data in east-coast region, &c
   social net -> not much locality
   very different from e.g. e-mail

Q: why OK performance despite all writes forced to go to the master region?
   writes would need to be sent to all regions anyway -- replicas
   users probably wait for round-trip to update DB in master region
     only 100ms, not so bad
   users do not wait for all effects of writes to finish
     i.e. for all stale cached values to be deleted

performance within a region (Section 4)

multiple mc clusters *within* each region
  cluster == complete set of mc cache servers
    i.e. a replica, at least of cached data

why multiple clusters per region?
  why not add more and more mc servers to a single cluster?
  1\. adding mc servers to cluster doesn't help single popular keys
     replicating (one copy per cluster) does help
  2\. more mcs in cluster -> each client req talks to more servers
     and more in-cast congestion at requesting web servers
     client requests fetch 20 to 500 keys! over many mc servers
     MUST request them in parallel (otherwise total latency too large)
     so all replies come back at the same time
     network switches, NIC run out of buffers
  3\. hard to build network for single big cluster
     uniform client/server access
     so cross-section b/w must be large -- expensive
     two clusters -> 1/2 the cross-section b/w

but -- replicating is a waste of RAM for less-popular items
  "regional pool" shared by all clusters
  unpopular objects (no need for many copies)
  decided by *type* of object
  frees RAM to replicate more popular objects

bringing up new mc cluster was a serious performance problem
  new cluster has 0% hit rate
  if clients use it, will generate big spike in DB load
    if ordinarily 1% miss rate, and (let's say) 2 clusters,
      adding "cold" third cluster will causes misses for 33% of ops.
    i.e. 30x spike in DB load!
  thus the clients of new cluster first get() from existing cluster (4.3)
    and set() into new cluster
    basically lazy copy of existing cluster to new cluster
  better 2x load on existing cluster than 30x load on DB

important practical networking problems:
  n² TCP connections is too much state
    thus UDP for client get()s
  UDP is not reliable or ordered
    thus TCP for client set()s
    and mcrouter to reduce n in n²
  small request per packet is not efficient (for TCP or UDP)
    per-packet overhead (interrupt &c) is too high
    thus mcrouter batches many requests into each packet

mc server failure?
  can't have DB servers handle the misses -- too much load
  can't shift load to one other mc server -- too much
  can't re-partition all data -- time consuming
  Gutter -- pool of idle servers, clients only use after mc server fails

The Question:
  why don't clients send invalidates to Gutter servers?
  my guess: would double delete() traffic
    and send too many delete()s to small gutter pool
    since any key might be in the gutter pool

thundering herd
  one client updates DB and delete()s a key
  lots of clients get() but miss
    they all fetch from DB
    they all set()
  not good: needless DB load
  mc gives just the first missing client a "lease"
    lease = permission to refresh from DB
    mc tells others "try get() again in a few milliseconds"
  effect: only one client reads the DB and does set()
    others re-try get() later and hopefully hit

let's talk about consistency now

the big truth
  hard to get both consistency (== freshness) and performance
  performance for reads = many copies
  many copies = hard to keep them equal

what is their consistency goal?
  *not* read sees latest write
    since not guaranteed across clusters
  more like "not more than a few seconds stale"
    i.e. eventual
  *and* writers see their own writes
    read-your-own-writes is a big driving force

first, how are DB replicas kept consistent across regions?
  one region is master
  master DBs distribute log of updates to DBs in slave regions
  slave DBs apply
  slave DBs are complete replicas (not caches)
  DB replication delay can be considerable (many seconds)

how do we feel about the consistency of the DB replication scheme?
  good: eventual consistency, b/c single ordered write stream
  bad: longish replication delay -> stale reads

how do they keep mc content consistent w/ DB content?
  1\. DBs send invalidates (delete()s) to all mc servers that might cache
     + Do they wait for ACK? I'm guessing no.
  2\. writing client also invalidates mc in local cluster
     for read-your-writes

why did they have consistency problems in mc?
  client code to copy DB to mc wasn't atomic:
    1\. writes: DB update ... mc delete()
    2\. read miss: DB read ... mc set()
  so *concurrent* clients had races

what were the races and fixes?

Race 1: one client's cached get(k) replaces another client's updated k
  k not in cache
  C1: MC::get(k), misses
  C1: v = read k from DB
    C2: updates k in DB
    C2: and DB calls MC::delete(k) -- k is not cached, so does nothing
  C1: set(k, v)
  now mc has stale data, delete(k) has already happened
  will stay stale indefinitely, until key is next written
  solved with leases -- C1 gets a lease, but C2's delete() invalidates lease,
    so mc ignores C1's set
    key still missing, so next reader will refresh it from DB

Race 2: updating(k) in cold cluster, but getting stale k from warm cluster 
  during cold cluster warm-up
  remember clients try get() in warm cluster, copy to cold cluster
  k starts with value v1
  C1: updates k to v2 in DB
  C1: delete(k) -- in cold cluster
  C2: get(k), miss -- in cold cluster
  C2: v1 = get(k) from warm cluster, hits
  C2: set(k, v1) into cold cluster
  now mc has stale v1, but delete() has already happened
    will stay stale indefinitely, until key is next written
  solved with two-second hold-off, just used on cold clusters
    after C1 delete(), cold ignores set()s for two seconds
    by then, delete() will propagate via DB to warm cluster

Race 3: writing to master region, but reading stale from local
  k starts with value v1
  C1: is in a slave region
  C1: updates k=v2 in master DB
  C1: delete(k) -- local region
  C1: get(k), miss
  C1: read local DB  -- sees v1, not v2!
  later, v2 arrives from master DB
  solved by "remote mark"
    C1 delete() marks key "remote"
    get()/miss yields "remote"
      tells C1 to read from *master* region
    "remote" cleared when new data arrives from master region

Q: aren't all these problems caused by clients copying DB data to mc?
   why not instead have DB send new values to mc, so clients only read mc?
     then there would be no racing client updates &c, just ordered writes
A:
  1\. DB doesn't generally know how to compute values for mc
     generally client app code computes them from DB results,
       i.e. mc content is often not simply a literal DB record
  2\. would increase read-your-own writes delay
  3\. DB doesn't know what's cached, would end up sending lots
     of values for keys that aren't cached

PNUTS does take this alternate approach of master-updates-all-copies

FB/mc lessons for storage system designers?
  cache is vital to throughput survival, not just a latency tweak
  need flexible tools for controlling partition vs replication
  need better ideas for integrating storage layers with consistency 
```
