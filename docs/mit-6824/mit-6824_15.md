# Spanner

# 6.824 2015 年第 15 讲 Spanner

**注意：**这些讲座笔记略有修改，来源于 2015 年春季 6.824 [课程网站](http://nil.csail.mit.edu/6.824/2015/schedule.html)上发布的内容。

## 介绍

[Spanner 论文，OSDI 2012](http://research.google.com/archive/spanner.html)

+   打破了旧的假设：不能假设时钟紧密同步

    +   在全球范围内的分布式系统中，紧密同步的时钟现在是可行的：GPS 和原子钟作为独立的来源

+   *数据模型：*不可变版本化数据

+   在多个数据中心构建和部署系统

+   Paxos 帮助您确定事件顺序。为什么我们仍然需要时间？

+   使用同步时间允许本地读取而无需锁定

+   在复制之上的事务

    +   跨多个副本组的两阶段提交

+   并发控制

    +   严格的两阶段锁定与时间戳

+   Paxos

    +   长寿领导者（定时租约）

    +   流水线（多个提案在飞行中）

    +   无序提交，有序应用

## Spanner 和“研究”

+   团队中充满了博士学位的人

+   当我们有冲动并且有话要说时，我们会写研究论文

+   尖端开发，令人难以置信的规模，但我们不是研究人员

## 历史背景

[Bigtable 论文，OSDI 2006](http://research.google.com/archive/bigtable.html)

+   2003 年底开始开发（6 位博士）

+   第一个客户于 2005 年中期启动了 Bigtable

+   分布式键值存储

    +   单行事务

    +   后来添加了延迟复制

+   价值主张

    +   扩展到大量数据

    +   自动重新分片

+   Bigtable 是“NoSQL”的鼻祖之一，或者更准确地说是“如何在不构建数据库的情况下存储大量数据”的鼻祖之一

+   当时的基本原则（Bigtable 的设计假设）：

    +   谁需要数据库？键值存储就足够了

    +   谁需要 SQL？对大多数应用程序来说是不必要的

    +   谁需要事务？两阶段提交太昂贵

## 为什么选择 Spanner？

+   发现 Bigtable 太难使用

    +   用户喜欢 SQL 数据库给他们带来的强大功能

    +   工程师不应该被迫绕过

        +   缺乏事务

        +   由于延迟复制提供的弱语义而显现出的错误

    +   程序员的生产力很重要

Megastore，约 2006 年开始，建立在 Bigtable 之上

+   乐观并发控制

+   基于 Paxos 的复制

    +   没有长寿领导者（每次写入都进行 Paxos“选举”）

    +   每个 Paxos 消息都写入 Bigtable

+   比 Bigtable 更广泛的事务类

+   类似 SQL 的模式和查询语言

+   具有一致复制

Dremel，Google 的数据分析，约 2008 年开始

+   列向存储和查询引擎

+   [`research.google.com/pubs/pub36632.html`](http://research.google.com/pubs/pub36632.html)

+   因为它允许 SQL 而受欢迎

## 事务

[Percolator，通用事务](http://research.google.com/pubs/pub36726.html)

+   快照隔离：普通事务有一个提交点（逻辑上，当您提交时，一切都发生了）

    +   待办事项：查找这意味着什么，因为我无法记下他的解释

+   建立在 Bigtable 之上

+   用户要求事务，但我们还没有准备好将其构建到 bigtable 中

## Spanner

+   我们知道我们需要

    +   一个数据库

    +   SQL

    +   数据中心之间的一致复制

    +   通用事务

+   其余的只是“纯粹的工程”

TrueTime 出现了...（关于他们如何发现纽约有人在研究分布式时钟，他们意识到这对于他们的并发控制可能有用的故事）

## 全球同步时钟

+   spanner 的行为就像单机数据库

    +   一致的复制：副本都报告相同的状态

    +   外部一致性：副本都报告相同的事件顺序

+   良好的语义

## 我们对 bigtable 错了吗

是的，也不是：

+   是的，对于长期来说是的：2003 年不知道 2009 年所知道的，没有人员或技术

+   不，因为很多人在 Google 使用 bigtable

想象你正在经营一家初创公司。哪些长期问题可以推迟解决？

初创公司困境：

+   太多时间花在可扩展存储上 => 浪费的努力 => 未能按时完成 => 失败

+   在可扩展存储上花费太少时间 => 当他们变得受欢迎时无法扩展 => 失败

你有能力/意愿/愿景做什么？

+   10 年前我们无法构建 Spanner：甚至 5 年前也不行

+   有人告诉他们应该内置事务，但他们没有这样做，因为当时他们无法做到

## 有趣的问题

为什么 Bigtable 论文在研究界和技术界都产生了更大的影响？

+   研究与实践

为什么系统研究人员坚持构建可扩展的键值存储（而不是数据库）？

## 教训

### 第零课

时机是一切。除非运气胜过时机。

当世界正在变化时，你无法计划时机：为你面前的问题设计最好的解决方案

TrueTime 的发生是由于事件和人的幸运巧合（即运气）。Bigtable 也是如此。Spanner 的初始设计（2008 年之前）与 Google 现在拥有的完全不同：直到项目在 2008 年重新启动之前，他们一直在反运气。

### 第一课

构建你需要的东西，不要设计过度。也不要设计不足，因为你会为此付出代价。

### 第二课

有时无知真的是福。或者可能是运气。

如果你戴着眼罩，你就无法超越。如果我们在 2004 年就知道我们需要一个具有外部一致性的分布式复制数据库，我们就会失败。

### 第三课

你的用户群很重要。

+   当 Google `< 2000`名员工时，bigtable 就开始了

    +   有限的产品数量

    +   工程师并不多

+   当 Google 有`10K`名员工时，spanner 就开始了

    +   更多的产品

    +   更多的工程师，更多的初级工程师，更多的收购公司

+   员工的生产力很重要

### 总结

你无法购买运气。你无法计划运气。但你不能忽视运气。

你可以增加自己幸运的机会：

+   具备强大的技术技能

+   锻炼你的设计感（找到学习的机会！）

+   建立一个强大的同事和朋友网络

+   学会如何在团队中工作

+   学会你擅长什么，以及你*不*擅长什么

    +   对自己要毫无保留地诚实

    +   愿意寻求帮助

    +   承认当你错了

    +   人们不喜欢与经常告诉他们错误的人合作

## Spanner 缺少什么？

可能的断开连接访问：我们能否构建可以使用数据库并能脱机运行的应用程序？

[Coda 文件系统中的断开操作](https://www.cs.berkeley.edu/~brewer/cs262b/Coda-TOCS.pdf)工作。

# 6.824 笔记

Spanner：谷歌的全球分布式数据库，Corbett 等人，OSDI 2012

为什么选择这篇论文？

+   现代化、高性能、受现实需求驱动

+   Paxos 的复杂使用

+   解决一致性 + 性能（将是一个重要主题）

+   Lab 4 是 Spanner 的（极大地）简化版本

有哪些重要的想法？

+   使用 Paxos 复制的分片管理

+   尽管进行同步的广域网复制，仍然保持高性能

+   通过**仅询问最近的复制品**来快速读取

+   尽管进行分片（这是真正的重点）仍然保持一致性

+   **巧妙使用时间**来保持一致性

+   分布式事务

这是一篇深奥的论文！我试图将一些想法简化成更简单的形式。

## 分片

思路：分片

+   我们以前在 FDS 中见过这种情况

+   真正的问题是管理配置更改

+   Spanner 对此的设计比 FDS 更有说服力

简化的分片轮廓（实验 4）：

+   复制组，Paxos 复制

    +   每个复制组中都有 Paxos 日志

+   主节点，Paxos 复制

    +   将分片分配给组

    +   编号配置

+   如果主节点移动了一个分片，组最终会看到新的配置

    +   在两个组的 Paxos 日志中都有 `"start handoff Num=7"` 操作

    +   尽管可能不是同时进行的

+   `dst` 在获得多数派的片段数据副本之前无法完成移交

    +   并且不能长时间等待可能失败的少数派

    +   少数派必须赶上，所以也许将分片数据放入 Paxos 日志中（！）

+   在两个组的日志中都有 `"end handoff Num=7"` 操作

**问：**如果一个 Put 操作与移交同时发生会怎样？

+   客户端看到新的配置，在移交开始前将其发送到新组？

+   客户端具有陈旧的视图，并在移交后将其发送到旧的组？

+   在移交期间到达任何一个？

**问：**如果移交期间发生故障？

+   例如，旧的组认为分片已移交

    +   但新组在它认为如此之前失败了

**问：** *两个* 组可以认为它们正在提供分片吗？

**问：**如果旧的组无法听到主节点，是否仍然可以提供分片？

**思路：**广域同步复制

+   *目标：*在单一站点灾难中生存

+   *目标：*靠近客户的复制品

+   *目标：*不要丢失任何更新

直到几年前都被认为是不切实际的

+   Paxos 太昂贵了，那么也许是主/备份？

+   如果主节点等待来自备份的 ACK

    +   50ms 网络将限制吞吐量并引起明显的延迟

    +   特别是如果应用程序必须在每次 50ms 进行多次读取

+   如果主节点不等待，它将在持久之前回复给客户端

+   分裂脑的危险；无法使网络可靠

有什么变化吗？

+   其他站点可能只有 5ms 距离 - 旧金山 / 洛杉矶

+   更快/更便宜的广域网

+   应用程序编写以容忍延迟

    +   可能会发出许多慢速读取请求

    +   但并行发出

    +   可能很快超时并尝试其他地方，或者冗余获取

+   大量并发客户端使您能够在延迟较高的情况下获得高吞吐量

    +   并行运行他们的请求

+   人们更加欣赏 paxos 并拥有更简化的变体

    +   较少的消息

        +   paxos 论文第 9 页：领导者每个操作 1 轮+大量预准备

        +   论文中的方案稍微复杂一些，因为他们必须确保最多只有一个领导者

    +   在任何副本处进行读取

实际性能？

+   表 3

    +   假装只是为了测量写入而测量 paxos，读取任何副本以获取读取延迟

        +   为什么随着副本数量的增加，写入延迟不会增加？

        +   为什么随着副本数量增加，延迟的标准差会下降？

        +   r/o *快*很多，因为不是 paxos 协议 + 使用最接近的副本吞吐量

        +   为什么读取吞吐量随着#副本增加而增加？

        +   为什么写入吞吐量不会增加？

        +   写入吞吐量似乎在下降吗？

    +   我们能从表 3 中得出什么结论？

        +   系统快吗？慢吗？

    +   你的 paxos 运行多快？

        +   我的协议每个协议花费 10 毫秒

        +   仅具有纯本地通信且无磁盘

        +   Spanner paxos 可能会等待磁盘写入

+   图 5

    +   `npaxos=5`，所有领导者在同一区域

    +   为什么在每个组中杀死一个非领导者没有效果？对于杀死所有领导者（“领导者硬化”）

        +   为什么有几秒钟是平坦的？

        +   什么导致它开始上升？

        +   为什么需要 5 到 10 秒才能恢复？

        +   为什么直到重新加入时斜率*更高*？

Spanner 从任何 paxos 副本中读取

+   读取不涉及 paxos 协议

+   直接从副本的 k/v 数据库中读取数据

+   可能快 100 倍——在同一房间而不是跨国

**问：**我们可以只*写*到一个副本吗？

**问：**从任何副本进行读取是正确的吗？

问题的例子：

+   照片分享站点

+   我有照片

+   我有一个 ACL（访问控制列表）规定谁可以看我的照片

+   我把我的妈妈从我的 ACL 中删除，然后上传新照片

+   实际上是网络前端执行这些客户端读/写操作

事件顺序：

1.  W1：我在 G1 组上（裸多数）写 ACL，然后

1.  W2：我在 G2 组上添加图像（裸多数），然后

1.  妈妈读取图像——可能从滞后的 G2 副本获取旧数据

1.  妈妈读取 ACL——可能从 G1 获取新数据

该系统不像单个服务器那样运行！

+   实际上没有任何一个时刻图像被...

    +   存在，但 ACL 还没有更新

这个问题是由以下几个因素的组合引起的

+   分区——副本组独立运行

+   为了性能而采取捷径——从任何副本读取

我们怎么修复这个问题？

1.  使读取看到最新数据

    +   例如，全面的 paxos 用于读取昂贵！

1.  使读取看到*一致*的数据

    +   数据如*某个*以前的时间点存在

    +   即在 #1 之前，#1 和#2 之间，或#2 之后

    +   这事实证明更加便宜

    +   Spanner 做到了这一点

这是 spanner 一致性故事的一个超级简化版本，适用于 r/o 客户端

+   “快照”或“无锁”读取

+   现在假设所有时钟都一致

+   服务器（paxos 领导者）使用写入时间标记每个写入操作

+   k/v 数据库为每个键存储*多个*值，

    +   每个都有不同的时间

+   阅读客户选择了时间 `t`

    +   每次读取

        +   在时间 `t` 询问相关的副本进行读取

+   一个副本如何在时间 `t` 读取一个键？

    +   返回`<= t`的最高时间的存储值

+   但是等等，副本可能落后了

    +   也就是说，可能有一个时间 `< t` 的写入，但副本还没有看到

    +   所以副本必须以某种方式确保它已经看到了所有的写入`<= t`

    +   思路：它是否已经看到了从时间 `> t` 开始的*任何*操作？

        +   如果是的，并且 PAXOS 组总是按时间顺序达成一致意见，那么检查/等待具有时间`> t`的操作就足够了

        +   这就是 Spanner 在读取时所做的（4.1.3）

+   读取客户端应该选择什么时间？

    +   使用当前时间可能会强制滞后的副本等待

    +   所以可能有一点过去的时间

    +   客户端可能会错过最新的更新

    +   但至少它会看到一致的快照

    +   在我们的例子中，没有看到新图像也没有看到 ACL 更新

这如何修复我们的 ACL/图像例子？

1.  W1：我在 G1 上写入 ACL，G1 将其分配时间=10，然后

1.  W2：我添加图像，G2 分配时间=15（> 10，因为时钟一致）

1.  妈妈选了一个时间，例如 t=14

1.  妈妈从滞后的 G1 副本读取 t=14 的 ACL

    +   如果它没有看到通过 t=14 的 PAXOS 协议，它知道要等待，以便返回 G1

1.  妈妈在 t=14 时从滞后的 G1 副本读取图像

    +   图像可能已经在那个副本上写入

    +   但是它将知道*不*返回它，因为图像的时间是 15

    +   `t`的其他选择也可以工作。

**问：**假设不同计算机的时钟一致是合理的吗？

+   为什么他们可能不会同意？

**问：**如果服务器的时钟不一致会发生什么？

一个性能问题：读取客户端可能会选择未来的时间，迫使读取副本等待“赶上”

一个正确性问题：

+   再次，ACL/图像的例子

+   G1 和 G2 对于时间的看法不一致

事件序列：

1.  W1：我在 G1 上写入 ACL -- 时间戳为 15

1.  W2：我在 G2 上添加了图像 -- 时间戳为 10

现在客户端在 t=14 时读取将看到图像但不会看到 ACL 更新

**问：**为什么 Spanner 不直接确保所有时钟都正确？

+   毕竟，它拥有所有那些主 GPS / 原子钟

## TrueTime（第 3 节）

+   实际上存在一个"绝对"时间`t_abs`

    +   但是服务器时钟通常偏移一些未知的量

    +   TrueTime 可以限制错误

+   所以`now()`产生一个区间：[最早，最晚]

    +   最早和最晚是普通的标量时间

        +   可能是自 1970 年 1 月 1 日以来的微秒

+   `t_abs`高度可能在最早和最晚之间

**问：**TrueTime 如何选择时间间隔？

**问：**为什么 GPS 时间接收器能够避免这个问题？

+   它们实际上是否会避免这种问题？

+   "原子钟"呢？

Spanner 为每个写入分配一个标量时间

+   可能不是实际的绝对时间

+   但是选择的是确保一致性

危险：

+   W1 在 G1，G1 的区间是 [20,30]

    +   在那个区间的任何时间都可以吗？

+   然后 W2 在 G2，G2 的区间是[11,21]

    +   在那个区间的任何时间都可以吗？

+   如果他们不小心，可能会得到 s1=25 s2=15

所以我们想要的是：

+   如果 W2 在 W1 结束后开始，则`s2 > s1`

+   从 4.1.2 简化的*"外部一致性不变式"*

+   导致快照读取看到与 W1、W2 的真实顺序一致的数据

Spanner 如何为写入分配时间？

+   （同样，这是大大简化的，参见 4.1.2）

+   写入请求到达 PAXOS 领导者

+   `s`将是写入的时间戳。

+   领导者将`s`设置为`TrueTime now().latest`。

    +   这是 4.1.2 中的“开始”。

+   然后领导者*延迟*直到`s < now().earliest`。

    +   即直到`s`被保证在过去（与绝对时间相比）。

    +   这是 4.1.2 中的“提交等待”。

+   然后领导者运行 Paxos 以导致写入发生。

+   然后领导者回复客户端。

这对我们的例子有效吗？

+   G1 处的 W1，TrueTime 说[20,30]。

    +   `s1 = 30`。

    +   等待提交直到 TrueTime 说[31,41]。

    +   回复客户端。

+   G2 处的 W2，TrueTime *现在必须*说`>= [21,31]`。

    +   （否则 TrueTime 就会出问题）。

    +   s2 = 31。

    +   等待提交直到 TrueTime 说[32,43]。

    +   回复客户端。

+   它对这个例子有效。

    +   客户端观察到 W1 在 S2 开始之前完成，

    +   而且`s2 > s1`。

    +   即使 G2 的 TrueTime 时钟慢了最多可能的时间。

    +   所以如果我妈妈看到 S2，她也保证会看到 W1。

为什么“开始”规则？

+   即为什么选择 TrueTime 间隔的结束时间？

+   先前的写入者只等到他们的时间戳刚好`< t_abs`。

+   新的写入者必须选择`s`大于任何已完成写入。

+   `t_abs`可能高达`now().latest`。

+   所以`s = now().latest`。

为什么“提交等待”规则？

+   确保`s < t_abs`。

+   否则写入可能会在未来完成。

    +   并且会让“开始”规则给后续写入的`s`太低。

**Q:** 为什么提交*等待*；为什么不立即使用选择的时间写入值？

+   间接地迫使后续写入具有足够高的`s`。

    +   系统没有其他方式来通信不同副本组中写入的下一个最小可接受的`s`。

+   等待迫使一些外部代理正在串行化的写入具有单调递增的时间戳。

+   没有等待，我们的例子回到了 s1=30 s2=21。

+   你可以想象明确的方案来将上次写入的 TS 传达给下一个写入。

**Q:** 提交等待多长时间？

这回答了今天的问题：大的 TrueTime 不确定性需要长时间的提交等待，因此 Spanner 的作者对准确的低不确定性时间感兴趣。

让我们退一步。

+   我们为什么要涉及所有这些时间戳的东西？

    +   我们的副本相距 100 英里或 1000 英里（为了本地性/容错）。

    +   我们想要从本地副本进行快速读取（无需完整的 Paxos）。

    +   我们的数据分布在许多具有独立时钟的副本组上。

    +   我们想要读取的一致性：

        +   如果 W1 然后 W2，读取不会看到 W2 但不看到 W1。

    +   它很复杂，但作为一个整体是有道理的。

    +   Lab 3 / Lab 4 的高性能演变。

为什么这个时间戳技术很有趣？

+   我们想要强制顺序--在实时发生的事情以某种顺序被分布式系统排序--“外部一致性”。

+   幼稚的方法需要一个中央代理，或大量的通信。

+   Spanner 通过时间隐式地进行同步。

    +   时间可以是一种通信形式。

    +   例如，我们预先同意在晚上 6:00 见面吃晚餐。

论文中有很多额外的复杂性。

+   事务，两阶段提交，两阶段锁定，

    +   模式更改，查询语言，等等。

+   一些我们以后会看到更多的东西。

+   特别是，在分布式系统中，事件排序的问题很快就会经常出现。
