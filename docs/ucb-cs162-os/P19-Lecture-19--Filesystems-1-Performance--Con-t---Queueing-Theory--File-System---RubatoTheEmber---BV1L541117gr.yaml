- en: P19：Lecture 19： Filesystems 1 Performance (Con't), Queueing Theory, File System
    - RubatoTheEmber - BV1L541117gr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P19：讲座19：文件系统1 性能（续），排队理论，文件系统 - RubatoTheEmber - BV1L541117gr
- en: Okay， everybody。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，大家准备好了吗？
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_1.png)'
- en: Welcome back。 Again， so we were talking last time about disks and SSDs。 And
    among other things。 this is an example of a disk that multiple platters two sides。
    You think of it as a cylinder is it the set of all tracks， which are concentric
    circles。 moving all the way down through the stack。 And the reason we think of
    a cylinder as a thing is the heads move all together to a given。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎回来。再次提醒，我们上次讨论了硬盘和固态硬盘（SSDs）。其中包括一个磁盘的示例，它有多个盘片，双面。你可以把它看作一个圆柱体，它是所有轨道的集合，这些轨道是同心圆。并且从堆叠的最上面一直到底部。我们之所以把它看作圆柱体，是因为磁头是一起移动到一个给定位置的。
- en: cylinder and then you rotate to actually read the sectors。 Okay。 And the reason
    the heads are all tied together and you have to go together is because heads。
    are really expensive， complicated technology and it's a commodity device and so
    you can't。 afford to have independent heads。 So we said there was a model of performance
    here， seek time。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 圆柱体，然后旋转以实际读取扇区。好的，磁头之所以必须一起移动，原因是磁头技术非常昂贵且复杂，它是一个商品设备，因此你不能负担得起拥有独立的磁头。所以我们之前提到过性能模型，寻道时间。
- en: which is the time to move， the head to the right cylinder rotational latency。
    which is the time to get the right， sector underneath and then transfer time。
    which is the time to transfer the blocks off。 And so a total model for disk latency
    is that it has that seek time plus rotation time plus。 transfer time， but it also
    has some other elements like queuing delay， which we'll talk。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 移动的时间是将磁头移动到右边的圆柱体的旋转延迟。获取正确扇区的时间，然后是传输时间，也就是将块传输出去的时间。因此，硬盘延迟的总模型包括寻道时间、旋转时间和传输时间，但它还包括一些其他元素，比如排队延迟，我们稍后会讨论。
- en: about today and hardware controller time， which you can imagine that's just
    the time for the。 controller to tell the disk what to do。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们讨论硬件控制器时间，你可以理解为这就是控制器告诉硬盘做什么的时间。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_3.png)'
- en: Okay。 So we're and we also talked about kind of typical numbers。 So for instance。
    if you look at a seagate 18 terabyte disk that's over one terabit per， square
    inch。 four to six milliseconds seek time and then the various rotational latencies。
    you're going to see on a commodity product are somewhere between 3，600 RPM to
    7，200 RPM。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们还讨论了一些典型的数字。例如，如果你查看一块西部数据18TB的硬盘，它的密度是每平方英寸超过1TB，寻道时间大约是4到6毫秒，而常见产品的旋转延迟大约在3600转/分钟到7200转/分钟之间。
- en: but servers can go up to 15 or even 20，000 RPM。 Okay。 So were there any questions
    about disks before I move on？ So if you think about it。 the model there of moving
    the disk head into the right track。 and then rotating and then finding the data
    means that there's a significant advantage。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但是服务器的转速可以达到15,000甚至20,000转/分钟。好的，在我继续之前，有没有关于硬盘的问题？如果你仔细想想，磁头移动到正确轨道然后旋转、找到数据的过程意味着它具有显著的优势。
- en: using locality to our advantage when we're starting to build file systems。 And
    so we're going to talk about that a little bit today and definitely next time。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始构建文件系统时，我们要利用局部性优势。所以今天我们将稍微讨论一下这个话题，下一次肯定会详细讲解。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_5.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_5.png)'
- en: Okay。 We also talked about SSDs that are made out of flash memory。 And I wanted
    to put this slide up， which I didn't last time to give you another idea。 of how
    flash works。 So this is silicon， dope silicon。 you probably all seen that in one
    of your 16 level classes。 Normally。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们还讨论了由闪存构成的固态硬盘（SSDs）。我想展示这张幻灯片，这是我上次没有展示的，目的是给你们提供一个关于闪存工作原理的另一种理解。这是硅，掺杂硅，你们可能在16级的课程中见过。通常情况下。
- en: there's a single gate on top and a control line and you get a transistor。 When
    there's a high voltage， the current flows and when there isn't， it doesn't。 What
    you get with flash is you actually put two gates on there with insulator in between，
    them。 And so that floating gate you see right here， oops， wait a minute， that
    you see right。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部有一个单独的门和控制线，你得到一个晶体管。当有高电压时，电流会流动；没有电压时则不会。使用闪存时，实际上你在其上放置两个门，中间有绝缘体。因此，您看到的这个浮动门，哦，等一下，您看到的这个浮动门。
- en: Don't do them。 The transistor in the middle is insulated from both sides。 So
    you can either store a bunch of electrons on it or not。 And if you store electrons。
    it changes the properties of the transistor enough that you， can detect it。 Okay。
    All right。 And the reason things wear out with flash is because basically those
    electrons get stuck。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不要去做它们。中间的晶体管两侧是绝缘的。因此，你可以选择是否将一堆电子存储在其上。如果存储了电子，它会改变晶体管的性质，以至于你可以检测到它。好吧，明白了。闪存会磨损的原因是因为这些电子基本上被卡住了。
- en: every now and then embedded in the insulation。 And so eventually when you get
    enough of those in there。 then it just doesn't work properly， anymore。 Okay。 And
    so the summary of SSD。 which is kind of where we were at last time， was really
    that。 the pros are really low latency and high throughput。 There's no moving parts。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 每隔一段时间，它会嵌入到绝缘材料中。所以，当你将这些足够多地放进去时，最终它就不能正常工作了。好吧。那么，关于SSD的总结，也就是我们上次讨论的内容，实际上是这样。优点是低延迟和高吞吐量，且没有移动部件。
- en: which is a big advantage for reliability。 And you can read things essentially
    at memory speed。 The cons used to be that the storage of these devices was much
    smaller than hard drives and。 much more expensive， except that none of that's
    true anymore。 And I should remember I showed you that you could easily get a 15
    terabyte SSD no problem。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可靠性的巨大优势。而且你可以几乎以内存速度读取数据。这些设备的缺点曾经是，它们的存储容量远小于硬盘，而且更贵，除了现在这些都不再成立。记得我曾经给你们展示过，你完全可以轻松地得到一个15TB的SSD。
- en: Now the it's a little more expensive， but it's not a problem from getting to
    space。 Some other interesting problems that show up and we're not going to have
    a lot of time。 in this class to discuss the file systems for flash that are unique
    from disk。 But there is this weird notion that you have to erase a whole group
    of blocks at a time。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在它稍微贵一点，但获得存储空间已经不成问题了。还有一些其他有趣的问题出现，我们在这门课中没有很多时间讨论与硬盘不同的闪存文件系统。不过，有一个奇怪的概念，就是你必须一次性擦除整个块组。
- en: And so there's a lot more management that has to be done down in the controller
    of the。 SSD to make that work well。 Okay。 And also the SSD has to realize that
    things wear out。 So but things are changing rapidly。 And as an amusing thing，
    last time。 remember I showed you that 100 terabyte disk that was， a， you can put
    into a regular computer。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，SSD的控制器需要做更多的管理工作，才能确保其良好运作。好吧，此外，SSD必须意识到元件会磨损。但是情况在迅速变化。还有一件有趣的事情，上次我给你们展示了那个100TB的磁盘，嗯，你可以把它放进一台普通计算机里。
- en: Now of course it was $40，000。 Really worth more than several computers， but
    you know。 you do this in the cloud perhaps。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当然它是 $40,000。确实比几台计算机还要值，但你知道，或许你可以把它放到云端去做。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_7.png)'
- en: Okay。 The last thing I wanted to mention is if you have any interest in persistent
    memory， it's。 always kind of fun to see what's coming up。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我想提到的最后一件事是，如果你对持久性内存感兴趣，它总是很有趣，看看未来会有什么新发展。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_9.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_9.png)'
- en: Right。 So for instance， when flash originally showed up， it had several different
    ways of using， it。 some of which were just like a memory card。 Others of which
    went into the SSD and had controllers and everything。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对，所以举个例子，当闪存最初出现时，它有几种不同的使用方式，其中一些就像一个存储卡，其他的则进入SSD并配备了控制器等一切组件。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_11.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_11.png)'
- en: Similarly， there's a bunch of persistent memory technologies。 This is one of
    my favorite ones that doesn't quite exist yet， which is made out of nanotube，
    memory。 which and has a cross hash pattern and it's three dimensional for storing
    bits。 And the difference between a one and a zero is kind of whether all of the
    nanotubes are。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，还有一堆持久性内存技术。这是我最喜欢的一种，虽然它还没完全实现，那就是由纳米管内存制成，它具有交叉哈希图案并且是三维的，用来存储比特。1和0之间的区别在于，是否所有的纳米管都……
- en: aligned or not。 And you can detect that difference with a resistance。 And the
    cool thing about nanotube memory is it doesn't wear out。 Okay。 And it's also potentially
    as fast as DRAM。 So and SSD is not that fast。 So someday。 there's a whole slew
    of possible technologies out there。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 是否对齐，你可以通过电阻来检测这种差异。而纳米管内存的酷炫之处在于它不会磨损。好吧，而且它的速度也可能和DRAM一样快。所以，SSD的速度还没有那么快。因此，总有一天，会有一大堆潜在的技术出现。
- en: And it may be the fact that when we teach this class in five years or whatever，
    it'll。 be all about the fact that the memory is persistent。 There is no disk。
    And the problem is when you reboot， it's got everything it had before。 So rebooting
    no longer is a good way to get rid of bugs。 Right。 So that's on the horizon。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，当我们在五年后或其他时候教授这门课程时，可能会全部讲述内存持久化的事实。没有磁盘。而问题在于，当你重启时，它会恢复之前的所有内容。所以重启不再是清除
    bug 的好方法。对吧？这就是未来的趋势。
- en: That's not that far off。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这还不算太远。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_13.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_13.png)'
- en: Okay。 All right。 So let's change gears now。 Let's talk about ways of measuring
    performance before we get into the file systems themselves。 Okay。 And so you can
    measure things like times and rates。 You can measure latency。 which is the time
    to complete a task。 That's easy。 Like if I wanted to get a block off the disk。
    how long would it take？ And that's measured in second units， right？ Seconds， milliseconds。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。好了，现在我们来换个话题。让我们在进入文件系统之前，先讨论一下性能测量的方法。好的。所以你可以测量诸如时间和速率之类的东西。你可以测量延迟，也就是完成任务的时间。这很简单。比如我想从磁盘读取一个块，花多长时间？这个时间是以秒为单位的，对吧？秒、毫秒。
- en: microseconds， hours， years。 The other thing， which is possibly similar is response
    time。 which is the time to initiate， an operation and get its response back。 which
    can be different from latency if you're thinking， about things like overhead and
    so on。 And then on a different fashion， is things like throughput and bandwidth，
    so how many。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 微秒，小时，年。另一种可能相似的概念是响应时间，也就是启动一个操作并获取其响应的时间。如果你考虑像开销等因素，响应时间可能与延迟不同。而在另一种情形下，还有吞吐量和带宽之类的概念，也就是每秒可以传输多少数据。
- en: accesses could I do per unit time or how much， how many bytes per second can
    I get？
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 访问次数是每单位时间内可以进行多少次，或者每秒可以获取多少字节？
- en: And then there's the overhead， which is the time to actually start an operation。
    So typically you go to send the controller a request。 There's some fixed amount
    of time。 probably in microseconds or milliseconds that needs， to lapse before
    the disk even gets the request。 And that's going to be pure overhead。 Okay。 So
    most IO operations are roughly linear like this。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是开销，也就是实际启动操作的时间。通常你会向控制器发送请求。在请求发出之前会有一个固定的时间间隔，可能是微秒或者毫秒，在磁盘收到请求之前。这将是纯粹的开销。好的。所以大多数
    IO 操作大致是线性的。
- en: This is a very simple model that often works， which is the latency as a function
    of the。 number of bits。 Remember little B is bits。 Is the overhead plus the bits
    divided by the transfer capacity。 which is sort of how， many bits per second you
    can get。 Okay。 Very simple model。 which we're going to show you something about
    in a moment。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的模型，通常是有效的，延迟是位数的函数。记住小写的b是位。是开销加上位数再除以传输能力，这就是每秒可以传输多少位。好的，非常简单的模型，稍后我们将向您展示一些相关内容。
- en: This is ultimately what people care about， but what does it really mean？ Okay。
    By the way。 the question here is why is this P bytes that's a type of order。 So
    what does it actually mean here to have performance？ Does it mean faster？
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这最终是人们关心的内容，但它到底意味着什么呢？好的。顺便说一下，这里问的问题是，为什么这个是 P 字节，那是一种排序方式。那么，性能到底意味着什么？是指更快的速度吗？
- en: Does it mean lower latency？ Does it mean higher throughput？ So whenever somebody
    says。 does this have higher performance？ Your question ought to be， what do you
    mean？
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着更低的延迟？是否意味着更高的吞吐量？所以每当有人说，这个性能更高时，你的第一个问题应该是，你是什么意思？
- en: That ought to be your first question if somebody says it performs more。 Okay。
    Because you got to even know what you're measuring。 All right。 Now， here's an
    example here。 So suppose we have a link that's a gigabit per second。 That's a
    pretty standard ethernet link these days in low end places。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人说它性能更好，那应该是你首先问的问题。好的。因为你得知道你在测量什么。好了，接下来是一个例子。假设我们有一个每秒一吉比特的链接。如今，这是低端地方常见的标准以太网链接。
- en: And that actually means that our， we can get 125 megabytes per second。 Okay。
    Out of that link。 I just took one gigabit and divided by eight。 All right。 And
    the startup cost， let's say。 is a millisecond just for the sake of argument。 And
    so we can build something that looks like this。 which is the length in bits on
    the bottom， that we want to transfer in a packet。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这意味着我们可以从这个链接中获得每秒 125 兆字节。好的。我刚刚将一吉比特除以 8。好的。启动成本，假设是毫秒级别，仅仅为了论证。于是我们可以构建一个看起来像这样的模型，底部是我们想要在数据包中传输的位数。
- en: and then we can have latency in blue and bandwidth， in red。 So I'm putting two
    different scales on the same graph。 I hope you don't mind that too much。 But what
    can we learn here？ Well， latency here has that startup cost plus the number of
    bits divided by this maximum。 rate。 Okay。 And you're going to have to normalize
    so that if you're using with bits， you deal with。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以看到蓝色的延迟和红色的带宽。所以我把两个不同的刻度放在同一个图表上。我希望你们不介意。但我们能从中学到什么呢？嗯，延迟这里有启动成本加上比特数除以这个最大速率。好的。如果你使用比特，你就得处理。
- en: bits or bytes， you deal with bytes。 But this S plus B over B is the thing that
    looks like a straight line。 right？ Because it's linear in B。 So that's our blue。
    And notice that it to transfer no bits。 there's still a millisecond。 That's why
    the intercept here is at a millisecond or a thousand microseconds。 which by the
    way， since my last Tuesday lecture， you guys are all that all these units figured
    out now。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 比特或者字节，你就得处理字节。但这个S加B除以B看起来就像一条直线。对吧？因为它对B是线性的。所以这就是我们的蓝线。并且请注意，传输零比特时，仍然需要一毫秒。这就是为什么拦截点在一毫秒或者一千微秒的位置。顺便说一下，自从我上周二的讲座之后，你们现在已经搞清楚所有这些单位了。
- en: right？ Yeah。 So we're dealing with powers of 10 or powers of two here。 Powers
    of 10， right？
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对吧？是的。所以我们在处理的是10的幂次或者2的幂次。10的幂次，对吧？
- en: Because we're dealing with bandwidth。 Okay。 So the effective bandwidth for transmitting
    so many bits is B over S plus B over B。 So that's the total number of bits I transfer
    divided by the latency。 And that gives me bits per second。 Okay。 And that's this
    red curve。 So notice that even though in the best case， I can get 125 megabytes
    per second， it takes。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们在处理带宽。好的。所以传输这么多比特的有效带宽是B除以S加上B除以B。所以这是我传输的比特总数除以延迟。这样就能给我每秒比特数。好的。这就是这个红色曲线。所以请注意，尽管在最佳情况下，我可以获得每秒125兆字节，但它需要。
- en: a very large packet to overcome that overhead and get that full bandwidth。 Okay。
    Questions。 Does that make sense？ All right。 So now we can talk about this key
    dotted line。 which is the half power point。 And that's or the half point。 And
    that's typically why it's not advancing。 There it is。 This is the number。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常大的数据包来克服这个开销并获得完整的带宽。好的。有什么问题吗？明白了吗？好吧。现在我们可以谈谈这个关键的虚线，也就是半功率点。这就是或者半点。通常这就是为什么它没有推进。它就是这个数字。
- en: the value of B for which I have half of my bandwidth。 Okay。 And so usually the
    half power point。 that's what this dotted line is， is an interesting。 one because
    it means you're kind of not overwhelmed by the startup overhead。 It's kind of
    you're kind of getting along to getting real raw overhead。 So a link， by the way。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我有半带宽的B值。好的。所以通常情况下，半功率点就是这个虚线，它是一个有趣的点，因为它意味着你不会被启动开销压倒。你基本上已经开始逐渐克服这个原始开销。所以一个链接，顺便说一句。
- en: the question is what was a link in here？ We're talking about a network。 So a
    link is a an ethernet cable or something that's transmitting。 Okay。 So for this
    example。 the half power bandwidth occurs when B is 125 kilobytes。 Okay。 So B，
    by the way。 in answer to that previous question is actually a variable。 And we're
    looking at the units here。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，这里有一个链接吗？我们在谈论的是网络。所以一个链接就是一个以太网电缆或者传输的某种东西。好吧。那么在这个例子中，半功率带宽出现在B为125千字节时。好的。顺便说一下，回答上一个问题，B实际上是一个变量。我们在看这里的单位。
- en: This is kilobytes in this case。 So where does that come from？
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是千字节，在这种情况下。那么这个从哪里来的？
- en: We find out the point at which the value of B， which gives us the half full
    bandwidth。 half of the bandwidth， and that's 125 kilobytes。 Now what's interesting
    about this for me is if we make the overhead much larger like for。 a disk， what's
    suppose it's 10 milliseconds， then the same kind of idea， the half power。 bandwidth
    now is for a packet that's 1。25 megabytes in size。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们找到了B的值，使得带宽的值达到一半的带宽。这个一半的带宽是125千字节。现在对我来说有趣的是，如果我们将开销增大，比如对于一个磁盘，假设是10毫秒，那么同样的概念，半功率带宽现在适用于一个大小为1.25兆字节的数据包。
- en: Before our half power point here was 125 kilobytes。 That says that until you
    when you transmit a packet that's 125 kilobytes in size， you're。 going to get
    at least half of your bandwidth in use。 Here that 10 millisecond startup cost
    says that if we don't get 1。2 megabytes as a packet， size。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的半功率点是125千字节。这意味着当你传输一个大小为125千字节的数据包时，你将至少使用一半的带宽。这里的10毫秒启动成本表示，如果我们没有得到1.2兆字节大小的数据包，
- en: we don't get half of our full bandwidth。 Okay。 So when the overhead gets high。
    you've got to figure out ways of getting rid of the overhead。 Either by making
    things arbitrarily large， which isn't always practical， or by， for instance。 in
    the case of disk， you make sure you don't seek very much and that will reduce
    the overhead。 Okay。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不会获得完整带宽的一半。好的，所以当开销增加时，你就得想办法减少这些开销。可以通过使数据包变得异常大，这不总是实际可行的，或者通过比如说，在磁盘的情况下，尽量避免过多寻址，这样会减少开销。好的。
- en: Questions？ Yeah。 So， I'm sorry I said this incorrectly earlier。 The lowercase
    b is the amount。 is a variable， it's the amount you're transmitting。 And I'm showing
    it in bits down here。 Okay。 And this is the capital B because this is a constant。
    This is， this is bytes capital B。 So here again， this little b is a constant。
    So what I really ought to do with these slides is I ought to get rid of the small
    b that's。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有问题吗？是的，抱歉，我刚才说错了。小写字母 b 是变量，表示你传输的数据量。我在这里显示的是比特。好的，而大写字母 B 是常量，表示字节。所以这里再次强调，小写字母
    b 是常量。因此，我在这些幻灯片上应该做的是，去掉公式中的小写 b。
- en: in the equation in bullet x。 Maybe that makes things less confusing。 Okay。 I'll
    do that。 All right。 All right。 Now， so what determines the peak bandwidth？ So
    remember the peak bandwidth is this。 this point that you would finally reach with
    an， arbitrarily large packet。 You'd hit the peak bandwidth and that's the guaranteed
    not to exceed bandwidth。 Okay。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这样可以减少一些混淆。好的，我会这样做。好了。那么，是什么决定了峰值带宽呢？记住，峰值带宽是指你最终会达到的那个点——一个任意大的数据包。你会达到峰值带宽，这就是保证不会超过的带宽。好的。
- en: So a one gigabit network link， the guaranteed not to exceed bandwidth is a gigabit，
    right？
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，一个千兆位网络链接，保证的最高带宽是千兆位，对吧？
- en: But what determines that？ Well， in the case of ethernet， it's the protocol。
    If it's a gigabit ethernet， you're not going to get better than a gigabit out
    of it。 But there's lots of things in systems that set that high point。 So in case
    of buses， you know。 you can look at this like PCIX is a very old bus。 That's a，
    you know， a gigabyte per second。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，是什么决定了这一点呢？在以太网的情况下，它是由协议决定的。如果是千兆以太网，你就无法从中得到超过千兆的带宽。但系统中有很多因素决定了带宽的上限。例如，关于总线，你可以看到像
    PCIX 这样的总线，它是一个非常老旧的总线，提供大约每秒 1 吉字节的传输速度。
- en: let's say， thunderbolt is another one that， a lot of you have on Intel machines。
    which gets you 40 gigabits per second。 So varies widely。 So when you're sort of
    trying to figure out， am I going to get my full bandwidth， you have。 to start
    by figuring out what is the thing that's the bottleneck bandwidth here。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，Thunderbolt 是另一个很多人使用的接口，尤其是在英特尔机器上。它的传输速度可以达到每秒 40 吉比特。所以它的速度差异非常大。因此，当你尝试弄清楚是否能达到完整带宽时，你需要从弄清楚瓶颈带宽在哪里开始。
- en: And so the device transfer bandwidth is another thing that could be setting
    a bottleneck。 So for instance， the rotational speed of the disk， if the disk is
    spins twice as fast， you're。 going to get twice the transfer rate off of that
    disk because the bits are going under。 the head twice as fast。 Okay。 And that's
    why high performance systems have 15，000 or 20。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，设备传输带宽是另一个可能造成瓶颈的因素。例如，磁盘的旋转速度，如果磁盘的转速是原来的一倍，那么你能从磁盘上获得的传输速率也会是原来的两倍，因为数据在磁头下方的传输速度是原来的两倍。好的，这就是为什么高性能系统会使用
    15,000 或 20,000 转每分钟的磁盘。
- en: 000 RPM disks in them。 Okay。 Whatever is the bottleneck in the path tends to
    be the peak bandwidth。 Yes。 No， if we increase the disk speed， you mean how fast
    it's spinning？ That's going to。 it's going to do a couple of things。 Okay。 It's
    going to not only decrease the overhead of rotating to find your sector。 So that's
    going to go down。 That's overhead。 But the other thing is when you're reading
    off the disk。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些磁盘通常是 15,000 转每分钟的磁盘。好的，路径中的瓶颈决定了最高带宽。是的，如果我们提高磁盘的转速，你是指它旋转的速度吗？这会做几件事。好的，它不仅会减少旋转到指定扇区时的开销。这个开销会减少。而且当你从磁盘读取数据时，
- en: the bits come off twice as fast。 Okay。 So it's， so the case of spinning the
    disk faster is actually speeding up a couple of things。 Now that latency for moving
    the head in and out， that's a challenge to make faster because。 that's a physical
    thing。 I mean， the nice thing about spinning is you spin it up to a certain speed
    and it stays。 there essentially。 Okay。 In terms of moving the head around。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 比特数据传输速度是原来的两倍。好的。所以，提高磁盘转速实际上加速了几件事。现在，移动磁头进出时的延迟是一个难点，因为那是物理问题。我的意思是，转速有个好处，你可以把它转到某个速度，并且它基本上会保持在那里。好的，关于移动磁头。
- en: it depends on how fast you can actually accurately move， the head。 And that's。
    that's a harder one to improve。 It's been improving over time。 It used to be that
    the access latency was like 15 milliseconds or 20 milliseconds and。 now we're
    getting down to four and six。 So it's been improving， but it's not improving rapidly。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这取决于你实际上能多快准确地移动磁头。这是一个更难改进的地方。它一直在改善。过去，访问延迟是15毫秒或20毫秒，而现在我们已经降低到了4毫秒和6毫秒。它在改善，但进展并不快。
- en: Okay。 So that's kind of pure overhead。 Any other questions？ Yeah。 So the half
    power bandwidth is what packet size， in this case it's， but packet size do。 I
    send such that I get half of the bandwidth out of my system。 Okay。 And the problem
    is that when I go to send a packet or take something off the disk， there's。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。所以这就是纯粹的开销。还有其他问题吗？是的。那么，半功率带宽对应哪个数据包大小，在这种情况下是，但是我发送的那个数据包大小是多少，才能从我的系统中获得一半带宽。好的。问题是，当我发送数据包或从磁盘取出某物时，存在。
- en: the raw overhead and then I get to get my full bandwidth out of it。 And so that
    because of the overhead， you can't just， what you need to do is figure out what。
    is the largest packet that I need so that I get half of my bandwidth out of it。
    That's the half power point。 Okay。 Okay。 All right。 Any other questions？ Now。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 原始开销，我就能从中获取完整带宽。所以因为有开销，你不能简单地做你需要做的是确定，哪个是最大的数据包大小，以便从中获取一半的带宽。这就是半功率点。好的。好的。还有其他问题吗？现在。
- en: so the question here again， what does it mean exactly to get half the bandwidth？
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这里的问题是，再次问，得到一半带宽究竟是什么意思？
- en: It means that this red curve， which you say， here's a packet size， how much
    bandwidth am， I getting？
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着这条红色曲线，表示包的大小，表示我能得到多少带宽？
- en: What is the packet size here where the bandwidth I get is half of the maximum？
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的包大小是多少，带宽是最大带宽的一半？
- en: That's the half power here。 Okay。 Clear？ And it's really， I mean， this previous
    slide showed here。 it's really the effective bandwidth， is having to take into
    account that overhead。 So if there was zero overhead and S was one or zero， I
    mean the effective bandwidth would。 be exactly a gigabit and there wouldn't be
    an issue of half power point， but we have， overhead here。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是半功率点。明白了吗？事实上，上一张幻灯片展示了这一点。真正的有效带宽是需要考虑这些开销的。因此，如果没有开销，S为1或0，我的意思是有效带宽将恰好是1千兆，比特率不会存在半功率点的问题，但这里有开销。
- en: That's why we have to take that into account。 Okay。 Now， so hire the bandwidth
    the better。 Yes。 but you can't always get higher bandwidth， but you'll try to
    get what you can。 So let's look at a couple other things in terms of modeling。
    So let's suppose we have some operation a server is going to do and it takes L
    latency and it。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们必须考虑这一点。好的。那么，带宽越高越好。是的，但你不能总是得到更高的带宽，但你会尽力获取可用的带宽。那么，接下来我们从建模的角度来看看其他几个因素。假设我们有一个操作，服务器将执行，并且它需要L的延迟。
- en: always takes exactly L latency。 And we would get something that looks like this，
    okay。 where we do the first thing， then， we do the second thing， then we do the
    third thing。 They're all equal length in time。 And if that is true， which it's
    never going to happen by the way。 but if it were true and， say L was 10 milliseconds，
    then B which is the big B here script。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 总是需要恰好L的延迟。然后我们得到类似这样的东西，好的。我们首先做第一件事，然后做第二件事，再做第三件事。它们的时间长度都是相等的。如果这是对的，虽然它永远不可能发生，但如果它是真的，假设L是10毫秒，那么B就是这里的那个大B。
- en: which is the number， of operations we can get per second is 100 because one
    over 10 milliseconds is 100 ops。 per second。 Okay。 And that's just the inverse
    of the link。 Now if the length was two years。 I don't know what this represents，
    maybe this represents， growing an orchid or something。 I don't know。 Then the
    number of orchids you get would be a half of an orchid per year。 Okay。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每秒可以执行的操作数是 100，因为 1 除以 10 毫秒等于每秒 100 次操作。好的。这只是链路的倒数。如果链路是两年，我不知道这代表什么，也许是指种植一株兰花之类的。我不确定。然后你得到的兰花数量将是每年半株兰花。好的。
- en: One over L。 So this is like the simplest scenario you could possibly have and
    it never happens this。 well。 Okay。 But let's just， this is sort of 61C material。
    I'm reminding you of this。 So for instance， and this applies to processors， disk
    drives， whatever。 Here's a pipeline。 Suppose you've got your item that takes L
    but you can divide it into three separate。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 1 除以 L。所以这是你可能遇到的最简单的情况，它实际上从来不会这么顺利。好吧，但让我们假设，这就像是 61C 的材料，我提醒大家这个例子。所以，例如，这适用于处理器、磁盘驱动器等设备。假设你有一个管道，其中某个项目需要
    L 时间，但你可以将其分为三个独立的部分。
- en: pieces that can be done independent of each other。 Remember that from 61C everybody，
    right？
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以相互独立完成的部分。记得 61C 的内容吧，大家还记得吗？
- en: So we could have blue， gray and green be the different pipeline operations to
    get that， full L。 right？ So we first do a blue thing， then a gray thing， then
    a gray thing and we're done。 And so this would look like this。 Here's the first
    thing。 Notice the individual item still took a whole L to do but it was done by
    doing the first， third。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们可以让蓝色、灰色和绿色代表不同的管道操作，以便实现那个完整的 L，对吧？首先做一个蓝色操作，然后是一个灰色操作，再做一个灰色操作，最后完成。这样看起来是这样的。这里是第一个操作。注意，每个单独的项目仍然需要整整一个
    L 来完成，但它是通过先做第一个、第三个操作来实现的。
- en: the second third， the third third。 And that means if we pipeline it like this。
    that means while we're doing the blue thing， for the next operation。 we can be
    doing the green one for the current one or the gray one。 for the current one and
    the green one for the previous one。 So we're pipelining。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个第三，第三个第三。这意味着如果我们像这样进行管道化处理，那就是当我们执行蓝色操作时，我们可以对下一个操作执行绿色操作，或者对当前操作执行灰色操作，同时对前一个操作执行绿色操作。所以我们正在进行管道化处理。
- en: That's look familiar to everybody。 So now we can just talk about the rates。
    So for instance。 if L is 10 milliseconds total and there were say four pipeline
    stages。 that means that instead of 100 ops per second， we can actually get 400
    of them coming through。 because we've got the pipeline going。 Okay。 And really
    you could also say that each one of these little things is a quarter of what。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这对大家来说很熟悉吧。那么现在我们可以谈谈速率。比如说，如果 L 是 10 毫秒，总共四个管道阶段。这意味着，我们不仅能以每秒 100 次操作的速率运行，实际上可以让
    400 次操作通过，因为管道正在工作。好吧。实际上你也可以说，每一个小的操作都是 L 的四分之一。
- en: L is so basically we get four of them for L unit time。 All right。 Okay。 Now。
    so there's lots of systems pipelines。 So the reason we talk about performance
    a bit with you guys is so that you can start。 thinking if I've got a system， what
    are my bottlenecks for bandwidth？ What's the limiting factor？
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: L 的单位时间内，我们基本上可以获得 4 次操作。好的。现在。所以有很多系统管道。我们与你们讨论性能的原因是让你们开始思考，如果我有一个系统，带宽瓶颈在哪里？是什么限制了我的性能？
- en: What are the overheads， et cetera？ So you can imagine here， for instance。 you've
    got a user program that makes a system called。 it to access the file and then
    it's got to go through the file system software and then。 maybe that's got to
    go through the upper half of the driver and the lower half of the。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，开销等问题呢？比如说，你可以想象，在这里，举个例子。你有一个用户程序，它通过系统调用来访问文件，然后必须通过文件系统软件，再可能通过驱动程序的上半部分和下半部分。
- en: driver and ultimately get to disk。 And so we can look at pipelines where we
    have kind of one process is making a system call。 Well， another one's working
    on the file system。 Well。 another one's in the upper part of the device driver
    and another one's in the lower。 part of the device driver。 So these pipelines
    kind of show up everywhere。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动程序最终到达磁盘。所以我们可以看一下管道，其中一个进程在进行系统调用，另一个在处理文件系统，再一个在设备驱动程序的上半部分，最后一个在设备驱动程序的下半部分。所以这些管道几乎无处不在。
- en: not just in processor pipelines like in 61c。 All right。 So anything with queues
    behaves roughly pipeline-like。 All right。 And those queues are going to be a problem
    for us。 We're going to have to talk about what's the actual queuing behavior。
    Okay。 Now。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是在61c中的处理器流水线里。好的。因此，任何与队列相关的东西，基本上都表现得像流水线一样。好的。这些队列会成为我们的一个问题。我们需要讨论一下实际的排队行为。好的。现在。
- en: the other thing that you can do， you also heard about this in 61c， is I could
    have a。 bunch of L things and if I put a multi-core at them， I could have a bunch
    of L things。 happening in parallel。 All right。 And now I can split them up as
    well。 So if I have four cores and each thing takes 10 milliseconds， I can also
    get 400 ops coming。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以做的另一件事，你在61c课程中也听过，就是我可以有一堆L任务，如果我给它们配上多核处理器，我就能让一堆L任务并行进行。好吧。现在我也可以将它们拆分开。所以如果我有四个核心，每个任务需要10毫秒，那么我也可以让400个操作同时进行。
- en: out for once， but that's because they're now being done in parallel。 Okay。 You
    see the difference of pipelining， I split it into pieces and I've got a pipeline
    going。 Parallelism， each of them is kept the same and they all go through multiple
    of them at， once。 Those are just different ways of structuring systems。 And of
    course in 61c。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就能同时完成，但这是因为它们现在是并行执行的。好的。你看到了流水线的不同，我把它分成了若干部分，并且有了流水线。并行性，每个部分保持不变，它们都同时经过多个处理。那些只是构建系统的不同方式。当然，这些内容也在61c中有所涉及。
- en: you saw this as multi-core。 Okay。 So lots of parallelism again。 where now we
    can have a bunch of user processes， all submitting。 syscalls at once and maybe
    there's a lot of parallelism in the file system and the drivers。 and there's multiple
    disks。 So we could have multiple things happening at once going through the system。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到这就是多核处理。好的。所以又是大量的并行性，在这里我们可以有一堆用户进程，同时提交系统调用，也许文件系统和驱动程序中有很多并行性，并且有多个磁盘。因此，我们可以有多个操作同时进行。
- en: Okay。 So， could anybody tell me that if we wanted to exploit parallelism like
    this， what we're。 likely to run into？ Can anybody come up with what are the biggest
    issues that might show up here？
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。那么，有没有人能告诉我，如果我们想像这样利用并行性，我们可能会遇到什么问题？有没有人能提出在这里可能出现的最大问题是什么？
- en: Synchronization problem。 Great。 Yes。 Okay。 Because if there's one file system
    and lots of people are accessing it。 you could imagine， you don't know anything
    about file systems quite yet。 but you could imagine that they're， all using shared
    data structures and if we don't have good synchronization。 it gets， all screwed
    up。 So parallelism， just like when we talked about thread level parallelism earlier
    in the term。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 同步问题。很好。是的。好的。因为如果有一个文件系统，而很多人同时访问它。你可以想象，虽然你现在可能还不了解文件系统的细节，但你可以想象它们都是使用共享数据结构，如果我们没有良好的同步机制，那么一切都会变得混乱。因此并行性，就像我们之前在学期初讨论的线程级并行性。
- en: in the IO system， we're going to have to make sure our parallelism doesn't get
    in the way。 of correctness。 Okay。 This is like this class， you never lose the
    stuff we teach you early on。 you just have， to apply it to different topics。 Okay。
    So。 let's go back to sort of a model of IO for a moment。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在IO系统中，我们需要确保我们的并行性不会妨碍系统的正确性。好的。就像这门课，你不会忘记我们早期教给你的内容，你只是需要将其应用到不同的主题上。好的。那么，让我们回到IO模型的问题上来。
- en: And here's a thread from a user and it is going to make generically some sort
    of IO， request。 I'm going to forget about file systems and stuff for a moment，
    say it's accessing the， disk。 So what happens is that request gets put into a
    queue。 Okay。 It could be a queue in front of the controller。 It could be a queue
    in the operating system or in the device driver。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是来自用户的一个线程，它将生成某种IO请求。我暂时不考虑文件系统之类的内容，假设它是在访问磁盘。那么发生的事情是，这个请求被放入队列中。好的。它可能是放在控制器前的队列中，也可能是在操作系统或设备驱动程序中的队列。
- en: And then there's a controller that pulls things off the queue and sends them
    off to the IO， device。 Okay。 And so the response time is going to typically be
    a queue time plus an IO device service time。 And so this is important。 That green
    thing is in the main path to getting your satisfied response。 right？ Because your
    request has to work all the way through the queue and then through the controller。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后有一个控制器从队列中取出任务，并将其发送到IO设备。好的。因此，响应时间通常是队列等待时间加上IO设备的服务时间。所以这很重要。那个绿色的部分是在获取响应的主要路径上，对吧？因为你的请求必须先通过队列，然后通过控制器。
- en: and get back。 So you could imagine that if the queue was completely full that
    this controller could。 be spitting things out really rapidly， but when you put
    your request in there， it still。 got to drain the queue down so you're in the
    front and then get to be processed。 Okay。 So a large queue translates into long
    latency。 Okay。 This is the McDonald's analogy， right？
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后再返回。所以你可以想象，如果队列已经完全满了，这个控制器可能会非常快速地处理事情，但当你把请求放进去时，它仍然需要排空队列，才能让你排到前面，然后被处理。好吧。所以一个大的队列就意味着较长的延迟。好吧。这就是麦当劳的类比，对吧？
- en: You really want that McFlurry or whatever it is you're going after。 You go into
    the McDonald's。 there's a huge line and you got to wait through the line before。
    you can even get to the counter to get served。 Okay。 And so that queue， believe
    it or not。 has a lot more importance to latency than is usually， recommended。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你真的很想要那个麦旋风，或者你正在追求的其他东西。你走进麦当劳，排了很长的队，你得等队伍排完，才能到柜台点餐。好吧。相信与不信，这个排队的过程对延迟的影响，比通常推荐的要重要得多。
- en: So when we're looking at the performance of an IO system， you know， we have
    our metrics。 like response time and throughput。 We can start talking about effective
    bandwidth here where we have the number of operations。 we're trying to do。 There
    might be some overhead and then there's something which is the time per operation。
    That looks exactly like that simple model I gave you earlier， right？ Because it's
    pretty universal。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当我们观察IO系统的性能时，你知道，我们有一些指标，比如响应时间和吞吐量。我们可以开始谈论有效带宽，在这里我们有我们尝试执行的操作数。可能还会有一些开销，然后是每个操作的时间。这看起来正好与我之前给你的简单模型一样，对吧？因为它是相当普遍的。
- en: it shows up all over the place。 What's going to be different about this is we're
    going to start having to address things。 that look like this。 Okay。 This is kind
    of got a linearity to it or it's a slight concavity downward。 This is something
    else entirely。 Okay。 And notice how I've labeled it at the bottom， 0% to 100%。
    What this represents is the full utilization of the device。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 它无处不在。不同的是，我们开始需要解决看起来像这样的事情。好吧。这种情况有点线性，或者稍微有点向下凹的趋势。完全是另一回事。好吧。注意我在底部标记了它，0%到100%。这代表的是设备的完全利用率。
- en: So 100% utilization means the devices go on all the time。 It's completely busy。
    0% means it's idle。 We have an overhead， but notice this behavior where as you
    get closer and closer to 100% of。 the capacity， the latency goes greater and greater。
    And there will be many things you encounter in your career at Berkeley that all
    have that。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所以100%的利用率意味着设备始终处于工作状态。完全繁忙。0%意味着设备空闲。我们有一些开销，但注意这种行为：当你越接近100%容量时，延迟会越来越大。在你在伯克利的职业生涯中，你会遇到许多类似的情况。
- en: response behavior。 Okay。 And you need today， we're going to talk about where
    some of that comes from。 but also you， need to be aware that this is a general
    engineering pattern。 And there's a couple of things to think about here。 If you
    design a bridge and you compute its maximum capacity for handling weight， call，
    that 100%。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 响应行为。好吧。今天我们要讨论的是这些行为的来源，但你也需要意识到，这是一个普遍的工程模式。有几个需要考虑的点。如果你设计一座桥梁，并计算其承重的最大容量，假设它是100%。
- en: Do you want to run the bridge at 100% capacity？ No， right。 That sounds very
    non clever。 Okay。 And so 100% anything once you've identified your 100% points
    becomes very important。 But the other thing that happens with cues is typically
    because of simple random behavior。 which we'll talk about in a moment， once you
    get closer and closer to that 100%， the latency。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你想让桥梁以100%的容量运行吗？不，对吧？那听起来一点也不聪明。好吧。所以，一旦你确定了100%的点，任何100%的情况都会变得非常重要。但队列的另一个问题通常是，由于简单的随机行为，我们稍后会讨论，一旦你接近100%，延迟就会增大。
- en: goes higher and higher toward infinity。 Okay。 Now any real system， of course，
    can't go to infinity。 but it's going to get arbitrarily， large。 Can anybody guess
    what was happening in the point where we're kind of growing without。 bound？ The
    crew is growing。 Great。 That's exactly right。 And the cue is growing in a way
    that's much larger growth for a little tiny bit of change。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 趋向无限增长。好吧。现在任何真实的系统当然不能无限增长，但它会变得任意大。有人能猜到我们在增长过程中发生了什么吗？队列在增长。太棒了。完全正确。队列的增长速度，远大于一些微小变化所带来的增长。
- en: in utilization。 Okay。 And that's generic。 So contributing factors to latency。
    if we think about the user thread， submits a request， and then they get a response
    back。 Software。 which is loosely modeled by a cue， the hardware controller， the
    I/O device service， time。 It's not easy to get in the way， but cueing behavior
    is very important。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在利用率方面。好吧，这很通用。所以对延迟的贡献因素。如果我们考虑用户线程提交请求，然后收到响应。软件，大致可以通过队列来建模，硬件控制器，I/O 设备服务时间。它不容易受干扰，但队列行为非常重要。
- en: And I don't know if any other classes that you've taken have focused on cues。
    We're not going to do a lot of it， but I want to give you some simple ideas about
    cues just。 so we can have some back of the envelope kind of ways of talking about
    performance。 Okay。 Now。 let's start with something very simple。 So here's a simple
    deterministic world。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你们上过的其他课程是否关注过队列。我们不会讲太多内容，但我想给你一些关于队列的简单概念，这样我们就可以用简单的方式讨论性能了。好吧。现在，让我们从一个非常简单的情况开始。这里是一个简单的确定性世界。
- en: which unfortunately the world is not deterministic。 but it's always nice to
    pretend it is for a few slides。 So what do I mean here？
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，世界不是确定性的。但假装它是确定性的几分钟总是让人觉得不错。那么我在这里是什么意思？
- en: So I have a cue in front of a server。 And that server， by the way。 could be
    a controller plus a disk。 It could be McDonald's， whatever。 And so if we imagine
    that items are arriving exactly every T sub A seconds， exactly， then。 we know
    that the server only takes T sub S seconds to serve。 And notice that T sub S is
    what？
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我有一个队列在服务器前面。顺便说一下，这台服务器可以是一个控制器加硬盘，也可以是麦当劳，随便。假设项目每 T 子 A 秒准确到达一次，然后我们知道服务器只需要
    T 子 S 秒来处理。请注意，T 子 S 是什么？
- en: It's shorter than T sub A。 Significantly shorter。 Okay。 So what's going to happen
    here？ Well。 we're going to， the arrival will show up。 It'll get put on the cue。
    but basically get taken off immediately because the cue is empty。 And then we'll
    serve T sub S。 And after we're done， the cue is now empty and the whole server
    sets idle。 Okay。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 它比 T 子 A 短。明显短。好吧。那么这里会发生什么呢？嗯，到达的请求会出现。它会被放入队列，但基本上会立即被取出，因为队列是空的。然后我们会处理 T
    子 S。处理完后，队列现在为空，整个服务器设置为空闲状态。好吧。
- en: So from the standpoint of how busy that server is， it's clearly not 100%。 In
    fact。 it's less than half kind of the way I've got this diagram here， right？
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 从服务器的忙碌程度来看，显然不是 100%。事实上，正如我在这里的图示，处理率不到一半，对吧？
- en: So that server is really idle。 Okay。 And in this particular useful situation。
    we're assuming determinism， so all requests are at， regular intervals。 There's
    a fixed time to process。 There's plenty of time in between。 We can start talking
    about a service rate， which is how fast is the server serving things。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 所以那台服务器真的很空闲。好吧。在这个特别有用的情况下，我们假设是确定性的，所以所有请求都是按固定间隔到达的。处理有固定的时间，之间有足够的时间。我们可以开始谈论服务速率，就是服务器处理事物的速度。
- en: It's one over T sub S。 So it takes T sub S time one over it is a service rate。
    Okay。 Just like one over L was our service rate in a couple of previous slides。
    And the arrival rate is how fast are things arriving that's one over T sub A。
    What can you tell me about Lambda versus Mu？ What was that？ Yeah。 Yeah。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 它是 1 除以 T 子 S。所以它需要 T 子 S 时间，1 除以它是服务速率。好吧，就像之前几张幻灯片中的 1 除以 L 是我们的服务速率一样。到达率是事物到达的速度，是
    1 除以 T 子 A。你能告诉我关于 Lambda 和 Mu 的什么呢？怎么说？对，没错。
- en: so Lambda one over T sub A is smaller than one over T sub S。 So this seems like
    a good situation。 Okay。 And typically when we're talking about utilization， it's
    Lambda over Mu。 And the fact that Lambda is less than Mu means we're not at that
    100% point and we're okay。 All is good。 Okay。 Because the rate at which things
    are coming in is less than the rate at which they can go。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 Lambda 的 1 除以 T 子 A 小于 1 除以 T 子 S。所以这看起来是一个不错的情况。好吧。通常我们讨论利用率时，是 Lambda 除以
    Mu。Lambda 小于 Mu 意味着我们没有达到 100% 的点，没关系，一切都好。因为事物到达的速度小于它们可以处理的速度。
- en: out。 Now， average rate is a complete world。 So this ideal world we're in， if
    we go from zero to one。 that's the 100% point at one， and we offer this low TS
    over TA。 what's great is we can serve this immediately。 And so the queue never
    builds up。 At most it has an item on there that gets taken off immediately。 So
    this is great。 Never happens。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 出来了。现在，平均速率是一个完整的世界。所以在我们所处的理想世界中，如果我们从零到一，那就是 100% 的点，当到达速率低于服务速率时，最棒的是我们可以立即处理。所以队列从不会积压，最多它上面会有一个项目，然后被立即取走。所以这是很棒的情况。但这从来不会发生。
- en: This is great。 However， if you notice this scenario where we try to offer more
    than 100% load。 what's， going to happen？ Well， we're going to start saturating。
    And so the device is going to be spitting things out as fast as it can， but where
    items。 are coming faster than the device can make it。 And so the queue is going
    to grow。 Okay。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好。但是，如果你注意到这种情境，我们尝试提供超过100%的负载，**会发生什么**？嗯，我们会开始饱和。所以设备将尽可能快地输出，但项目的到达速度超过了设备处理的速度。因此队列会增长。好的。
- en: So when we're in the mode where TS over TA is greater than one， what happens
    is we grow。 Our queue keeps getting longer and longer。 Okay。 So you could maybe
    say this is。 you're at that McDonald's， but there's a bunch of tour。 buses that
    keeps showing up and dumping people at the door， and they're all going for that。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当我们处于TS/TA大于1的模式时，发生的事情是我们开始增长。队列会越来越长。好的。所以你也许可以说这是你在麦当劳，但有一堆旅游巴士不断到达并把人们送到门口，他们都要去排队。
- en: McFlurry。 Okay。 Now， at the end of the day when the buses stop going， the queue
    will drain。 And we get back to being able to get our ice cream quickly。 Okay。
    Now。 what's the queue wait time look like what's growing unbounded at a rate determined
    by TS， over TA？
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: McFlurry。好的。现在，当公交车停止时，队列会清空，我们又能快速地拿到冰淇淋了。好的。那么，队列的等待时间看起来怎么样，正在以由TS与TA的比例决定的无界速率增长吗？
- en: Let's look at reality。 So reality， nothing's deterministic。 Okay。 I hate to
    break this to you。 If you don't know that already， maybe this is a sad day for
    you， but nothing in the world。 is deterministic。 Okay。 Even at the quantum level。
    So what happens？
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看现实情况。那么现实中，没有什么是确定的。好的。我很抱歉告诉你这个。如果你还没有意识到这一点，可能今天对你来说是一个难过的日子，但这个世界上没有什么是确定的。好的。即使是在量子层面也是如此。那么发生了什么呢？
- en: So let's look at a situation where we're going to have the same average rate
    of arrivals。 Okay。 So the average rate of arrivals are still going to be one over
    TA， but we're going to。 have bunches of them。 So there'll be a bunch of people
    and then the killed and then a bunch of other people。 Okay。 That's bursty。 All
    right。 And this is much better comparison with the bus because the bus shows off。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们来看一下一个情况，在这个情况下，平均到达速率是相同的。好的。所以平均到达速率仍然是1/TA，但我们将会有一堆到达。所以会有一堆人，然后暂停，接着又有一堆其他人到达。好的。这就是突发性情况。好了。这是一个更好的与公交车进行比较的情况，因为公交车会停靠。
- en: but people get， off and the bus leads and other bus shows up。 A bunch of people
    get off。 So look what happens here。 So the first item arrives and it's immediately
    pulled off the queue and it starts serving。 Okay。 So that so far looks exactly
    like the previous slide we had。 Then another one shows up at the next bursty time
    slot and that's white and now white is。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 但是人们下车，公交车离开，另一辆公交车到达。一堆人下车。那么看这里发生了什么。第一个项目到达后，立即从队列中取出并开始服务。好的，到目前为止看起来和我们之前的幻灯片完全一样。然后另一个项目出现在下一个突发时间段，它是白色的，现在白色的。
- en: going to be sitting in the queue until the blue one is serviced。 Okay。 So this。
    this white rectangle here is unhappy because they're not， they're going to take。
    longer to get their ice cream than they would have expected if there's nobody
    in line。 And then orange comes along and orange。 Notice how they're each coming
    at these little ticks here。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 将会一直排队，直到蓝色那辆被服务。好的。那么这个，这个白色矩形这里是不高兴的，因为他们没有人排队时，拿到冰淇淋的时间会比预期的要长。接着橙色出现了，注意看它们是如何在这些小刻度处到达的。
- en: So orange shows up。 It's in the queue， whites in the queue， in front of it。
    And then gray comes along。 Okay。 And now we're at the end of a burst。 but notice
    we've got three items in the queue。 So the queue is no longer empty。 It's got
    things in it。 And as soon as blue finishes。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 所以橙色到达了，排在队列里，白色排在它前面。接着灰色来了。好的。现在我们处于突发的末尾。但注意我们队列里有三项。因此队列不再是空的了，里面有东西。而且一旦蓝色完成。
- en: the great thing is that now white can get in the server and。 now orange is in
    the front and gray is next， right？ You guys see what's happening here。 And then
    we go down one more and then eventually the powder blue one gets serviced and
    we're。 good to go。 And the queue even has a period of time where it's empty。 Okay。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒的是，现在白色可以进入服务器，而橙色排在前面，灰色在后，明白发生了什么吗？然后我们再往下看，最终浅蓝色的那个也被服务了，我们可以继续了。队列甚至有一段时间是空的。好的。
- en: But we could set this up so that the rate in which they arrive over on average
    is exactly。 the same as the deterministic case。 But notice the difference here。
    The difference is that there are some folks in here that are really unhappy。 Like
    look at this powder blue guy。 He arrived just a little bit after the dark blue
    one did。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以设定一个情况，让它们的到达速率平均上与确定性情况完全相同。但请注意这里的不同。不同之处在于，这里有些人非常不开心。看看这个浅蓝色的人，他在深蓝色的人后面稍微晚了一点到达。
- en: But look at all the time they're stuck waiting in the queue。 Okay。 So queues
    in a bursty scenario start filling up。 Questions。 Office hours simplify。 Yes。
    Very good。 Today， today I'm presenting a model of office hours。 Yeah， I apologize
    about that。 Are there any questions other than how close this is to the office
    hour situation？
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 但看看他们在排队时等了多长时间。好了。所以在突发场景中，队列开始堆积起来。问题。办公时间简化。是的，非常好。今天，今天我在展示一个关于办公时间的模型。是的，我为此道歉。除了这和实际办公时间情况有多接近之外，还有其他问题吗？
- en: So the moment we start getting burstiness or non-determinism， then we start
    having problems。 And the question is really， how do we model burstiness？
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 所以一旦我们开始出现突发性或非确定性，我们就开始遇到问题。问题实际上是，如何建模这种突发性？
- en: And there's a mathematical framework that works pretty well。 Where if you start
    with the exponential distribution like this， which says the time of the next。
    arrival f of x is lambda e to the minus lambda x。 Okay。 Where the average amount。
    the average arrival rate is one over lambda。 And so lambda is a rate。 This is
    called memoryless。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个数学框架非常适用。如果你从像这样的指数分布开始，它表示下一个到达的时间f(x)是lambda e的负lambda x次方。好了，其中平均到达速率是1/lambda。所以lambda是一个速率。这个被称为无记忆分布。
- en: Okay。 And the curve looks like this， where I'm plotting the time between now
    and the next arrival。 Okay。 On the x axis。 And this is a probability distribution
    function because it tells me kind of what's the probability。 that I'll get somebody
    that has a， a， a， a， a interval of two。 Okay。 Does anybody know what the deal
    with memoryless arrivals are？ Yes。 Perfect。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，曲线是这样的，我绘制了从现在到下一个到达之间的时间。好了，x轴上。这是一个概率分布函数，因为它告诉我，我得到某个时间间隔为2的人的概率是多少。有人知道无记忆到达的含义吗？是的，完美。
- en: So the conditional probability， if I already know I've waited two seconds， what's
    the probability。 of the time to keep waiting？ It turns out that if you do conditional
    probability for those of you that remember that and you。 rescale the graph， it
    looks exactly the same。 So this model is a great model for burst buses in Berkeley。
    right？ You're sitting， waiting at the bus stop， and it doesn't matter how long
    you've waited。
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 那么条件概率，如果我已经知道自己等了两秒，接下来继续等待的概率是多少？结果是，如果你做条件概率，对于那些记得这个概念的人，并且你重新缩放图表，它看起来完全一样。所以这个模型对于伯克利的突发公交非常适用，对吧？你坐在那里等公交，无论你等了多久都不重要。
- en: The distribution of how long you're going to wait is the same when you rescale
    it。 Okay。 It's memoryless。 That's what this means。 Okay。 Now。 the good thing about
    a memoryless distribution is that it's easy to plug into things and use。 as a
    model。 The question you might ask is， is it realistic？ Well。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你将要等待的时间分布在重新缩放后是一样的。好了，它是无记忆的。这就是它的意思。好了，现在，关于无记忆分布的好处是，它容易代入到其他东西并作为模型使用。你可能会问，它现实吗？嗯。
- en: it turns out that a lot of physical processes when you combine a bunch of them。
    together tend to have what looks like a memoryless arrival rate that comes out。
    So oftentimes what will happen is if you don't really know what the actual distribution
    is。 oftentimes people will say， let's assume it's memoryless， let's compute the，
    let's compute。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 结果发现，许多物理过程在将多个过程结合在一起时，往往会表现出像无记忆到达速率那样的特性。所以很多时候，如果你不知道实际的分布是什么，通常人们会说，假设它是无记忆的，我们来计算一下，计算一下。
- en: the rate。 Okay。 Lambda。 And that will be， we'll use a memoryless distribution
    and we'll plug that into our formulas。 Now， there's lots of arguments that you
    can run into and in 70 and 170， they'll talk about。 this a lot。 You know， is that
    a fair characterization？ Not always。 But it is one that people use a lot。 Okay。
    So what am I saying？
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 速率。好的。Lambda。然后我们将使用一个无记忆分布，并将其代入我们的公式。现在，你可能会遇到许多不同的争论，在70和170课程中，他们会经常讨论这个问题。你知道，这是不是一个公平的表述？并不总是。但这是一个人们经常使用的表述。好了，我在说什么？
- en: I'm saying that if you don't know anything better， you assume that they're all
    independent。 of each other and have a memoryless distribution and there's only
    lambdas， the one parameter。 you have to find。 Okay。 So what does this mean for
    this？ So if we had a burst。 a memoryless bursty behavior， what this really is，
    is there's some。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我是说，如果你没有更好的理解，你假设它们都是相互独立的，且具有无记忆的分布，并且只有λ，一个参数，你需要找出它。好的，那么这对我们有什么意义呢？如果我们有一个突发的无记忆的突发行为，实际上这意味着有一些。
- en: arrivals that are very close to each other and then there's some long tail arrivals。
    So if you look here， there's a lot of short ones and there's some occasional long
    ones。 So we could talk about a queue with a memoryless arrival。 Okay。 And there's
    an average arrival time。 just like we talked about earlier， which is one over，
    Lambda。 So lots of short， a few long。 Okay。
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 到达时间非常接近的情况，然后是一些长尾到达时间。所以如果你看看这里，有很多短的到达时间，也有一些偶尔的长时间到达。所以我们可以谈论一个具有无记忆到达的队列。好的，并且有一个平均到达时间，就像我们之前讨论过的那样，即1除以λ。所以很多短的，到达时间少数长的。好的。
- en: So I will tell you that a lot of folks who are not trying to get a hyper accurate
    model。 will think about things in terms of memorylessness。 So we're going to use
    this moving forward。 Okay。 So let's quickly remind you of some general random
    distributions。 So you all know about if the server spends time t with customers，
    we could look at the。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我会告诉你，很多人并不试图得到一个超准确的模型，他们会从无记忆的角度来考虑问题。所以我们将继续使用这个方法。好的，快速提醒你们一些常见的随机分布。所以你们都知道，如果服务器花费时间t与客户互动，我们可以看一下。
- en: distribution of service times。 So what you think about this is you get to the
    counter at McDonald's and this is the。 distribution of how long it takes to get
    your McFlurry。 Okay。 And there's an average in the middle and some distribution。
    Okay。 So the mean is the what you get when you sum up the probability or sum up
    the area under， the curve。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 服务时间的分布。所以你可以这样想，当你到达麦当劳的柜台时，这是获取你的麦旋风所需时间的分布。好的，分布的中间有一个平均值，旁边是一些分布。好的，那么均值就是你将概率加起来，或者将曲线下的面积加起来得到的结果。
- en: Okay。 The variance is what you get when you sum up probability times the t minus
    the mean。 Okay。 So。 and you're familiar with the square root of variance， which
    is the standard deviation。 So this is the way you think about midterms one and
    two， right？ Where the mean is like 52。 unfortunately， and the standard deviation
    was， I don't know， 12 or something， right？
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，方差就是你当你将概率乘以(t减去均值)后加起来的结果。好的。所以，你们对方差的平方根也很熟悉，那就是标准差。所以这就是你们考虑期中考试时的一种方式，对吧？均值大概是52，遗憾的是，标准差是12还是类似的数值，对吧？
- en: So the squared coefficient of variance is something you probably haven't seen
    too often。 And that is the variance， which is sigma squared divided by the mean
    squared。 And what's great about C is C has no units。 So we can come up with some
    equations for queuing that are unitless。 And if we know what C is， we can plug
    them in there and have a good， have a good approximation。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 所以方差的平方系数可能是你不太常见的东西。它是方差，σ²除以均值的平方。C的好处是C没有单位。因此，我们可以得出一些无单位的排队方程。如果我们知道C的值，我们可以将其代入并得到一个好的近似值。
- en: of what's going on。 So for instance， important values of C here are if C is
    zero。 we're back to determinism。 Why is that？ Well， if C is zero。 the only way
    that's going to happen is sigma squared is zero， which means。 there's no standard
    deviation， which everything takes exactly the same amount of time。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么事情。那么例如，这里的重要值C是当C为零时，我们回到确定性。为什么会这样呢？嗯，如果C为零，唯一可能发生的情况是σ²为零，这意味着没有标准差，所有事情都会花费相同的时间。
- en: Or deterministic。 Another one is that this good old memory list thing。 remember
    this is how you talk about， buses in Berkeley， C is one。 So typically， when C
    is one。 it's often because it's a memory list situation。 And then finally， disk
    response times。 there's been a lot of people that have measured how， disks perform。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 或者是确定性的。另一个是这个老牌的无记忆情况。记住，这是你用来描述伯克利的公交车的方式，C等于1。因此，通常当C等于1时，这通常意味着是一个无记忆的情况。最后是磁盘响应时间，很多人都测量过磁盘的性能。
- en: and they have a C that's a little bigger than one。 So it's not memory list，
    and really 1。5 means that the majority of the seeks are less than， the average。
    Can anybody come up with a reason why the majority of the seeks might be less
    than average latency？
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的C值稍微大于1。所以这不是内存无关的，实际上1.5意味着大多数寻道操作的延迟会小于平均值。有没有人能想到为什么大多数寻道操作的延迟会小于平均延迟？
- en: Remember， seek is moving that it's an expensive move in the head in and out。
    Yeah。 Say that again。 Okay。 Because a lot of things are on the same。 Yeah。 So
    the file is good。 The file systems that try to exploit locality， try to make sure
    that you don't move the head。 very much。 So if you do a really good job with your
    file system。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，寻道操作意味着磁头的移动，它是一个代价较高的过程。对的，再说一遍。好的，因为很多东西都在同一位置。对。所以文件系统是好的。那些试图利用局部性的文件系统，尽量确保你不需要大幅度移动磁头。所以如果你把文件系统做得非常好。
- en: then you're going to have more locality， and most of your seeks are going to
    be less than the average。 And that's why oftentimes people will talk about C equal
    1。5。 Okay。 Now， of course。 that only works if you build a good file system。 If
    you don't build a good file system。 you're not going to get that。 Okay。 Question。
    Right。 This is all stuff you know， right？
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你将会有更多的局部性，并且大多数的寻道操作会比平均值少。这就是为什么很多时候人们会说C等于1.5。好的，当然，前提是你要构建一个好的文件系统。如果你没有构建一个好的文件系统，你是得不到这样的结果的。好的，问题来了。这些都是你们已经知道的，对吧？
- en: So now let's talk a little bit about queuing。 Okay。 So queuing theory is a whole
    topic。 Anybody here taking any classes on queuing theory or had queuing theory
    talked about？ No。 All right。 We're the first。 I feel privileged。 So queuing theory
    is a very complicated topic that all sorts of。 you can take a whole class， on
    it， but I'm going to give you a very simple model here that works well for some
    of the。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来谈谈排队问题。好的，排队理论是一个完整的主题。这里有谁上过关于排队理论的课程，或者听过关于排队理论的讲解吗？没有。好的，我们是第一个。我觉得很荣幸。排队理论是一个非常复杂的主题，你可以专门学习一个完整的课程，但我会给你一个非常简单的模型，这个模型对于一些情况来说非常有效。
- en: things we talk about in this class。 And that model is that we have a queue in
    front of say a controller and a disk。 And we're going to look at the whole queuing
    system， which is what I've got in cyan here。 is having some arrivals that come
    in and some departures that go out。 And if you remember from high school chemistry，
    remember detailed balance was talked about。
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这门课上讨论的内容是这样的。这个模型是我们在前面假设有一个排队队列，假设有一个控制器和一个磁盘。我们将会查看整个排队系统，正如我在这里用青色标出的部分。这是有一些到达的请求和一些离开的请求。如果你还记得高中化学的内容，记得提到过详细平衡。
- en: at one point in chemistry， which is you get to a point where the rate of a reaction
    happening。 and the rate of the reaction， unhappening are meeting each other。 And
    that's the final stage。 So in queuing theory， you have arrivals are at the same
    rate as departures on average。 And in that case， you get a steady state。 All right。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在化学中有一个观点，反应发生的速率和反应不发生的速率会相遇到一个点。这是最后的阶段。所以在排队理论中，到达和离开的速率在平均情况下是相等的。在这种情况下，你就得到了一个稳态。好的。
- en: So the queuing theory we talk about in this class in this lecture is steady
    state queuing， theory。 This is not something that deals with transient startup
    behavior。 That's a whole much more complicated topic。 Okay。 So when we talk about
    coming up with a queuing model for something。 we're talking about steady， state
    behavior。 All right。 By the way。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在这门课上讨论的排队理论，或者说在这次讲座中的排队理论是稳态排队理论。这并不是处理瞬态启动行为的内容。那是一个更加复杂的主题。好的。所以当我们谈论为某个问题构建一个排队模型时，我们谈论的是稳态行为。好的，顺便说一句。
- en: there's a series of books by somebody named Kleinrock。 Great books on queuing
    theory。 So if you feel like you want to learn a lot more about it， go for it。
    Okay。 But for today。 we're steady state。 Okay。 And arrivals are characterized
    by some probability distribution。 We showed you one earlier that's possible memory
    list， right？ That's an option。 Okay。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 有一系列由Kleinrock所著的书，关于排队理论的经典书籍。如果你想深入了解，可以去读一读。好的。但今天我们只讨论稳态排队理论。好的。到达事件由某些概率分布来描述。我们之前展示过一种可能的内存无关的情况，对吧？那是一个选项。好的。
- en: And departures are characterized by some probabilistic distribution。 And the
    trick is what is the latency from the point that your request arrives to when。
    you get your answer and also how long is the queue on average？
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 离开事件则由一些概率分布来描述。关键是从请求到达的那一刻开始，到你得到答案的那一刻，延迟是多少？同时，平均队列长度是多少？
- en: Those are two questions we care about。 Time and queue size。 Okay。 And so I want
    to introduce you to Little's Law。 Okay。 This is just a little law。 It's a good
    one。 Okay。 Little was his last name。 But the idea is if you have a situation with
    arrivals coming into some system and departures。 and the arrivals are coming in
    at some rate， lambda and in general， there are L items， in the queue。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们关心的两个问题：时间和队列大小。好吧。所以我想向你介绍Little定律。好吧，这只是一个小定律，但它是一个很好的定律。Little是他的姓氏。基本的想法是，如果你有一个到达某个系统的情况，并且有离开的人，到达的速率是lambda，一般情况下，队列里有L个项目。
- en: then what can you say about this？ Well， in any stable system， as we just said。
    the arrival rate is equal to the departure， rate and the average number of jobs
    in the system， N。 I'm sorry， I said earlier that L， was number of jobs。 L is the
    latency that you wait。 What you can see here is that the number of jobs N is equal
    to lambda times L， period。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你能说什么呢？嗯，在任何稳定的系统中，正如我们刚才所说的，到达率等于离开率，系统中的平均工作数量是N。抱歉，我之前说L是工作数量，L其实是你等待的延迟时间。你可以在这里看到，工作数量N等于lambda乘以L，结束。
- en: So if you know what lambda is and you know the average latency it takes to get
    through， the system。 then you know how many jobs are stacking up there。 And what's
    interesting about this is this doesn't matter whether you have memoryless。 arrivals
    or anything you like。 It works under all circumstances。 Okay。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果你知道lambda的值，并且知道通过系统的平均延迟时间，那么你就知道有多少工作在积压。而有趣的是，这与是否有无记忆性到达，或者其他任何情况无关。它在所有情况下都适用。好吗？
- en: so regardless of the structure， bursts variation， instantaneous variations，
    whatever。 it all washes out in the average。 Okay， so if you know what lambda is。
    you know what the time to do a request is that you can。 figure out how many jobs
    are sitting in the queue。 So this is going to be interesting here。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 所以无论是结构，突发变化，瞬时变化，还是其他任何情况，它们都会在平均值中消失。好吧，所以如果你知道lambda的值，知道做一个请求的时间，你就可以计算出队列里有多少个工作。这个会很有趣。
- en: So the question， by the way， from the previous， why does memoryless imply C
    equal one？
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，顺便提一下，之前的问题，为什么无记忆性意味着C等于一？
- en: You just have to plug it in。 Okay， because sigma squared over M squared for
    memoryless is one。 Okay。 so here's a simple example。 Look， if the latency for
    us to get through the system is L equal five and there's an item。 arriving every
    one second， then it's pretty easy to see that there are five jobs at a。 time in
    the system。 Anybody want to disagree with that？ Seems pretty simple， right？
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要把它代入公式。好吧，因为对于无记忆性，sigma平方除以M平方等于一。好吧，这里有一个简单的例子。看，如果我们通过系统的延迟是L等于五，且每秒到达一个项目，那么你很容易就能看出，系统中每次都有五个工作。有人不同意这个理解吗？看起来很简单，对吧？
- en: If they're arriving one a second， it takes you five to get in， then there's
    on average， five jobs。 Here's how you think about that。 You go to McDonald's。
    you're getting a lot of free advertising for me today。 I don't even like McDonald's，
    but anyway。 you go， you come to the door and you look in， the McDonald's and there's
    a bunch of people in line in front of you。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果他们每秒到达一个人，你花五秒才能进入，那么平均有五个工作。这样理解怎么样？你去麦当劳。今天我为麦当劳做了很多免费的广告，我甚至不喜欢麦当劳，不过随便吧。你走到门口，往里看，麦当劳里面排了一大堆人在等。
- en: Okay？ And you walk to the counter and by the time you get to the counter， if
    you turn around。 and look behind you， there's the same number of people in line。
    Okay？
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 好吗？你走到柜台，到你到达柜台的时候，如果你转过头，回头看，排队的人数是一样的。好吗？
- en: That's what it means to be steady state。 All right？
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是所谓的稳态。明白吗？
- en: And so that's why this equation works because if you look at the rate that people
    are coming， in。 all right， and you look how long you took and you turn around
    and you look， you know。 that in that time that you were going through the line，
    people were coming in at that rate。 You take the time you were there times the
    rate that gives you how many people are in， line。 Okay？
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是这个公式为什么有效的原因，因为如果你看人们到达的速率，嗯，然后你看自己花了多长时间，转身看看，你知道。在你排队的这段时间里，人们以那个速率在进来。你将你在那里花的时间乘以那个速率，就可以得出排队的人数。好吗？
- en: Very simple。 Now， that's little's law。 And here's a very quick sketch。 You ready？
    One， two， three。 put your put your proof sketch hat on。 If you look at a bunch
    of items。 each of which takes L time and they're varying all over。 the place and
    there's T time that we're looking at the system。
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 非常简单。现在，这是小利法则。这里有一个非常简单的示意图。准备好了吗？一，二，三。戴上你们的证明示意帽。如果你看看一堆物品，每个物品需要L的时间，它们的分布是随机的，系统的观察时间是T。
- en: So we're going to average over capital T。 How do we know what the average number
    of jobs are in the system？
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们要对大T进行平均。怎么知道系统中工作的平均数量是多少？
- en: Okay？ It's very easy。 We say， well， here is the number of jobs at this one slice
    of time。 How do I know that？ There's one， two， three， four of them。 And what I
    want is what's the average number of jobs in the system？
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 好吗？这非常简单。我们说，假设这里是某个时间点的工作数量。怎么知道的呢？这里有一，二，三，四个。那么，我想知道的是系统中工作的平均数量是多少？
- en: So can anybody think how I do this？ Yeah， very good。 Area。 We compute the area。
    So what we're going to do is make each one of these stripes equal to size one。
    And if we compute the area and divide by the time， we're going to figure out the
    average。 number of folks in here。 Okay？ Exactly。 So here we go。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，谁能想出我怎么做这个呢？对，非常好，面积。我们计算面积。所以我们要把每一个条带的大小设为1。如果我们计算这个面积并除以时间，就能得出平均值。系统中的人平均数量是多少？好，完全正确。我们开始吧。
- en: We're going to say the system area S at any given time is L i times one， okay，
    which。 is that height。 Okay？ So L i is the length。 The height is one that gives
    us the area at that point。 And so we'll just add up all the areas throughout here。
    That's the sum of all areas。 And then that turns out is just L of one， L two，
    L three， L four， which are the latencies。
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要说，在任何给定时间，系统的面积S等于L i乘以1，好的，就是那个高度。好的？所以L i是长度，高度是1，这样就得出了那个点的面积。所以我们就把所有的面积加起来。这是所有面积的总和。然后这就变成了L1，L2，L3，L4，它们是延迟时间。
- en: And so now we take the total area， we divide by T and that gives us the average
    number。 of people in the queue。 Good。 And so if you look here。 the average number
    of people in the queue is S over T。 We can compute that out。 That's the sum of
    all L's over T。 Or if we take the total number of jobs。
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们取总面积，除以T，这样就得出平均人数。很好。所以如果你看看这里，队列中人的平均数量是S除以T。我们可以算出来。这是所有L的总和除以T。或者如果我们考虑所有工作的总数。
- en: we're going after divided by T。 That's the average number of jobs times the
    L's divided by N total。 That's the average latency。 And that gives us the number。
    the average number of people in the queue is equal to， lambda average times length
    average。 Okay？
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要除以T。这是工作平均数乘以L的平均值，再除以N总数。这就是平均延迟。然后得出结果。队列中人的平均数量等于，lambda平均值乘以长度平均值。明白了吗？
- en: Little's law。 Something to remember， it might actually show up on midterm three。
    I suspect it might。 But it's universal and think of it as this is the McDonald's
    law。 You look in the door。 you have a rate of people coming in， you look when
    you get to the counter， you look back。 That tells you how many people are in line。
    Okay， any questions？ All right。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 小利法则。记住这一点，它可能会在期中考试三上出现。我怀疑它可能会出现。但它是普遍适用的，可以把它看作是麦当劳法则。你看着门口，有人进来的速率，你走到柜台，看一下你到达时的情形，回头看看。这就告诉你队伍里有多少人。好，大家有问题吗？好。
- en: So now when you apply it to a queue， what do you got？
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在，当你把它应用到队列时，你得到了什么？
- en: If you know the average time waiting in the queue and you know the average arrival
    rate。 you just melt climb together and that gives you the average length of the
    queue。 So basically。 this is going to be universally useful for going from the
    time you've been。 in the queue to the average length of the queue。 Okay？ All right。
    So here we go。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道队列中平均等待时间，并且知道平均到达率，你只需将这两个数相乘，就能得出队列的平均长度。所以基本上，这个公式对于从你在队列中的等待时间推算队列的平均长度是普遍适用的。好吧？好了，我们开始吧。
- en: We'll do all of this and we'll take a brief break。 So here's a。 here's your
    little bit of queuing theory that we expect you'll know something， about。 Because
    one。 systems in equilibrium， no limit to the queue。 Two。 the time between successive
    arrivals is random and memoryless。 So we're going to have a。
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会做所有这些，然后休息一下。所以这是你的排队理论小知识，我们希望你对它有一些了解。因为一，系统是平衡的，队列没有上限。二，连续到达的时间是随机且无记忆的。接下来我们要做一个。
- en: a rival rate， which is memoryless。 Okay？ So the arrival rate is lambda， the
    service rate。 which is how long it takes the server， to go can be an arbitrarily
    complex thing。 So we're not going to make that memoryless。 And you can think why
    that might be， right？
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到达率，它是无记忆的。好吧？所以到达率是 lambda，服务率，它是服务器完成工作所需的时间，可以是一个非常复杂的东西。所以我们不会让它是无记忆的。你可以想象为什么会这样，对吧？
- en: If it's a DRAM， you go to the DRAM， it probably takes a pretty deterministic
    amount of time。 to do a read from it。 Okay？ So deterministic service times for
    servers are not out of the question。 but the arrival， rates， things are typically
    coming up in bursts。 Okay？ So here's the parameters。 So lambda， the service rate
    T， CER， and C， which is the squared coefficient， those are。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是 DRAM，你去访问 DRAM，可能需要一个非常确定的时间来读取它。好吧？因此，服务器的确定性服务时间并非不可能，但到达率，通常是以突发的方式出现的。好吧？所以这里是参数。lambda，服务率
    T，CER 和 C，即平方系数，这些是。
- en: things that are kind of like independent variables。 And if you know them。 you
    can derive a bunch of other things like mu， which is the service， rate is one
    over T， CER。 Okay？
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一些类似于独立变量的东西。如果你知道它们，你可以推导出一堆其他的东西，比如 mu，这是服务率，rate 是 1 除以 T，CER。好吧？
- en: That's just the average number of things the server can do per unit time。 The
    utilization of the server is just lambda over mu， like we said before， which also
    comes。 out to lambda times T， CER。 What do we know？ We know that the utilization's
    got to be between zero or one or we're in trouble。 If we're greater than one，
    we know the queue is going to grow without bound。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是服务器每单位时间可以完成的平均工作量。服务器的利用率就是 lambda 除以 mu，像我们之前说的那样，也就是 lambda 乘以 T，CER。我们知道什么？我们知道利用率必须介于
    0 和 1 之间，否则我们就有麻烦。如果大于 1，我们知道队列会无限增长。
- en: So any stable system always has u less than one。 And so here are our results。
    Now in times past a number of years ago， I used to derive these for you。 At least
    the first one is very easy to derive。 I won't subject you to that。 But if you
    notice here。 the time in the queue， T， Q， is equal to the service time， the average，
    service time。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何稳定的系统，其利用率总是小于 1。所以这是我们的结果。以前几年，我曾经为你们推导过这些。至少第一个非常容易推导出来，我不会让你们受苦。但是如果你们注意到这里，队列中的时间
    T，Q 等于服务时间，平均服务时间。
- en: times u over one minus u。 Okay？ Now the general service time where we have a
    generalized service here。 not just memory， lists， looks exactly the same except
    that there's this one half。 one plus C factor here。 So notice by the way， if C
    equals one。 one plus one is two divided by two is one。 This middle thing factors
    out if we have C equal one。
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: times u over one minus u。好吧？现在我们有一个一般的服务时间，在这里我们有一个广义的服务，不只是无记忆的，看起来和之前一样，唯一的区别是这里有一个
    1/2，1 + C 的因素。所以顺便提一下，如果 C 等于 1，1 + 1 等于 2，除以 2 就是 1。如果 C 等于 1，这中间的东西就会因子化。
- en: Okay？ So the memory list service distribution is just the special case of the
    general one。 And the way we talk about this is an mm1 queue。 It's memory list
    input memory list output one queue。 The bottom one is a memory list input general
    output。 So it could be any distribution one server。 Okay？ And so if you look，
    the question is， why does the response delay grow unboundedly even though。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧？因此，无记忆的服务分布只是一般服务分布的特殊情况。我们通常称这种情况为 mm1 队列。它是无记忆输入、无记忆输出的一种单队列。底部的那种是无记忆输入、一般输出。因此它可以是任何分布，一台服务器。好吧？所以如果你看，问题是，为什么响应延迟会无限增长，尽管。
- en: utilization is less than one？ Well if you notice the closer and closer you get
    to one with you。 what happens， we blow， up here。 See that？ So the closer you get
    to one。 the more we're getting kind of on this part of the curve。 Now why is that？
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 利用率小于 1？好吧，如果你注意到，随着你越来越接近 1，会发生什么呢？我们在这里爆炸了。看到了吗？所以越接近 1，我们就越接近曲线的这个部分。那为什么会这样呢？
- en: Anybody want a hazard of guess？ Yeah。 So first of all， right。 we're assuming
    the queue is of infinite size because otherwise， this math doesn't work out， right？
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 有人想猜测一下吗？是的。所以首先，对吧，我们假设队列是无限大小的，否则这个数学公式就不成立了，对吧？
- en: Okay， yep。 Why does it go up like this？ Let me show you。 So in fact actually
    I'll show you in a second。 Let's take a brief break。 We'll come back。 I'll show
    you why it goes up。 All right。 Stand up， shake it out。 This is a rough lecture
    because there's a lot of mathematics in it。
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，是的。为什么它会这样上升？让我给你们展示一下。事实上，我会在一会儿给你们展示。我们先稍微休息一下，等会儿回来，我会给你们解释为什么它会上升。好了，站起来，活动一下。这是一堂比较艰难的讲座，因为里面有很多数学内容。
- en: So the question that was on the table was， what's causing this behavior？
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，桌面上提出的问题是，是什么导致了这种行为？
- en: Now you can derive these equations given some reasonable assumptions and you
    happen to get。 this u over 1 minus u factor。 So you could say if I were being
    particularly annoying that。 well it's just in the math， right？ The math causes
    it to go like that， end of story。 Okay。 but that's somehow a little unsatisfying，
    right？ I mean， I would find a little unsatisfying。
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以根据一些合理的假设推导出这些方程，最终得到这个`u / (1 - u)`的因子。所以你可以说，如果我特别烦人，那就是“好吧，这只是数学，数学导致了它是这样的，故事结束。”好的，但这总有点让人不满意，对吧？我的意思是，我会觉得有点不满意。
- en: So let's see if we can do something else。 Okay， so let's see if I can get this
    to advance again。
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们看看能不能做点别的事情。好的，看看我是否能让它再次推进。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_15.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_15.png)'
- en: Hello。 Where is this locked up？ Okay， so if we build this where the maximum
    utilization is at one point here and here is。 the number， this is the rate at
    which things are being served on the y-axis， then what we。 can see is as we raise
    our request rate， this green curve kind of represents maybe what。 we get out of
    the server。 Okay， and there might be a little bit of overhead。
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你好。这里被锁住了？好的，如果我们构建一个系统，其中最大利用率位于这里的某一点，并且这里是服务速率，位于y轴，那么我们可以看到，当我们提高请求速率时，这条绿色曲线大致代表了我们从服务器得到的响应。好的，可能会有一些额外的开销。
- en: That would prevent things from going forward。 So that， you know。 so we know
    for instance that in this point we can't do anything actually。 greater than mu
    max because we're utilization is greater than one that's bad。 If we look at this
    queuing that we just came up with， why does the latency blow up？
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这将阻止事情继续进行。所以，你知道的。我们知道，比如说，在这个点，我们实际上不能做任何事情，因为我们利用率大于1，这很糟糕。如果我们看一下刚才得出的这个排队模型，为什么延迟会爆炸呢？
- en: Because the queue blows up on every birth。 So the fact that we have a memoryless
    input says there's randomness on the input that's。 going to cause burstiness which
    is going to cause the queue to build up。 Okay。 and so if you look at it， we really
    have something latency wise that looks like。 this and latency is really what matters
    to us because it's how long do I have to wait。
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因为队列在每个到达时都会爆炸。所以我们有一个无记忆输入，意味着输入中有随机性，这将导致突发性，从而导致队列堆积。好的，所以如果你看，它实际上是一个延迟曲线，看起来像这样，而延迟才是我们真正关心的，因为这决定了我需要等多久。
- en: from when I submit a request to get the response back。 And we know that this
    curve that we're talking about here has proportionality of utilization。 over one
    minus utilization and so it's going to blow up as we get closer and closer to
    this， point。 Okay， so the half power point here says that we may want to try to
    find a point in which。
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 从我提交请求到收到响应的时间。我们知道，我们这里谈论的这个曲线有一个与利用率成比例的关系，公式为`利用率 / (1 - 利用率)`，因此它会在我们越来越接近这个点时趋于爆炸。好的，那么这里的半功率点表示我们可能想找到一个点，在这个点。
- en: about half of the systems use so the utilization is about 50% because that'll
    be a nice medium。 between keeping things busy and not getting this latency effect。
    Okay。 so that notion we talked about half power point is useful from earlier。
    But let's look at why do we get an unbounded response time。 So here we go。
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 约有一半的系统使用，利用率约为50%，因为这是一个很好的中间值，介于保持系统忙碌和避免延迟效应之间。好的，之前我们提到的半功率点的概念是有用的。但让我们看看为什么我们会得到一个无界的响应时间。好了，继续。
- en: Remember that if we have determinism in the arrival， then we can actually lay
    things out， like this。 Oops。 And we can use up 100% of our service time because
    we do the first service and then the。 second service and the third service and
    things arrive exactly at the right rate to be used。 by the disk or whatever。 So
    there's never any slop here， it's perfect。 Something arrives。
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，如果到达是确定性的，那么我们实际上可以像这样安排事情。哎呀。我们可以利用100%的服务时间，因为我们首先进行第一次服务，然后第二次服务、第三次服务，事情恰好以正确的速率到达，可以被磁盘或其他设备使用。因此，这里从来不会有任何浪费，一切都是完美的。东西到达了。
- en: we process it。 The next thing arrives， we process it。 We effectively keep the
    queue empty。 Okay。 now what did I say about generalized processes where a bunch
    of stuff is arriving？
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们处理它。下一个到达，我们处理它。我们实际上保持队列为空。好的。那么，我之前说过的关于广义过程的内容，指的是一堆东西到达时的情况？
- en: It's probably not deterministic。 So let's look at what happens if we add some
    burstiness here。 Okay。 so now we have a stochastic or bursty arrival process and
    now what happens is things。 arrive in a burst， here they are， did it look， and
    then they get processed in order by the。 service and then there might be a gap
    and then they arrive in a burst and we get some。
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能不是确定性的。所以让我们看看如果我们在这里加入一些突发性，结果会怎样。好的，现在我们有一个随机的或突发的到达过程，接下来发生的是事情。以突发的方式到达，它们来了，看看它们，然后按顺序进行处理。然后可能会有一个间隙，然后它们又以突发的方式到达，我们又会得到一些。
- en: processing and so on。 But notice if we go for the same arrival rate on average
    we did earlier。 then if we have， a bunch of bursts， it does mean that we have
    these blank spots。 Okay。 in order to make sure the average catches up， but it
    turns out what happens here is。 this wasted time never gets reclaimable with bursts。
    Okay。
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 处理等等。但请注意，如果我们追求与之前相同的平均到达率，那么如果我们有一堆突发流量，这确实意味着我们会有这些空白时间段。好的，为了确保平均值赶上，但事实证明，在这里发生的事情是，这些浪费的时间永远无法通过突发流量来回收。好的。
- en: you burst things grow up and as you're trying to empty things out， there's never。
    a long enough period of time for things to fully empty and that's kind of why
    we get。 this curve going up。 So the moment we start adding burstiness。 it's like
    we have a bunch of them arrive and， they start getting processed and then there
    might be a few long ones and then a bunch。
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 你让突发流量增长，而在你尝试清空这些流量时，永远没有足够长的时间让事情完全清空，这就是为什么我们看到这条曲线向上走。所以，一旦我们开始加入突发流量，就像是我们有一堆请求到达，它们开始被处理，然后可能会有一些长的请求，然后又是一堆。
- en: of them arrive and the net effect is that things just add up。 Okay。 And that's
    kind of an intuition of what's happening here。 Okay， so let's give you a little
    example。 So let's suppose that the user has a request of 10， 8 kilobyte disk I/Os
    per second。 So 10 per second is the request rate。 Suppose that requests and service
    are exponentially distributed。
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 它们到达了，最终效果是事情会累积。好的。这就是我们在这里所发生的事情的一种直觉。好的，那么让我们给你一个小例子。假设用户的请求是每秒10个，8千字节的磁盘I/O。所以每秒10个是请求速率。假设请求和服务是指数分布的。
- en: So that means first and foremost that C is one and we use a simpler equation
    and now。 assume that the average service time is 20 milliseconds。 Okay。 Now。 what
    if we want to ask some questions like what's how utilized is the disk？
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着首先C是1，我们使用一个更简单的方程式。现在，假设平均服务时间是20毫秒。好的。那么，如果我们想问一些问题，比如磁盘的利用率是多少？
- en: But what we're going to do is we're going to compute the utilization which it
    turns。 out is lambda times the service time。 And once we've got that。 then we
    can start asking questions like what's the average time， spent in the queue。 what's
    the average length of the queue。 And this last one which I think you should look
    at carefully is interesting is what's。
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们要做的是计算利用率，事实证明它是lambda乘以服务时间。一旦我们得到了它，我们就可以开始问一些问题，比如队列中花费的平均时间是多少？队列的平均长度是多少？而这个最后一个问题，我认为你应该仔细看一下，它很有趣，问的是：
- en: the average response time overall for the disk request。 And what that means
    is it's the time you spend in the queue plus the time it takes to get。 your service
    done， right？ So it's two pieces。 So T system is the queue time plus the service
    time。 And so now you can imagine a computation like this showing up somewhere
    that you might run。
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘请求的平均响应时间总体而言。它的意思是你在队列中花费的时间，加上完成服务所需的时间，对吧？所以它有两个部分。所以T系统是队列时间加上服务时间。现在你可以想象像这样的计算会出现在你可能运行的某个地方。
- en: into in a few weeks。 But for instance， you might say what's lambda lambda is
    10 per second。 Why is that it's 10 I/O per second？ Okay。 What's the service time？
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 几周后就会进入。那么比如说，你可能会问，lambda是什么，lambda是每秒10次。为什么是10？是每秒10次I/O？好的。那么服务时间呢？
- en: This is the average time to service a customer 20 milliseconds。 Okay。 Because
    it says it's 20 milliseconds。 And that's including a bunch of things like the
    controller plus C plus rotation plus transfer。 And you could imagine that the
    way you got this service time was you did a computation。 based on other things。
    But fortunately for this slide I gave it to you 20 milliseconds， right？
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是每次为客户提供服务的平均时间，20毫秒。好的。因为它说的是20毫秒。并且包括了一些因素，比如控制器加C加旋转加传输。你可以想象，你得到这个服务时间的方式是基于其他因素进行的计算。但幸运的是，在这张幻灯片上，我给了你20毫秒，对吧？
- en: And 20 milliseconds is how many seconds？ 0。02。 You guys are all very good at
    that translation now because of that magic slide from last week。 And so now we
    could say what's the utilization of the server？ Well， it's lambda times T server。
    which is 10 per second times 0。02 seconds， which is， 0。2。 So notice that the 1
    over seconds and the seconds cancel。 This is very helpful。
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 20 毫秒是多少秒？0.02。由于上周的那个神奇的幻灯片，你们现在都很擅长这个转换了。所以现在我们可以说服务器的利用率是多少？嗯，是 λ 乘以 T
    server。也就是每秒 10 次乘以 0.02 秒，结果是 0.2。所以注意，秒数的倒数和秒数相互抵消。这是非常有用的。
- en: You learned this in high school chemistry as well that you always cancel the
    units。 If your units don't cancel， you got a problem。 Okay。 And notice that our
    utilization is 0。2。 Is that bigger than 1？ Good。 People are paying attention。
    I'm glad。 So no， 0。2 is not bigger than 1。 So now what's the time in the queue？
    Well we use this version of the equation T server times u over 1 minus u because。
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你们在高中化学课上也学过，你总是需要抵消单位。如果你的单位没有抵消，那么你就遇到问题了。好的，注意到我们的利用率是 0.2。这个大于 1 吗？很好，大家都在注意。很高兴。所以不，0.2
    不大于 1。那么现在队列里的时间是多少？我们使用这个版本的方程，T server 乘以 u 除以 1 减去 u，因为。
- en: well， that's the memory， the MM1， Q memoryless in memoryless out one server。
    Okay。 And so we just plug it in。 Service time is 20 times 0。2 over 1 minus 0。2。
    That's the queuing equation gives us 20 times 0。25， which says 5 milliseconds。
    What is that 5 milliseconds at 5 milliseconds at the time you spend in the queue？
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那就是记忆，无记忆的 MM1 队列，一个服务器。好的，所以我们直接代入。服务时间是 20 乘以 0.2，再除以 1 减去 0.2。这就是排队方程，它给出的结果是
    20 乘以 0.25，结果是 5 毫秒。那么这 5 毫秒是排队花费的时间吗？
- en: Now notice because of the parameters we've got here， that's only a fraction
    of the total。 disk service time。 That's good。 It means we're not building our
    queue up。 Okay。 If we had different numbers here， such that this utilization got
    like 0。8 or 0。9， this。 would be considerably longer time spent in the queue。 Okay。
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在注意到，由于我们这里的参数，它只是总磁盘服务时间的一小部分。这很好，意味着我们没有让队列堆积起来。好的。如果这里的数字不同，比如这个利用率变成了 0.8
    或 0.9，那么队列中花费的时间就会显著增加。
- en: And that's the point at which it builds up and you got problems。 But let's finish
    this example。 So now if I'm a user and I put a request into this queue， how long
    till I get my answer？ Well。 first of all， how long is the queue？ The queue is
    lambda times TQ。 There's little's law gives us 0。05 items in the queue on average。
    So the queue is really not a function here， right？
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是它开始累积并出现问题的地方。但我们先完成这个例子。所以现在如果我是一个用户，我把请求放入这个队列，我要多久才能得到答案？嗯，首先，队列有多长？队列是
    λ 乘以 TQ。根据小法则，队列中平均有 0.05 个项目。所以在这里，队列实际上不是一个函数，对吧？
- en: But if we look at the system time total， it's TQ plus T， sir， and it says that
    when I take。 queuing into account， rather than it taking 20 milliseconds， it actually
    takes 25 milliseconds。 So there's a little extra time in the queue。 All right。
    Now this is an exercise to you guys if you were to try adjusting this so that
    lambda。
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们看看系统的总时间，它是 TQ 加 T server，它告诉我们，当我考虑排队时，实际上它需要 25 毫秒，而不是 20 毫秒。所以队列里多了一些额外的时间。好了，现在这是一个练习，如果你们试着调整它，使得
    λ。
- en: was faster and so that this 0。2 was closer to 1， you would see this number could
    go arbitrarily。 large。 In fact， it could be easy to come up with 100 milliseconds
    or 200 milliseconds purely because。 of the queuing time having nothing to do with
    the fact that the disk always takes 20 milliseconds。 Okay。 And so the reason I
    go， I subject you guys to learning a little bit about queuing theory。
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果更快一些，让这个 0.2 更接近 1，你会看到这个数字可能会无限增大。事实上，纯粹因为排队时间的原因，可能很容易得到 100 毫秒或 200 毫秒，而与磁盘总是需要
    20 毫秒的事实无关。好的，之所以让你们学习一些排队理论，就是这个原因。
- en: is I want you to realize that the queue can become easily the most significant
    contributor。 to latency easily if you're running too close to that 100% utilization
    point。 So whenever you're doing a back of the envelope calculation， you might
    try to figure out what。 is what is the utilization of one mean in terms of whatever
    operations per second， how。
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我想让你们意识到，队列很容易成为延迟的最大贡献者，尤其是在你们接近 100% 利用率的情况下。所以，每当你做一些粗略的计算时，可能会尝试去弄清楚一个利用率意味着什么，每秒多少操作，如何。
- en: close am I to one？ Okay。 And I would say the best advice you can get out of
    this class as being engineers in general。 is you never run anything at 100%。 If
    you're running anything at 100%， something's going to break。 Right。 It's much
    better to run at that half power point or maybe a little bit larger than that。
    but never get close to 100%。 Either in the weight capacity of a bridge， that's
    a bad idea。
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我离1有多近？好吧。我会说你从这门课中得到的最好建议是，作为工程师，普遍来说，永远不要让任何东西运行在100%负载下。如果你让某个东西运行在100%负载下，某些东西就会坏掉。对吧？最好是运行在半负载点，或者稍微大一点的负载下，但永远不要接近100%。就像桥梁的承载能力，接近100%是个坏主意。
- en: or the number of requests。
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 或请求的数量。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_17.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_17.png)'
- en: per unit time you're trying to get out of a system。 Okay。 Now。 there's a bunch
    of resources we have on the resources page you can take a look at。 that have some
    things from the Hennissian Patterson book and so on。 And you should definitely
    assume that back of the envelope queuing theory like we've been。
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 你试图从系统中获取的单位时间。好吧。现在，资源页面上有一堆资源你可以查看，其中包含一些来自Hennissian Patterson书籍的内容等等。你应该绝对假设我们之前讨论的类似于信封背面排队理论的内容。
- en: talking here is fair game for mid-term three。 Okay。 But now that we know what
    the queue could do to us， we can start asking questions about。 how do we optimize
    IO performance。 Well， response time is really queue plus other stuff。 And so how
    do we improve performance？ Well， we could make everything faster。 Okay。
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的内容是期中考试第三部分的内容。好吧。但现在我们知道了队列可能对我们产生的影响，我们可以开始问如何优化IO性能。其实，响应时间就是队列加上其他因素。那么我们如何提高性能呢？好吧，我们可以让一切变得更快。好吧。
- en: I have a little smiley face there， but that's not a bad solution if we let you
    do that right。 on the mid-term。 Maybe we don't let you do that。 But always consider
    if something's a bottleneck。 what did we talk about scheduling？ Scheduling only
    matters if there's not enough of something。 right？ Queuing theory gets in the
    way when there's not enough of something。
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我那里有一个小小的笑脸，但如果我们允许你这样做，作为期中考试的解决方案也不算坏。也许我们不允许你这么做。但总是要考虑某些东西是否是瓶颈。我们之前讲过调度问题吗？调度只有在某些东西不够用的时候才重要。对吧？当某些东西不够时，排队理论就会成为障碍。
- en: So always consider maybe making things faster。 The other is maybe more parallel。
    Okay。 If I have a bunch of disks and they're spread out， then maybe I could send
    requests to all。 of the disks and now everything is faster by parallelism。 Okay。
    And we're going to actually toward the end of the term， we will be talking about
    distributed。
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 所以总是考虑也许可以加速一些操作。另一个可能是更多的并行处理。好吧。如果我有一堆磁盘并且它们分散开来，那么也许我可以向所有磁盘发送请求，利用并行性让一切变得更快。好吧。我们实际上将在学期末讨论分布式系统。
- en: systems and parallelism that you can get out of things that are spread through
    many servers。 in the network。 That could be a way of improving queuing time by
    spreading things out for many queues。 Okay。 Now， we could optimize the bottleneck
    to increase the service rate。 Okay。 So there's maybe we'd get a faster controller
    or slightly faster device here。
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 系统和并行性可以帮助你从分布在许多服务器上的东西中获得。网络中的那种方式。那可能是通过将事情分布到许多队列中，从而提高排队时间的一个方法。好吧。现在，我们可以优化瓶颈来提高服务速率。好吧。也许我们会得到一个更快的控制器，或者这里有一个稍微快一点的设备。
- en: We could accept the queue and do something else。 We compute a few more digits
    of pi while we're waiting for a response。 So there are other things we can do。
    But queues are useful。 Okay。 If the one response to this could be， well， this
    is a problem that's removed the queue。 Who needs a queue？ Okay。 But remember，
    the reason the queue was there in the first place was to absorb bursts because。
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以接受队列并做些其他事情。比如在等待响应时，我们可以计算更多的圆周率数字。所以我们可以做其他的事情。但队列是有用的。好吧。如果回应这个问题的答案是，嗯，这个问题已经消除了队列。谁需要队列呢？好吧。但记住，队列最初存在的原因是为了吸收突发流量，因为……
- en: bursts are the real world。 And if you have a queue that can absorb some bursts。
    then the things that are generating， the requests don't have to wait around just
    to put their thing on the queue。 So that's why we have a queue。 So queues are
    very important to smoothing the overall behavior of the system as a whole。 So
    you can't really get rid of queues， but you need to know they're there。 All right。
    Now。
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 突发流量才是现实世界中的情况。如果你有一个队列能够吸收一些突发流量，那么生成请求的东西就不必在队列中等待。所以这就是为什么我们需要队列的原因。队列对平滑整个系统的行为非常重要。所以你不能真正去除队列，但你需要知道它们的存在。好了，接下来。
- en: and then for finite queues， obviously， you need to do some pushback on people
    putting。 stuff on the queue。 So that's admission control。 So when is the disk
    performance the highest？ Okay。 Thinking back for a moment。 When there are big
    sequential reads or there's so much work to do that they can be piggybacked。 so
    you can reorder queues。 It's okay to be inefficient if things are mostly idle。
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有限队列，显然你需要对把东西放入队列的人进行一定的拒绝控制。这就是接纳控制。那么，磁盘性能何时最高呢？好，回想一下。当有大量顺序读取，或者有太多工作需要做，能够合并处理时，你可以重新排列队列。如果大多数时间都处于空闲状态，那么低效也是可以接受的。
- en: So if you don't have so many things that your queues are filling up， maybe you're
    less， efficient。 It's only when your queues are filling up that it's very important
    to be extremely efficient。 at that disk。 Okay。 So bursts are a threat and an opportunity。
    They're a threat because they cause the queue to grow。
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你的队列没有那么多任务堆积，也许你会效率较低。只有当你的队列开始填满时，才特别需要提高效率。好了，突发情况既是威胁，也是机会。它们是威胁，因为它们导致队列增长。
- en: They're an opportunity because they'll let you guarantee there's always something
    there。 to you to satisfy and therefore you can keep the system busy。 That could
    actually be a good thing。 right？ Because when you're in this， I should say that
    before we lose this whole thought process。 When I'm in this point here， where
    I'm close to 100% utilization and the average latency。
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一个机会，因为它们让你确保系统始终有事情可以做，因此可以保持系统繁忙。这其实是件好事，对吧？因为当你处于这个状态时，我应该先说一下，在我接近100%利用率而且平均延迟很高的时候。
- en: is really high， what's happening with the disk？ If you just look at it from
    the standpoint of this queue。 it looks bad。 But what's happening with the disk？
    It's working， right？
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 那么磁盘发生了什么？如果你从队列的角度看，它看起来很糟糕。但是磁盘发生了什么？它在工作，对吧？
- en: The disk is efficiently doing stuff all the time。 That could actually be a good
    thing， right？
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 磁盘一直在高效地工作。这其实是件好事，对吧？
- en: If you put in an expensive resource， you want to keep it busy。 So you've got
    to be able to go back and forth between the latency of any one request grows。
    without bound。 But the thing was when the queue is full， we know the expensive
    resource is busy。 So keep that in mind。 Okay。 So this is why we talk these through
    with you。
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你投入了昂贵的资源，你就想让它保持忙碌。所以，你必须能够在延迟之间来回切换，尽管任何单个请求的延迟是无上限的。但关键是，当队列已满时，我们知道昂贵的资源在忙碌。因此，记住这一点。好的，所以我们跟你们讲这些。
- en: And so other opportunities， which we'll talk a little bit about toward the end
    of the term。 and in the next couple of lectures too， is we could use user level
    device drivers to make。 things faster。 We could reduce the impact of I/O delays
    by doing other useful work。 These are all about making overhead smaller， doing
    something else when you have to wait， for things。
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 所以还有其他的机会，我们将在学期末稍微谈一谈，接下来的几节课也会提到， 我们可以使用用户级设备驱动程序来提高效率。我们可以通过做其他有用的工作来减少I/O延迟的影响。这些方法的核心是减少开销，在等待时做些其他事情。
- en: These are all， you know these things because we've been talking about them all
    term。 One process goes， or one thread goes to sleep， but another one works。 And
    now today you learned about reducing the overhead as well。 Okay。 So I'm going
    to pick up with disk scheduling next time。 But let's in conclusion。
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些你们都知道，因为我们整学期都在讨论这些。一旦一个进程或线程进入休眠，另一个进程就可以继续工作。今天你们也学到了如何减少开销。好了，下一次我会讲磁盘调度，但让我们总结一下。
- en: I'll let you guys go， disk performance is really queuing time。 plus controller
    and then plus seek plus rotational plus transfer time， those five elements。 And
    remember the rotational latency， the time to get to the or sector once you've
    gotten。 to the right track is on average half a rotation on average， right？
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我让你们自己去理解，磁盘性能实际上是排队时间加控制器时间，再加上寻道时间、旋转时间和传输时间，这五个要素。记住，旋转延迟是指一旦到达正确的轨道，寻找到扇区的时间，平均来说大约是半个旋转周期，对吧？
- en: And then the transfer time is a disk spec， excuse me。 We talked about complex
    interactions with the queue and so for hard disk drives， you've。 got queuing time
    plus controller plus seek plus rotation plus transfer。 SSDs are simpler because
    you just the controller time plus the transfer time。
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然后传输时间是磁盘的规格，抱歉。我们讨论了队列中的复杂交互，因此对于硬盘驱动器来说，你有排队时间、控制器时间、寻道时间、旋转时间和传输时间。SSD则更简单，只需要控制器时间加传输时间。
- en: We talked about systems being designed to optimize performance and reliability
    and bursts。 and high utilization give you lots of queuing delays。 So we introduced
    the queuing latency equation。 And the thing to keep in mind is we gave you two
    equations， but they're really the same， equation。 If you look at what we've got
    here， if you set C to one， this thing collapses down to。
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了系统设计旨在优化性能、可靠性和突发情况，而高利用率会导致大量的排队延迟。因此，我们引入了排队延迟方程。需要记住的是，我们给出了两个方程，但它们实际上是相同的方程。如果你看看这里的内容，如果将
    C 设置为 1，这个方程就会简化成。
- en: the MM1 queue。 If you set C to something non one， then this is the MG1 queue。
    Okay。 And so with that， I'm going to say have a great rest of your Tuesday and
    we'll see you， on Thursday。 All right。 [ Silence ]。
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: MM1 队列。如果你将 C 设置为非 1 的值，那么这就是 MG1 队列。好的。那么就这样，我祝你度过一个愉快的星期二下午，我们周四见。好的。[沉默]。
- en: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_19.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7e8fedabeca3779235890b7a1e5c0fd_19.png)'
