# P12：第12讲：调度3 饿死（已完成），死锁 - RubatoTheEmber - BV1L541117gr

好的，大家能听到我说话吗？

![](img/e43763a2764cb9b447c151b8565693fa_1.png)

好的，开始吧。这是我们关于调度的第三讲。我们将讨论一些其他的调度算法。然后我们会讨论饿死问题，接着谈谈死锁，如何检测死锁以及如何避免或防止死锁。好的。

所以请记住，在之前的实时调度讲座中，我们讲到的目标是性能的可预测性。所以我们希望能够以高度的信心预测出给定系统的最坏响应时间。现在，在实时系统中，性能保证可能是任务级别的，也可能是类别级别的。

我们希望提前保证这些任务的可预测性。所以，当我们对比常规系统时，我们看到的是，常规系统的性能可能是系统导向的，或者可能是吞吐量导向的。然后我们回头看，看看我们的吞吐量、性能在上一次怎么样。

比如一分钟或者十分钟。对于实时系统，关键是强制执行可预测性，对吗？

这不一定等同于快速计算。所以当我们考虑硬实时系统时，这就像你车上的防抱死制动系统，或者类似的东西，它们是时间关键的安全系统。很多时候，这也可能是工厂自动化，你有机器人之类的。

我们希望在可能的情况下满足所有的截止日期。我们希望设计我们的系统、配置我们的资源，确保我们始终能够按时完成任务。因此，我们需要根据系统中的任务数量以及我们拥有的资源来提前确定如何为这些任务提供服务。

我们看了很多不同的调度算法，以便能够做到这一点。现在，相比之下，还有我们为多媒体使用的软实时系统。对于在家中的你们来说，之间有很多系统，它们都在使用软实时来尽力保证我的视频和音频能够顺利传输。

这是没有中断的。但是没有保证，这意味着偶尔你可能会看到帧跳跃或者听到音频跳跃。好的，现在如果我们看看像“最短剩余时间优先”或者“多级反馈队列”这样的算法，它们容易发生饿死吗？如果你仔细想想，在像“最短剩余时间优先”这种情况下，我们可能会遇到...

这样做就会让那些长时间运行的任务因为短时间运行的任务而饿死，对吧？因为这是最短剩余时间优先算法的特点。我们在优先级调度中也遇到了相同的根本问题——我们把所有时间都给了高优先级的任务，而不给低优先级任务分配时间。现在，如果我们看看像多级反馈队列这样的算法，它只是一个近似方法。

对于我们来说，实施 SRTF（最短剩余时间优先）时，我们更多是回顾过去的性能，而不是预测未来应用程序的 CPU 使用情况。所以它会遇到同样的问题，对吧？我们将从长时间运行的任务开始，这些任务会在高优先级队列中启动，短时间量的队列。

它们将不断地到达时间片的末尾，但仍然希望继续运行。所以它们最终会被降级到最低优先级队列。如果我们看一下 CPU 分配的情况，如果高优先级队列中有任务，它们会先被运行，这就意味着其他长时间运行的任务将只能等待。

任务将会被启动。好，现在想想看，对吧？

到目前为止，我们研究的调度策略都围绕着优先级。我们希望将 CPU 分配给那些优先级更高的任务，这意味着那些优先级低或者没有优先级的任务可能永远无法运行。它们会被启动，但我们没有用优先级来表示“我们希望系统做什么”。

这主要是为了给系统提供不同类别的任务处理方式。我们希望能够让系统明确表示，嘿，这个任务比那个任务更重要，而不是只运行这个任务，完全忽略其他任务。所以，如果你这样想，我们的最终目标是：我们希望系统能够处理大量不同类型的任务。

有些任务是 CPU 密集型的，有些是 I/O 密集型的，有些是交互式计算的，有些是多媒体任务。我们希望系统能够运行所有任务，而不仅仅偏向某一类任务，只运行其中一类。所以我们需要考虑这一点，对吧？我们的 I/O 密集型任务，当它们完成一个 I/O 操作后，它们只需要足够的 CPU 时间来继续执行。

可以调度 I/O 设备进行下一个 I/O 操作。同样地，如果我们有交互式任务，我们希望性能良好。当你输入一个按键时，我们不希望按键的响应需要几秒钟的时间才能显示出来。而对于我们那些 CPU 密集型的任务，我们希望它们高效运行。我们希望能够快速执行它们。

尽可能快速地将任务处理完。像上下文切换这样的操作，只会让 CPU 密集型任务运行得更慢，因为上下文切换会带来额外的开销。

![](img/e43763a2764cb9b447c151b8565693fa_3.png)

同时，也要考虑我们所处的环境。当我们回顾计算机发展的初期，回到 50 年代和 60 年代，那个时候的计算主要依赖大型计算机，对吧？每台计算机背后都需要很多人共同使用。刚开始时，世界上只有少数几台大型计算机，它们服务着成千上万的用户。

如果你想想这些主机的成本，它们的价格从数百万到数千万美元不等。所以在这些机器上，计算周期是非常昂贵的。但是现在看看我们所处的位置，物联网时代。如果你坐在一辆现代汽车里，你会发现自己被数十台计算机所包围。

你周围可能有40台不同的计算机、微控制器、微处理器。只要环顾四周，你会发现计算机无处不在。所以，比例发生了彻底的变化。每人拥有多台计算机。现在计算周期便宜了。但是，当我们最初开始考虑调度时，是在那种背景下——成千上万的用户共享计算资源。

我们需要在成千上万的用户之间共享如此宝贵的计算周期，这些用户使用我们的主机。因此，调度程序的设计确实是围绕优先级来进行的，以便为CPU密集型任务、I/O密集型任务等分配资源。在80年代，我们看到了个人计算的崛起。因此，计算机的使用比例从成千上万的人共享一台计算机，变为一人一台计算机。

在那个时候，计算周期的价值大大降低。即使我们看工作站或网络服务器，像是部门文件服务器，它可能只服务100个人。所以，现在的不同机器开始有了不同的用途。我有一个网络文件服务器，它是专门用来提供文件服务的计算机。

现在不进行任何计算。没有互动，只是提供内容。现在的转变是公平性和避免极端情况。我们不希望这些环境中出现资源饥饿。回想一下90年代，我们看到了云计算数据中心的兴起。于是，50,000台计算机被放置在一个仓库里。

现在我考虑在谷歌的Docker上运行Google幻灯片，制作我的课程幻灯片，而不是在我的笔记本电脑上运行它。它是在一个数据中心运行的，我和这个区域内的数百万其他用户共享这个资源。几乎回到了主机时代，只不过不再是单一的计算机，而是成千上万台计算机协同工作，以尽可能高效的方式运行。

为我提供一种交互体验，几乎和我在本地运行PowerPoint时一模一样。所以当你开始思考时，现在你要考虑的是可预测性，比如95百分位的性能保证。你不得不做大量的系统工程，这真是令人惊叹。

目标是让这50,000台计算机表现得和我本地运行的应用程序一样。但我也得到了服务器整合的好处。管理一个填满了50,000台计算机的数据中心，比管理一堆桌面PC更高效。同时，你还需要处理一些突发流量。想象一下，如果你是CNN。

比如说你是《纽约时报》的一员，上周你观察到你的网络和系统流量，在几分钟到几小时的时间内，从原来的基准值增加了100倍。尽管如此，最终用户仍然看到了相同的第95百分位性能，因为你在这些数据中心里做了大量的扩展。

如果只有一台机器，而我突然需要处理比平常高 100 倍的流量，那就难得多了。好的。那么我们真正要问的问题是，如果我们要优先处理一些工作任务，是否意味着那些没有被优先处理的任务将会被饿死？嗯，按照我们所看过的方法，的确会发生这种情况。对吧？

那些优先级较低的工作，如果有足够的高优先级工作，这些低优先级工作将永远无法执行。我们的所有 CPU 都将分配给这些高优先级工作。因此，我们可以考虑一些方法，确保始终为这些低优先级工作分配一定的 CPU 份额。对吧？所以，采用基于优先级的调度。

我们总是会倾向于将 CPU 优先分配给优先级更高的任务。如果就绪队列中有优先级更高的任务，它就会得到执行。这意味着低优先级的任务可能会被饿死。那么相反的做法是，我们可以考虑按比例分配 CPU。

因为最终，这就是我们想要的。对吧？你知道，我们有一组多样化的应用程序在运行，我们希望每个应用程序都能得到一定份额的 CPU。优先级更高的应用程序，我们希望分配更多的 CPU 份额。优先级较低的应用程序。

我们希望获得更少的 CPU 份额，但仍能获得一些 CPU。如果我们不希望它们获得任何 CPU，我们就根本不会将它们接入系统。对吧？好的。所以目标是，如果每个任务根据其优先级分配一定的 CPU 份额，那么低优先级任务的运行频率会更低，但它们仍然会运行，不会饿死，直到它们完成。

能够取得进展。对吧。记住彩票调度法。这里的基本思想是，在给定一组工作任务，或者说工作任务的混合时，我们将为每个任务分配一定份额的票数。对吧？

所以在这种情况下，我们将把 50% 的 CPU 分配给任务 A，30% 分配给任务 B，剩下的 20% 分配给任务 C。因此，我们将根据任务的优先级分配票数。我们可以看到，例如，任务 A（红色）获得了大量票数。它获得了 50% 的票数。

任务 C 获得 20% 的票数，而任务 B（蓝色）获得 30% 的票数。现在，在每个时间片，每次时钟滴答声中，我们都需要做一个调度决策。我们将随机抽取一张票，安排相应的任务或线程运行。所以我们可以使用的简单机制是将所有票数加总起来。

非常棒，选一个飞镖，投掷那个飞镖，然后任务记录它们分配到的票据数量。它们按票据数量排序，然后我们就选择前J个票据，使得这些票据的总和大于飞镖落的位置。好的，这种方法的问题是，它在长期内表现良好，但在短期内却不一定有效。

在短期内，我们可能会遇到大量的不公平现象。所以我们有两个任务，任务A和任务B，它们具有相同的优先级和相同的运行时间。我们为它们分别分配50%的票据，按理说，任务A的运行时间相对于任务B的运行时间应该是相同的。若我们计算它们的比率，那比率应该是1。

你会发现，对于较短的运行时间任务，它可能非常不公平。那么，为什么呢？

为什么它不会正好是50%呢？它有一半的票据。有什么想法吗？

我是如何选择哪个任务运行的？我使用一个伪，哦，我是怎么选择的？

我使用了一个伪随机数生成器，其中有“伪”这个关键词。它不是一个真正的随机生成器，它会在生成的值中存在一些偏差。顺便说一下，很多重新调度的工作花费了几个月的时间来设计一个既快速又高效，同时在调度决策中非常均匀的伪随机数生成器。

它生成的值的分布。事实证明，实际上，即使你尝试这么做，如果你看较小的抽样集，因我的调度，调度决策的次数很少，所做的调度决策次数不多，我会看到那些偏差。如果我从我的伪随机数生成器中生成数百万个伪随机数，它会。

看起来很均匀。但是在一个小子集中，它可能看起来非常、非常有偏差。而这是生成随机数时遇到的问题。这个问题出现在各个地方，特别是在安全上下文中，我正在生成一个密钥的随机位。如果我知道使用了什么伪随机数生成器，并且了解其中的偏差，我就能知道它生成的。

初始条件和种子，我通常可以通过高度的概率预测出你的秘密密钥是什么。很多设计加密应用中随机数生成器的工作，目的就是避免别人通过猜测随机数的选择来猜出密钥。好的，这里面临的问题是，随机性并非真正的随机，这破坏了。

所以作为一种替代方法，人们提出了步幅调度（stride scheduling）。在这里，思想是我们希望在给定每个任务的情况下，实现相对CPU的比例调度，而不需要使用随机性。因此，我们将避免使用类似大数法则的逆法则，也就是小数法则。

我们看到的偏差问题。所以任务的步长是一个大数除以基本上你分配到的份额。所以如果你考虑一下，你拥有的票证份额越大，你最终的步长就越小。所以在这个例子中，如果我们将 W 设置为 10,000，并且给 a 100 个票证，那么我们会。

给 a 分配 50 个票证，b 分配 250 个票证，那么 a 的步长是 100，b 的步长是 200，c 的步长是 40。现在每个任务都会有一个通过计数器，调度器将会选择通过计数器最小的任务来运行。

在那个任务运行后，我们会获取步长并将其添加到通过计数器中。在运行一个量子后，添加通过计数器。因此，如果你考虑一下，这意味着拥有大量票证的任务，步长较小的任务，其通过计数器的增加速度会比其他任务慢。

拥有更少的票证和更大的步长，因此它们的通过计数器会更快地增加。由于我们选择的是具有最小通过计数器的任务，因此我们会更频繁地运行那些拥有更多票证的任务。但最终，它们的通过计数器将超过那些票证较少任务的计数器，然后票证较少的任务将会运行。

你可以看到，我们在预先计算我们希望的分数，并且我们已经从方程中去除了随机性。是的，问题是，如果我们有一个运行时间非常长但票证数很少的任务，我们需要处理像计数器溢出这样的问题。是的，所以有很多复杂的问题我们需要担心，因为我们希望。

要能够处理这样一个事实，即使我们有很多短时间运行的任务，随着时间的推移，我们的通过计数器也会溢出，另外，你有新的任务加入系统，我们应该将它们的默认通过计数器设置为多少，以避免它们总是运行直到赶上系统中的其他任务。

所以总是有像这样的细节问题我们需要担心。但是关键是，即使是那个只有少量票证的运行时间非常长的任务，它仍然能够运行，这就解决了我们在基于优先级的系统中遇到的问题。还有其他问题或评论吗？好，好的，那么我们来看一下另一个调度器，Linux 完全公平调度器。

这个调度器的目标是，我们希望给每个进程分配相等的 CPU 时间。哦，问题是 W 是否只是一个任意选择的大数？是的，我们希望选择一个非常大的 W，这样我们就可以有一个良好的范围来设置我们的步长。好的，所以这里的目标是每个进程都能获得相等的 CPU 时间，我们有 n 个线程。

所以我们需要一些东西来保持同步，以便最终能够实现这样的情况：当我们查看时，我们可以看到所有线程在CPU上**几乎同时执行**。所以可以这样理解：你有n个线程同时在一个CPU的周期上执行。这就像我们之前讨论过的**同时多线程**的概念，我们可以通过利用额外的功能单元，来同时运行多个线程。

如果这是一个完美的环境，完美的世界，我们如果在任何时刻查看，我们会看到CPU时间的分配是均等的。也就是说，线程1、线程2和线程3每个都有一个周期。通常来说我们无法做到这一点，因为真实的硬件并不是这样工作的。

为了让整个CPU工作，或者通过SMT技术，我们可能会调度少量的线程，比如2个线程同时执行。因此，对于一个特定的量度，现在我们暂时假设一个线程将获得CPU的一个周期。

我们看到它们都得到了相等的CPU时间。好了，这里是我们要做的基本框架。我们将跟踪每个线程使用的CPU时间，然后调度线程，确保我们能够达到每个线程一个周期的目标。所以每个人都应该有一个周期的时间。

也就是说，平均执行速率基本相同。那么我们该如何实现呢？

这完全是关于调度决策的问题。我们该选择哪个线程来运行？

当我们需要做出这个决定时，我们会查看所有线程，并尝试修复**执行速度最慢的线程**。所以这将修复这个**完全公平的错觉**。这里有一个例子，线程一已经领先，它的运行时间已经超过了一个周期。

线程二运行时间少于一个周期，而线程三则已经完成了一个周期。所以，如果我们要修复这个错觉，我们会选择哪个线程呢？

是的，我们会选择蓝色的线程二。因为线程二落后了。所以它没有那个“公平”错觉，因为它的公平份额应该是一个周期。而且这与稍后我们在讲解网络时会讨论到的一个叫做公平排队的概念非常相似。好，我们将使用一个堆调度队列来实现这一点，它可以为我们提供不错的**等效的平均执行率**。

它的行为将是O(log n)的复杂度，其中n是线程的数量，用来添加或移除线程，所以我们可以高效地做出调度决策。好，现在想想看，如果一个线程处于休眠状态，它的CPU时间就不会前进。那么当你敲击键盘时，等待中的线程会发生什么呢？

当IO事件被唤醒时，它会滞后，所以它会立即运行。这对于交互性能和响应性非常有利。所以，除了保证公平性，我们还希望系统有一个低响应时间，这使它适合交互式计算，并且我们希望确保它不会受到任何。

所谓的饥饿现象。但是每个进程至少应该能运行一点。因此，我们必须解决几个约束条件。一个是我们想要有目标延迟，所以我们需要设定一个线程得到响应的时间上限。

所以这将是我们的量子，接下来我们必须设置我们的调度量子。量子将是我们目标延迟与系统中线程数的函数。因此，如果我们的目标延迟是20毫秒，而我们有四个进程，那么我们的量子将只是简单地设置为5毫秒的时间片。

好的，这很有道理，但是如果我们有很多线程，很多进程，比如200个呢？

那么这就意味着我们应该使用0.1毫秒的量子。这是一个问题。回想一下轮询调度算法，轮询调度的一个大问题就是选择合适的量子大小，以免我们最终把所有时间都花在保存和加载寄存器上。所以这就是为什么我们需要对我们的量子设置最小值的原因。

即使这意味着我们无法达到目标延迟，权衡的结果是，我们可以尝试使用0.1毫秒的量子，但最终我们将会花费大量时间在上下文切换上。因此，我们无论如何都无法达到目标延迟。好的，Linux CFS的另一个目标是吞吐量，这意味着我们必须避免过多的开销，这也意味着我们不能有过多的上下文切换。

所以这实际上会给我们设定一个最低的粒度，量子也应该遵循这一规则，这样我们就不会把所有时间都花在上下文切换上。因此，我们将为特定架构选择一个合理的量子下限，从而得出合理的开销上限。

上下文切换。好的，现在我们的目标延迟可能是20毫秒，最小粒度为1毫秒，假设有200个进程，那么我们将给每个进程分配1毫秒的时间片。好吧，稍微偏题一点，因为我们需要讨论一下优先级是如何设置的，用户在Unix系统中如何与优先级交互。

所以，当我们回顾人们在60年代和70年代使用的工业操作系统时，优先级只是一个整数，你指定它并强制执行你所设定的目标调度策略。当他们在伯克利开发Unix时，他们的思考是，与其将其视为简单的优先级，不如让用户彼此友好。

在 Unix 中，实际上有一个系统调用叫做 nice 系统调用，用于设置进程的优先级。优先级的范围从负 20 到正 19。负值意味着进程不友好，正值表示友好。所以，如果你想对与你共享系统的朋友好一点，你就将你的进程的 nice 值调高。

这将导致系统给你分配更少的 CPU 时间，你的进程将花更多时间在就绪队列中。你的朋友的进程将获得更多的 CPU 资源。相反，如果你不想对你的朋友好，你只需将所有进程的 nice 值设为 -20，它们就会运行，你知道这样做并不好。

保持朋友们在外面。好的，那么调度器将会把那些优先级较高的进程保留在就绪队列中。它们不会那么频繁地运行，而优先级较低的进程将能更频繁地运行。现在，对于一个一阶调度器，这将直接转化为优先级。但在 Linux CFS 中，我们将以不同的方式来看待这个问题。

好的，那么在 Linux CFS 中，我们将改为根据进程的 nice 值或优先级来调整它们获得的 CPU 周期速率。那么我们该如何做到这一点呢？

好吧，想一想，如果我们想给一些进程更多的 CPU 资源，而给其他进程更少的 CPU 资源。那么我们想要不同的比例分配，但要保证每个进程都能得到一些资源。我们的模型是，我们希望不同的线程在一段时间内能够获得不同数量的 CPU 周期。

那些我们希望给予较低优先级的进程，在一段时间内将获得较少的 CPU 周期。所以，最简单的方法就是通过权重来实现这一点。我们将为每个进程分配一个权重 W_i，这样我们就能计算出切换时间片的大小，也就是我们允许进程运行的时长。

如果每个进程都获得相等的份额，我们只需简单地将每个进程的权重设为 1。然后，我们就可以应用基本的计算方式：这就是 1 除以总权重的和，乘以目标延迟。那就是 n。

它将是 1 除以 n 乘以我们的目标延迟，这就是我们基本的平均分配。现在，我们有灵活性，如果我们想增加或减少某个进程的优先级，只需更改它的权重，这样就能给它不同的资源份额。让我们看一下实际应用。我们将用 nice 值作为优先级的代表，因为这是用户设置优先级的方式。

Unix会告诉系统这个任务的优先级高或低，较低的值表示较低的优先级，负值表示“不友好”，较高的值则表示优先级较高。所以可以理解为一个反向的关系，如果你这样思考的话。我们将使用“nice值”来调整我们的权重，通过一个指数函数来实现。所以它会是1024除以1。

nice值的5次方的25。假设我们有两个CPU任务，它们的nice值差为5。这意味着优先级较低或nice值较低的任务将最终获得三倍于高优先级任务的权重。所以1.25的5次方大约等于3。是的。所以问题是，如果它是三倍速率，它是否就能运行三倍的时间。

是的，它将运行三倍的时间。它将获得更长的量子时间，并且会按照调度的方式来执行。接下来，我们还需要处理如何分配CPU时间以及如何选择下一个要运行的任务。好了，这就引出了我们下一个要讨论的点，那就是我们将不再使用实际的CPU时间。

所以，我们将使用虚拟运行时间的概念，而不是壁钟时间。我稍后会解释这是什么意思。好了，给你一个例子，我们的目标延迟是20毫秒，最小粒度是1毫秒，我们有两个CPU绑定的线程，它们可以在我们允许的情况下持续运行。假设线程A的权重是1，线程B的权重是4。

那么线程A的时间片是多少，另外我们的总权重是5。好了，A的权重是1，回到之前的例子，它将是1除以总权重5，再乘以目标延迟20，得到的结果是4毫秒。这就是A在被调度时的运行时间。

对于B，它的时间片将是4，这就是它的权重4除以总权重5，再乘以目标延迟20，得到的结果是60，因此它将运行16毫秒。这样，我们就能达到目标延迟，或者我们将按照20%的比例分配给A，80%分配给B。如果我们查看物理CPU时间或壁钟时间，可能会是这样的。

我们会看到这种不对称性，B会在这16毫秒的时间段内运行，而A会在更小的4毫秒时间段内运行。但我们将跟踪线程的虚拟时间，简单地理解就是，如果你有更高的权重，你的虚拟。

运行时间将增长得较慢，如果你的权重较低，你的虚拟运行时间将增长得更快。因此，在这个虚拟世界中，我们可以保持A和B获得相等的份额，但当它们实际运行时，B将运行得更长，并且会更频繁地被调度。好了，我们的所有调度决策都基于虚拟时间，因此我们只需继续跟踪我们的。

红黑树包含了所有可执行的进程，我们会寻找最左边的元素，也就是最小的虚拟时间元素，因为我们再次尝试修复这个问题。每个人都得到一个时间片的幻觉，但实际上是虚拟时间中的时间片，而不是 CPU 时间。我们通过`O(1)`时间来决定运行哪个进程，我们甚至可以将其缓存，以确保始终如此。

在内存中，当我们需要添加或移除一个线程时，它将会是`O(log n)`时间复杂度。所以当我们准备进行调度时，我们只需抓取最左边的节点，这就是我们要调度的进程。

![](img/e43763a2764cb9b447c151b8565693fa_5.png)

好的，我们已经向你展示了许多不同的调度算法，最终，当你设计一个系统时，你会根据应用场景来选择一种调度算法。具体选择哪种算法将取决于应用场景和用例。在某些情况下，你可能需要一些适用于通用计算的算法，而在其他情况下……

在某些情况下，你可能需要像机器人操作系统（ROS）或网络文件存储操作系统那样的调度系统，因此你会选择一个符合这些要求的调度器。如果你关心 CPU 吞吐量，那么你可以使用先到先得（FCFS）调度算法，这在高性能计算环境中是可能使用的算法。

如果你关心的是平均响应时间，那么也许你会使用类似最短剩余时间优先（SRTF）这种近似算法。如果你关心的是 IO 吞吐量，类似的 SRTF 算法也适用。如果你关心的是 CPU 时间的公平性，可以使用类似 Linux 的 CFS（完全公平调度器）算法。如果你关心的是 CPU 等待时间的公平性，那可能需要使用……

如果你关心按时完成任务，那么类似轮转调度的算法可以应用于实时系统。你可以使用 EDF（最早截止时间优先）或其他实时调度算法。如果你更关心优先处理最重要的任务，可能会使用严格优先级调度，但你必须意识到，可能会发生饿死现象。

总的来说，在很多情况下，我们处理的系统是多用途的，工作负载各异，因此你需要选择一个能够满足大多数工作负载需求的调度算法，但这意味着它不能满足所有工作负载的需求。

![](img/e43763a2764cb9b447c151b8565693fa_7.png)

关于调度的最后一言。当调度策略、调度的公平性和相关细节真正重要时，何时才是关键呢？

答案是，我们没有足够的资源来满足需求。我们没有足够的资源。另一种思考方式是，比如我有一群工程师，什么时候该为工程师购置一台更快的计算机？或者如果我是一个城市规划师，什么时候需要在高速公路或桥梁上增加一条车道，或为我的公司增加一条更快的网络连接？

所以一种方法是在它能够自我回收成本并提高响应时间时购买。你可以这样想，那个工程师，那个开发人员，你每年支付他们几万美元。如果他们坐在那里等待计算机做某事，那就是浪费生产力，你支付给他们的钱只是让他们坐在那里盯着屏幕或者。

也许在窗口里玩wordle之类的游戏。所以购买更快的电脑将在提高生产力方面迅速收回成本。如果你正在为一群网站用户提供服务，购买更快的电脑意味着他们可以更快地完成订单结算。因为他们不太可能转向某个有更快结账流程或更高便利性的竞争对手。所以有很多原因让你要确保你已经合理配置了资源。

现在你可能会想，好吧，当我达到百分之百的利用率时，那就是我去买下一台电脑的时候了。但是这里有一个响应时间与利用率的图表。你可以看到，随着利用率接近百分之百，响应时间趋向无穷大。你最终会花费所有时间进行上下文切换，或者进出队列。

处理所有的开销。开销开始占主导地位。所以实际上，所有调度算法起作用的时间，尤其是它们有效的时间，就是在这条线性部分的曲线中。而且正是在你接近这个拐点时，才是你购买新电脑的时机，或者更快的链接，那就是你做出增加资源决策的时候。

在此之前，你知道你可以选择算法，算法将帮助你管理可用资源，因为你不会让这些资源过载。只有当你开始接近过载时，才会变得无关紧要。好吧，有关时间表的任何问题吗？是的。在哪两个之间？LLC。

是的，问题是Linux完全公平调度器和轮转调度之间有什么区别。轮转调度只是简单地给每个人一个平等的机会使用CPU，给他们相同大小的时间片。而CFS则根据优先级动态调整这个时间片的大小。是的，问题是，如果我们有相等的优先级，比如说。

在所有线程之间，那么在Linux完全公平调度器和轮转调度之间，它们基本上会是一样的吗？是的，它们基本上都会按轮转调度进行，因为你总是会用CFS挑选在虚拟时间中落后的线程。它们都会以相同的速度推进虚拟时间，因为它们都有。

这就是相同的公平性，因此你将简单地轮流进行。队列的顺序将是一样的，因为它们的优先级相同。是的，所以它们会非常相似。是的，问题是，如果一个线程进入休眠，然后你把它唤醒，是否会补偿它在内容上落后的部分。是的，正是如此。

所以这就是好处，如果你总是关注哪些线程进度最慢，这些线程会被进一步推迟，你会努力让它们赶上来。关键在于细节，如何让它们赶上，而不是简单地把所有的CPU时间分配给它们，这样你仍然需要运行其他任务。

另外，再次提到，你会有新的任务进入系统，你需要弄清楚它们在虚拟时间中的位置。虽然在稳态下思考这些问题更容易，但在实现过程中，你必须担心所有的边界情况。好了，我们有一些行政事务要处理。

我的办公时间从下周开始，周二从一点到两点，周四从十二点到一点。我还在找房间，但应该会在Soda大楼的四楼某个地方。今天你们有一个截止日期，项目一、代码、报告、最终报告和小组评估都要提交。作业二截止日期是周四，而期中考试二，好像我们刚考完期中。

但是期中考试二的冲突请求截止日期是星期五。学期进展得非常快。好了，接下来我们休息四分钟。好了，现在让我们换个话题，讨论一下“饿死”的致命版本。人们在讨论死锁和饥饿时常常感到非常困惑。我将尽力讲解清楚，如果你有任何问题，随时举手提问。

请举手，我们再讲一遍。关于饥饿，饥饿意味着线程会无限期地等待。像我们讨论的低优先级线程可能最终会饿死，因为系统中会不断有高优先级线程进入。死锁则不同。

死锁意味着我们有一些循环等待资源的情况。这里有线程A，它拥有资源一。它在使用资源一的同时，等待资源二。资源二由线程B拥有并使用。线程B在等待资源一，而我们刚才提到，资源一由线程A持有。

所以这是一个循环等待资源的情况。这里的关键区别在于，线程A在无限期等待，线程B也在无限期等待。所以这就是饥饿的现象。因此，死锁意味着你会有饥饿的情况。线程无法前进。死锁和饥饿的区别是，饥饿是可以结束的。

如果我们停止将高优先级的线程引入系统，低优先级的线程就会开始运行。发生死锁时，除非有外部干预，否则它不会结束。在这里没有办法改变这种情况，使得线程A或线程B能够运行。这些线程无法做任何事情来改变这种情况。

这两辆车都被困住了。让我们看一个例子。我们从一个现实世界的例子开始。这是一座横跨峡谷的桥，位于加利福尼亚140号公路上，通往优胜美地国家公园，或者如果你是从优胜美地国家公园回来。为了这个例子，我们假设汽车必须占有公路上的段落。

我们将资源看作是高速公路的段落。每辆车必须占有自己下方的段落，如果它想前进，必须获得前方的段落。它持有下方的段落并试图获得前方的段落。

对于这座桥，我们将桥分为两半。为什么分成两半呢？

因为这样更容易理解。通过这座桥，你必须获得一个段落才能上桥。你还需要获得另一半桥的段落并进入，然后你需要离开桥。你可以认为，一次只能有一个方向的交通流动。

我们有这两段路段，橙色和红色的车占有它们的桥的一半。我们试图获取绿色车所占有的段落，而绿色车则持有该段落并试图向另一个方向行驶。这里我们有死地。橙色和红色的车在等待东半部分，同时占有西半部分，而绿色车占有东半部分。

东半部分的车等着西半部分的车。我们有了死地。我们该如何解决这种情况呢？

好吧，绿色车可以倒车，释放那个段落，让橙色和红色的车占有它。但事情并不简单，因为绿色车后面还有蓝色车。蓝色车必须倒车，但它不能倒车，因为后面还有紫色车。紫色车也必须倒车，然后蓝色车倒车，绿色车也倒车。

现在，橙色和红色的车可以通过了。所以饥饿但不是死锁的情况是这样的：我们有一队从西向东行驶的车队。在这种情况下，每辆车会在前方的段落释放时获取该段落。

由同一方向行驶的汽车组成。这些车正在使想要向西行驶的交通饥饿。这种情况最终会得到解决。一旦向东行驶的车停止，向西行驶的车就可以通过。这与我们现在所处的情况不同，后者没有解决办法。在这里，那些车无法前进。

它们都被困住了，等待着其他人持有的资源。

![](img/e43763a2764cb9b447c151b8565693fa_9.png)

好的，接下来我们来看一下锁的情况。这里有一个例子，使用两个线程，线程A和线程B，其中线程A会尝试获取X锁和Y锁，做一些工作后释放Y锁，再释放X锁。线程B会获取Y锁，然后获取X锁，做一些工作后释放X锁，再释放Y锁。这是最糟糕的死锁情况，因为它是非确定性的。

有时候不会发生这种情况。而其他时候，比如项目截止前的凌晨两点，它就会一直发生。你一看它就不发生了，一提交给自动评分系统它就又发生了。非确定性是一件非常糟糕的事情，因为它让调试变得非常困难。应用程序调试改变了时序并使得bug消失了，但这对于部署来说也是不好的。

如果你为你的公司部署这个程序，而且它会随机死锁，那就是个问题。好的，接下来我们来看一下不幸的情况。在不幸的情况下，线程A获取了锁X。然后由于某些原因，发生了一个上下文切换，线程B被调度，它获取了锁Y。现在我们再切换回A，A尝试获取Y，并被放入等待队列。

所以Y被B占用了。现在我们选择另一个线程来运行，最终B可以运行，并且它去获取X，而X被线程A占用了。所以它被放入等待队列。它也被阻塞了，剩下的代码无法访问。并且这种情况不会自行解决，因为A无法继续执行，B也无法继续执行。所以我们在这里没有其他选择。

所以我们遇到的情况是，线程A持有锁X，同时等待锁Y，而锁Y被线程B持有，而线程B又在等待锁X。所以你可以看到我们又有了一个循环依赖图。好吧。于是没有线程可以运行，这是死锁。现在，在幸运的情况下，有很多幸运的情况，一个幸运的例子是：

A线程获取了X锁，获取了Y锁，开始做一些工作。我们发生了上下文切换。B线程去获取Y锁。它被阻塞了。我们切换回A，完成A线程正在做的工作，释放Y锁，或者说释放X锁，最终我们切换回B线程。B获取了X锁。这是它想要做的。然后释放X锁，释放Y锁。

还有很多其他类似的幸运交错情况。只有几个不幸的交错，但幸运的交错有很多。因此大多数时候这个程序会正常工作。然后偶尔火箭爆炸。好的，接下来是一个来自网络的例子。这里我们有一组火车，所有的火车都有这些交叉点。

这里。火车可以向东向西行驶。它们可以向南向北行驶，或者在这个例子中是南北行驶。然后它们尝试转弯。所以每列火车都在试图向右转。对，结果我们就得到了一个循环依赖，它想向右转，但那条轨道被另一列火车占用了，而那列火车也在试图向右转到已经被占用的轨道上。

由另一列火车和四列火车之间完整的循环，类似的问题也出现在多处理器网络中，我们需要在不同的微处理器之间路由消息包。在我们的多处理器系统中，消息就像一条小虫子。这就是为什么这种路由方法叫做虫洞路由。解决方案是。

即使我们的网格扩展到四个方向，我们也设置了规则。我们规定了频道的顺序。路由的方式是，你总是先朝东西方向走，然后再朝南北方向走。这样就强制要求我们不允许北南方向的火车试图右转，或者南方的火车。

或者北南方向的火车也试图向右转。因为它们必须先走东西方向，而不是第二个方向。这被称为维度排序，我们先处理x维度，再处理y维度和z维度，依此类推。稍后我们会看到为什么这种排序方式也能解决这个问题。

我们刚才看到的线程A和线程B的情况。好吧，我们可以发生许多其他类型的死锁。选一个资源，如果线程必须等待这个资源，那么就可能会发生死锁。资源可以是锁，也可以是终端、打印机、CD驱动器、DVD驱动器、内存，甚至是其他线程，线程会在管道或套接字上阻塞等待。

来自其他线程。任何资源，只要符合某些标准，我们就会阻塞在上面。我们可能会发生死锁。例如，我们可能会在空间上发生死锁。那么，假设有一个程序线程A，它将分配或等待分配1MB内存，接着它会再分配或等待分配另一个1MB内存，然后执行一些操作，再释放。

那么，分配1MB内存后再释放另一个1MB内存。线程B会尝试做同样的事情。假设我们有一台只有2MB内存的机器，这时我们就可能会遇到同样的死锁问题。如果我们先运行线程A，它占用1MB内存，然后运行线程B，它也占用1MB内存，那么现在两个线程都无法再占用更多的内存，只能静静地等待。

这是计算机科学中著名的问题——哲学家就餐问题。我们通常把它叫做律师就餐问题。问题的基本参数如下：这些律师去一家餐馆，这是一家便宜的餐馆，他们坐在一张圆形桌子旁，桌子上有五个律师。由于餐馆非常便宜，所以他们。

他们每人只在桌子上放五根筷子。桌子中间有一大碗米饭。我们都知道，如果我们想吃米饭，不止一根，而是需要两根筷子。那么我们说，好，吃饭时间到了，律师们会怎么做呢？每个律师都会去拿一根筷子。如果每个律师同时都拿了一根筷子，会发生什么呢？

死锁。对吧？每个人都拿着一根筷子，大家互相对视着，中间有一碗米饭，结果大家都饿死。真的饿死。那么，如何解决这种死锁呢？我们可以对一个律师说，做个好人，把你的筷子让给别人。祝好运。我觉得这不太可能发生，对吧？

但是，如果他们这么做，如果有一个无私的律师，如果我们找到了独角兽，他们会放弃筷子，然后另一个律师就能得到两根筷子。然后他们可以吃饭，吃完后把筷子放回池子，其他律师就可以吃饭，依此类推，直到所有律师都吃上饭。明白吗？

这可能给我们一些启示，了解如何解决这些死锁情况。但这里的警告是，这将需要说服其中一个人放弃他们持有的资源。好吧，我们如何预防死锁呢？我们可以制定桌面规则，规定如果拿最后一根筷子会导致桌上的某人没有两根筷子，那就不能拿。明白吗？

因为只要剩下一个筷子，而且至少有一个律师手里有一个筷子，他们可以拿到这个筷子，然后就有两根筷子可以吃饭，吃完后再把筷子放回池子里，其他律师就可以吃了。明白吗？

所以这就是我们可以通过类似规则来避免死锁的方式。你可以考虑如何将其正式化，对吧？我们该如何正式化这一点？

假如你知道，桌子上坐着一群章鱼，会发生什么呢？

那我们如何将这种情况转化为一个规则，确保所有的章鱼——它们非常聪明——能够使用筷子吃饭，做所有那些事情呢？好吧，让我们先从正式化死锁的定义开始。死锁发生需要四个条件。第一个是必须有互斥。

所以，每次只有一个线程可以使用特定的资源或资源的某个实例。第二个是必须有占用等待。所以，持有至少一个资源的线程正在等待获取其他线程持有的资源。接下来是不可抢占。所以，如果一个线程持有资源，我们不能在它还没有用完资源之前从它手中抢走资源。

就像在律师用餐的案例中，意味着如果一个律师拿着筷子，我们不能直接过去抢走筷子，直到他们吃完。我们不能插手。最后，我们必须有循环等待。即存在一组线程，其中T1正在等待某些资源。

被T2持有。T2正在等待T3持有的资源。T3在等待T4持有的资源，依此类推，一直到Tn在等待由bread one持有的资源。现在，关于死锁有一点需要注意。为了使系统发生死锁，必须满足四个条件。

移除这些需求中的任何一个。我们就不会有死锁。我们可能会有饥饿现象，但我们不会有死锁。如果系统处于死锁状态，且我们可以移除其中任何一个要求，那么我们就能将其从死锁状态中解救出来。好了，有什么问题吗？好的。那么，首先我们需要做的是，弄清楚如何判断我们的系统是否处于死锁状态。

死锁。我们将使用我们所谓的资源分配图。所以这是模型。我们有线程。在这里我们有线程T1和T2。我们有一个小框，这里是这些线程的结束点，然后我们有资源。有不同类型的资源。比如CPU，或者是内存。

CPU实际上不是一个非常好的例子，因为我们可以抢占CPU。我们可以从某个线程那里拿走CPU并将其分配给另一个线程，但它仍然是一个资源。我们可以有磁盘驱动器、打印机、锁等，任何东西都可以是资源，然后我们还有一些资源有多个实例，我们将通过标记有多个实例来表示。

通过这些额外的点。额外的点意味着像在这种情况下，资源二有三个实例。这意味着有三个线程持有资源二的一个实例，或者一个线程可以持有所有三个实例，或者任何其他组合。好，现在，线程通过请求资源来使用资源。比如获取该资源并在使用完毕后将资源释放回池中。

我们生成资源分配图的方式如下。我们的图V被分为两种类型。我们有一组，包含线程和资源，然后我们有指向这些资源的有向边。指向这两组之间的资源，线程和资源之间的边。现在，请求边是指从线程指向资源的边，就像这样，从T1指向R1。

这个R1的实例。分配，所以持有资源的对象是指向相反方向的有向边。也就是说，从资源实例指向特定的线程。所以说，从这个第一个点到线程二，这就意味着该资源的一个实例由线程二持有。

![](img/e43763a2764cb9b447c151b8565693fa_11.png)

好的。那么这是一个资源分配图的例子。这里有资源一，它的一个实例被线程二持有。资源二，一个实例被线程三持有。资源四，一个实例被线程三持有，然后资源三这里有两个实例，一个由线程一持有，另一个由线程二持有。那么，第一个问题是。

这个系统有死锁吗？没有。它没有死锁。因为例如，线程二在等待资源二，而资源二被线程三持有。线程三不在等待任何东西。它持有资源二的一个实例，它持有资源四的一个实例。所以它可以完成任务并退出系统。

这样就会释放资源二。那么线程二可以运行，对吧？

因为它将拥有资源一的一个实例、资源二的一个实例以及资源三的一个实例。它将释放资源一，然后线程一可以获得该实例并执行直到完成。所以这不是一个死锁系统。这里是死锁的一个例子。我们这里有一个循环图，对吧？线程一持有资源三的一个实例，并在等待资源一的实例。

资源一由线程二持有，线程二正在等待资源二的实例，而资源二由线程三持有，线程三正在等待资源三的实例，资源三由线程二和线程一持有。我们有一个循环等待。没有任何一个线程能够继续执行。没有任何东西会改变这一点。

没有线程能够释放资源并让其他线程继续运行。仅仅因为你有一个循环，并不意味着你有死锁。再次强调，必须满足所有这些条件才算死锁。因为在这里，线程三正在等待资源二，同时持有资源一的一个实例。

线程一正在等待资源一，同时持有资源二的一个实例。所以你可能会想，哦，我们这里有一个循环，可能是死锁。但我们还有两个其他线程，对吧？

这里有线程二，它持有资源一的一个实例。不需要任何资源，所以它可以运行并退出系统，对吧？

这将释放一个 R1 实例。那么 T1 就可以获取它。然后 T1 将拥有运行所需的所有资源，或者线程 T4 拥有所有它需要的资源。它拥有 R2 的一个实例，可以运行直到完成，释放该实例。然后线程 T3 可以获取它，拥有所有它需要的资源并完成任务。

只要有线程可以运行并产生解决方案计划，那么我们就知道我们的系统没有死锁。但在这个中间情况中，我们无法取得任何前进进展。

![](img/e43763a2764cb9b447c151b8565693fa_13.png)

好的。如果你仔细想想，这为我们提供了一个死锁检测算法。我们可以说我们的向量 X 代表一个非负整数的 M 元向量，这些整数是给定资源的数量。所以我们为每种资源都定义了空闲资源，对吧？

所以我们向量的每个元素将代表一个给定的资源，资源一、二、三，依此类推。每个资源有多少实例是可用的？我们有一个请求向量，它表示每个线程对于这些资源的当前请求。然后我们有一个分配向量，它是每个线程的资源分配情况。

这些资源已经分配给该线程。所以现在我们可以查看任务是否最终能自行完成。那么这是我们将要使用的算法。我们将初始化可用资源向量，使其为我们拥有的空闲资源。我们将把所有节点加入未完成的集合中。接着，我们将执行一个 while 循环，并遍历所有节点。

在未完成集合中的节点。对于每个节点，我们将进行检查，查看该节点的请求向量是否小于或等于可用资源。这意味着什么？

这意味着没有进程能够获取它所需要的所有资源并运行到完成。所以我们将假设它做了。它将运行到完成，然后它会怎么做？

它将释放所有已分配的资源。所以我们将把它分配的资源返回到可用资源池中。现在我们将查看下一个节点。也许那个节点没有它所需要的资源。也许它的请求大于可用资源。所以它会保持在未完成状态。

我们将查看下一个节点。我们会继续遍历，反复检查所有未完成的节点，只要情况在变化，直到我们达到一个点，要么什么都不变，我们的完成变量保持为真，要么未完成集合中没有节点。

那么如果我们退出这个过程，而未完成集合中还有节点，那意味着什么？或者说，如果我们完成了这个过程并退出，而未完成集合中什么都没有，那意味着什么？没有任何节点？

是的。是的。所以如果未完成集合中没有任何内容，那么就没有死锁。如果未完成集合中还有节点，而我们发生了死锁，那么说明即使所有其他节点退出系统后，仍然有节点无法获得所需的资源。没有找到可以让节点完成的路径。

让所有的进程完成吧。所以这就是我们的死锁检测方法。这将是我们判断系统是否当前处于死锁状态的方式。好的。现在问题变成了，如果我们发生了死锁，我们该怎么办？有几种选择或四种不同的选择。

其中一种方法是我们可以简单地避免死锁。我们编写代码时确保不会发生死锁。想一下频道的逻辑顺序。你先在X维度上路由，再在Y维度上路由，然后是Z维度，依此类推。你对资源获取顺序进行强制排序，字典顺序。你必须总是在获取Y之前先获取X。

你在接下来的过程中不能获得Y。这些类型的方法从一开始就避免了死锁的发生。第二种你可以用来处理死锁的方法是恢复。系统，你知道，死锁检测会说，“哦，系统发生了死锁。你该怎么办？”

你得找出如何从中恢复。也许你终止一些进程或者回滚操作。”另一种方法是使用像死锁检测算法这样的东西来预测，如果我允许某个系统请求，是否会导致死锁，从而避免批准该请求，防止系统发生死锁。

另一种方法就是直接忽略死锁。死锁根本不存在。继续前进。有时会使用所有这些不同的方法。最后这种方法是最简单的，因为你只是——死锁不存在。所以，如果它偶尔发生，我就不打算去检查它了。好吧。现代操作系统会尽量确保操作系统不会。

遇到死锁。这通常是对的。确实有一些bug偶尔会导致系统死锁，但基本上，你知道，设计良好的代码是不会死锁的。应用程序可以随便死锁。操作系统只是会忽略它。所以我们称这为鸵鸟方法。对应用程序来说，死锁根本不存在。好吧。

那么我们可以使用哪些技术来尝试避免进入死锁情况呢？

所以一种方法是，如果我们有无限的资源，对吧？记得那些资源的实例吗？好吧。如果我们有无限数量的实例，那么线程永远不会进入那种必须等待特定资源的情况。现在，它不一定要是无限的，只要足够大，我们就不会用完它。

对吧？我们可以通过使用虚拟内存，制造我们有无限内存的幻觉。这样我们就不会遇到两个线程请求两兆内存，而我们没有足够的内存的问题。我们可以把两兆内存扩展为两千兆内存。对吧？如果你把它扩展到两万兆，那可能就有问题了，对吧？

所以我说幻觉并不完美，但我们可以让这个幻觉足够大，足以让人觉得我们有无限的资源，对吧？比如一座有12,000条车道的大桥，你永远不需要等待。实现起来当然并不实际。就像无限磁盘空间一样。如果我们没有任何共享的话。

但是，如果我们有完全独立的线程，没有共享资源。那么我们就不会有死锁。我们也不会有任何非常有用的东西。你知道的。如果你从不与真实世界互动，那么做任何事都会非常困难，你永远不会使用终端，永远不会使用打印机，永远不会进行任何IO操作。是的。

这实际上不可行。我们禁止等待。这其实是电话网络的工作方式。如果你说，“哦，打电话给妈妈和托莱多”，对吧？你的电话会通过电话公司网络进行路由。如果它遇到了一条满的干线或者网络交换机已经满了，你就。

变得快速繁忙。稍后再试。这有点像，你知道的。想象一下，你想去旧金山，你开车。如果你遇到红灯或交通堵塞，你就会被瞬间传送回伯克利。进入旧金山可能需要一段时间。这非常低效，对吧？

因为你每次都必须继续重试，直到你听到忙音才能通过。好了，回到虚拟资源的概念，如果我们有类似虚拟内存的东西，就能避免这个问题，假设系统只有两兆内存，而两个线程都请求两兆物理内存的话。

如果我们将虚拟地址空间设置为四个吉比字节，我们就不会遇到问题。即使有数百个线程，它们都可以请求它们的两兆内存，我们也不会遇到占用等待的情况。好了，最后一张幻灯片，我想讨论一些防止死锁的技术。你可以让线程在一开始就请求所有它们需要的资源。

问题是，如何预测在一开始时我所有需要的东西呢？

这真的很难。那么，作为开发者你该怎么办？如果你被告知程序错了就会被终止，而且你必须从头开始，那你只会高估自己需要的资源。所以，这会非常低效。好了，但如果你能够算出只需要两根筷子，你就可以请求这两根。

同时使用两根筷子。如果你不知道自己是需要两根还是五根，而它又有点像是死刑，如果你弄错了，那你就会请求五根筷子，即使你只需要两根。你可以强制所有线程以特定的顺序请求资源。因此，这又涉及到像是x，y，z的路由顺序，或者字典顺序排列。

这时候就会起作用。所以，我们说每一个锁你要获取时，必须按照字典顺序获取，像是x，y，z，或者先请求磁盘，再请求内存等等，你就能避免那种循环等待的链条。因为每个人都会按同样的顺序请求。因此。

这是我们可以采用的另一种方法，但你必须通过编程或者其他实践和工具来强制执行，确保这一点能发生。好的，有问题吗？

好的，我周四见。好的。

![](img/e43763a2764cb9b447c151b8565693fa_15.png)

（深呼吸）。
