- en: P15：Lecture 15： Memory 3 Caching, and TLBs (con't), Paging - RubatoTheEmber
    - BV1L541117gr
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: P15：讲座 15：内存 3 缓存和TLBs（续），分页 - RubatoTheEmber - BV1L541117gr
- en: Okay， let's get started。
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，开始吧。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_1.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_1.png)'
- en: So today we're going to look at our third lecture on memory and we're going
    to look， at caching。 translation， look aside， buffered and then we'll get into
    demand behavior。 Okay。 so remember we have the two level page table， right？ So
    here we have this tree of page tables。 We use the magic 10， 10， 12， orderization
    for the pattern and that gives us this nice。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所以今天我们将看到第三讲关于内存的内容，我们将探讨缓存，转换、旁路缓存（look aside）以及缓冲区，然后我们将进入需求行为部分。好的，记住我们有双级页表，对吧？所以这里我们有这棵页表树。我们使用神奇的10，10，12排序模式，这为我们提供了一个很好的结构。
- en: breakdown where each of our tables， our page tables is 1，024 entries to the
    10。 The entry is 4 bytes so that fits on a 4k page which represents our offset
    of 2 to the， 12。 By doing this， your tables are a fixed size， we have the root
    page table pointer for the。 page table pointer here which is a register， the CRP
    register on x86， points to our top。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 分析每个表格时，我们的页表每个包含1,024个条目，每个条目是4字节，这样就适合一个4k的页面，代表我们的偏移量为2的12次方。通过这样做，我们的表格大小固定，我们有页表指针的根指针，这个指针是一个寄存器，x86上的CRP寄存器指向我们的顶部。
- en: level table， the index of the top 10 bits into that table。 That gives us a pointer
    to the page table in physical memory。 At the second level。 the index into that
    with our P2 index with the next 10 bits， that。 gives us the page table entry for
    the actual physical page that we're looking for。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在级别表中，前10位的索引指向该表。这为我们提供了指向物理内存中页表的指针。在第二级中，使用P2索引和接下来的10位进行索引，这会给我们提供实际物理页的页表项。
- en: Combining that physical frame number with our offset and we get the page and
    we get the。 byte on the page。 Lots of bookkeeping information that we'll be going
    through later on today in the page。 table entry and things like valid bits， 30
    bits， modified bits and so on。 Now one of the nice things about the two level
    scheme is the amount of data structures that。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 将物理帧号与我们的偏移量结合，我们得到页面，并得到页面上的字节。有很多后续信息，我们稍后会在页表项中逐步讲解，比如有效位、30位、修改位等等。现在，双级方案的一个好处是数据结构的数量。
- en: we're going to have is going to be proportional to the fraction of the virtual
    address space。 that's actually in use。 It's going to be much much smaller than
    the actual virtual address space。 Okay， now how do we do translation？ Again， remember。
    translation is done in the memory management unit。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将拥有的内容将与实际使用的虚拟地址空间的比例成正比。它将比实际虚拟地址空间要小得多。好了，那么我们如何进行转换呢？再次提醒，转换是在内存管理单元中完成的。
- en: The memory management unit has to translate every instruction fetch， every load
    and every。 store from the virtual address space used by the program， the instruction
    of the addresses。 emitted by the CPU to the actual physical addresses that are
    used by memory。 Now。 how do we do this translation？ Well， for a single level page
    table。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '内存管理单元必须将每条指令的获取、每个加载和每个存储操作从程序使用的虚拟地址空间、CPU发出的地址指令转换为内存使用的实际物理地址。现在，我们如何进行这种转换呢？好吧，对于单级页表， '
- en: we're just going to index into that table and read， the page table entry。 check
    that it's valid and that will give us the physical page frame。 For two level tables。
    it can be exactly what I showed you on the last slide where we're。 going to walk
    through two sets of those page tables。 For n levels。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要索引到该表并读取，检查页表项是否有效，然后它将为我们提供物理页帧。对于双级页表，它可能正是我在上一张幻灯片上展示的那样，我们将遍历两组页表。对于n级页表，
- en: the page tables will walk through n sets of page shavings。 So what we're watching
    the memory management unit do is just a form of pre traversing。 It's traversing
    through that tree of page table entries to find the page table entry for。 the
    actual physical page that we want。 All right， now where do we put the memory management
    unit？
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 页表将遍历n组页表项。因此，我们观察到内存管理单元所做的事情只是一种预遍历的形式。它正在遍历那棵页表项的树，以找到我们想要的实际物理页的页表项。好的，那么我们将内存管理单元放在哪里呢？
- en: Well， those on the processor die right after the processor。 So the processor
    is generating virtual addresses。 The memory management unit uses the page table
    base register to traverse through the page。 tables that are stored in memory。
    And notice here， our cache in this case is physically addressed。 So the addresses
    that were passing through the cache are addresses that have been translated。 Okay。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这些操作发生在处理器芯片上，就在处理器旁边。所以处理器生成虚拟地址。内存管理单元利用页表基址寄存器来遍历存储在内存中的页表。请注意，这里的缓存是物理寻址的。所以我们传递给缓存的地址是已经被转换过的地址。好的。
- en: So when we give the MMU a virtual address， it's going to do this traversing。
    Now since we have a cache here， it might be the case that portions of those page
    tables。 are in the cache。 If that's true， then the memory management unit will
    get back those page table entries。 right away。 And it'll be able to return answer
    to the processor or provide the physical address rather。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们给MMU一个虚拟地址时，它将进行遍历。现在，由于我们这里有缓存，可能有一些页表项已经在缓存中了。如果是这样的话，内存管理单元将立即返回这些页表项，并且它能够立刻返回处理器一个物理地址。
- en: for the processor right away。 If not， then we might have to go all the way out
    to physical memory in order to do that。 proof of our error。 And if those page
    tables are actually out on this。 we might actually have to do IO in， order to
    actually do that conversion from a virtual address to physical address。 So if
    we hit in the cache， it's going to be super fast。 If you're missing the cache。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理器来说。如果没有找到，那么我们可能需要一直访问物理内存才能进行验证。而且，如果那些页表实际上在外面存储，我们可能还需要进行IO操作才能把虚拟地址转换为物理地址。所以如果我们命中缓存，速度将会非常快。如果缓存缺失。
- en: it could be really， really slow。 Okay。 So what's the memory management unit
    doing？ Well。 on every instruction fact， load and store is doing this tree traversal
    to do this conversion。 from a virtual address to a physical address。 And it finds
    an invalid page table entry for whatever reason。 the decommission， the access，
    the type of operation， and whatever。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会非常非常慢。好的。那么内存管理单元在做什么呢？实际上，在每条指令执行时，加载和存储操作都在做这棵树的遍历，用来将虚拟地址转换为物理地址。如果它发现一个无效的页表项，不管是什么原因，比如去除的操作，访问类型等等。
- en: it's going to return a fall and will drop into the， operating system。 Okay。
    So one thing to consider here is the memory management unit is before the cache。
    The cache is how we make things fast。 Right？ This cache is inside the processor。
    So it's going to operate on the order of nanoseconds。 But going out to memory。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 它会返回一个失败状态，并跳转到操作系统。好的。那么这里需要考虑的一点是，内存管理单元在缓存之前。缓存是让一切变得快速的关键。对吧？这个缓存就在处理器内部。所以它的运作速度是纳秒级的。但是访问内存。
- en: that's like 100 nanoseconds going out to disk。 That's like millions of nanoseconds。
    So in order to actually access something in the cache， we have to go through this
    process。 which could potentially take millions of nanoseconds。 Seems like that
    really defeats the whole purpose here。 Right？
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 就像是100纳秒去访问磁盘。那大约是百万纳秒。所以，为了能够在缓存中访问某些内容，我们必须经过这个过程，这个过程可能会消耗数百万纳秒。看起来这真的违背了我们设定的目标，对吧？
- en: So let's look at what caching offers and how we might apply caching to the cancellation，
    process。 So we're going to do a quick primer， which you forgot on 61C on what
    cache。 So a cache is just a repository where we keep copies that we can access
    much more quickly。 or faster than the original copy。 Right？ So rather than having
    to go out to memory。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们看看缓存提供了什么，以及我们如何将缓存应用到取消过程中。我们将快速介绍一下缓存的基础知识，这些你在61C课上忘了的东西。缓存只是一个存储库，用来存放可以更快速访问的副本，或者说比原始副本更快。对吧？所以我们不需要每次都去访问内存。
- en: we have a cache here。 In this case， it's a data cache that lets us access copies
    of what's in our physical memory。 much faster。 So like a millisecond instead of
    a nanosecond rather than hundreds of nanoseconds。 Okay。 What makes caches work
    is that they make the frequent case fast and they make infrequent。 cases less
    dominant。 So if you look at it moderate computer。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里有一个缓存。在这种情况下，它是一个数据缓存，允许我们更快速地访问物理内存中的副本。这样我们可以比纳秒级访问快得多，差不多是毫秒级，而不是数百纳秒。好的。缓存之所以有效，是因为它让常见的情况变得更快，而让不常见的情况变得不那么显著。所以如果你看看一个中等规模的计算机。
- en: you're going to find caching everywhere。 Right？ So we're going to look at how
    we can use it to cache memory locations。 I would be to address translations。 I
    would be to cache domain name resolutions。 I would be to cache network locations，
    pages， file blocks。 Everything in computers really is accelerated by using caches
    or almost not always be。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现缓存无处不在，对吧？所以我们要看看如何利用它来缓存内存位置。我会用来解决地址转换。我会用来缓存域名解析。我会用来缓存网络位置、页面、文件块。在计算机中，一切都可以通过使用缓存来加速，或者几乎总是如此。
- en: the case is not too expensive。 We're going to walk a very high hit rate and
    we're going to want to kind of minimize。 the miss cost as much as possible。 And
    so that kind of gets us to how do we evaluate caches。 We evaluate it with this
    measure， the average access time。 The average access time is just a hit rate times
    the hit time。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况并不算太昂贵。我们会有一个非常高的命中率，并且我们希望尽量减少未命中的成本。所以，这就引出了我们如何评估缓存的问题。我们用这个指标来评估它：平均访问时间。平均访问时间就是命中率乘以命中时间。
- en: So when we find it in the cache plus the miss rate times the miss time。 So when
    we don't find it in the cache and have to go out to a lower level of our memory，
    error。 So caching is how we get system performance。 So here's an example。 Right？
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，当我们在缓存中找到数据时，加上未命中率乘以未命中时间。也就是说，当我们在缓存中找不到数据时，必须去更低级别的内存查找，这就出现了错误。所以缓存是提高系统性能的关键。这里有一个例子，对吧？
- en: If the processor directly gives the memory， it takes us 100 nanoseconds。 If
    a processor is operating in a nanosecond， it's some nanoseconds。 So accessing
    something on the processor like an S-grant cache is a nanosecond。 Going all the
    way out in a memory， 100 nanoseconds。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理器直接访问内存，则需要100纳秒。如果处理器在1纳秒内操作，那是某个纳秒级别。所以，像S-grant缓存这样的处理器访问是1纳秒。而从内存中获取数据需要100纳秒。
- en: It's 100 times slower if we're operating out of main memory than if we're able
    to stay。 on the processor and operate a processor speeds。 Just went out and spent
    thousands of dollars on that crazy fast Intel。 you know， i9， 12，000， plus KF processor。
    And now you're going to run it at the speed of the memory。 So this is where cache
    and the thing can help us have speeds that look closer to what。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从主内存中操作，它的速度是100倍慢于直接从处理器上操作的速度。如果我们能够保持在处理器上操作，就能以处理器的速度运行。你刚刚花了几千美元买了那款疯狂快速的Intel
    i9 12,000 Plus KF处理器。现在，你却要让它运行在内存的速度下。所以这就是缓存和这个技术可以帮助我们在速度上接近处理器实际速度的原因。
- en: that processor can actually do。 Okay， so how do we apply the average memory
    access time here？ Again。 it's the hit rate times the hit time plus the miss rate
    times the miss time where。 the hit rate plus the miss time is one。 Okay， so what
    if we have a 90% hit rate？
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，处理器实际上能做什么呢？好吧，如何在这里应用平均内存访问时间呢？再次提醒一下，计算公式是：命中率乘以命中时间加上未命中率乘以未命中时间，其中，命中率加未命中率等于1。好吧，如果我们有一个90%的命中率呢？
- en: So 90% of the time the processor is going to find the data in the cache。 That's
    really good。 Like 90% of the time， 9 out of 10， we're finding it in the cache。
    But what is that really translated？ Well， that's going to be 0。9 times one nanosecond。
    90% of the time。 And then the other 10% of the time of 0。1， it's going to be 101。
    Now。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以90%的时间，处理器会在缓存中找到数据。这真的很好。比如90%的时间，10次中有9次我们能在缓存中找到它。但这到底意味着什么呢？嗯，那将是0.9乘以1纳秒，90%的时间。然后，另外10%的时间，0.1，就是101纳秒。现在。
- en: why is it 101 and not 100？ Because I have to look into cache first before I
    don't find it。 And so there's one nanosecond to look in the cache and then 100
    nanoseconds to go out and。 get it from the next level， which is memory。 That's
    11。1 nanoseconds。 Is that good？ Is that bad？
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么是101而不是100呢？因为我必须先在缓存中查找，才知道它不存在。所以在缓存中查找需要1纳秒，然后需要100纳秒去下一层内存中获取。这就是11.1纳秒。这样好不好？这样算不算差呢？
- en: Well， I mean， it certainly seems better than 100 nanoseconds。 It's 10 times
    faster。 But it still is 10 times slower than this processor that I spend all this
    money to buy。 So it actually is pretty bad。 A 10x slowdown really isn't for acceptable。
    So what if I increase the hit rate？ What if I hit the hit rate the 99%？ Well。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我的意思是，它显然比100纳秒要好。它快了10倍。但它仍然比我花了大价钱买的这个处理器慢10倍。所以它其实是相当糟糕的。10倍的减速是完全不能接受的。那么如果我提高命中率呢？如果我将命中率提高到99%呢？嗯。
- en: if I hit the hit rate the 99%， now it's 0。99 times one plus 0。01 times 101。
    So it's 2。01 nanoseconds。 So that's much better， not perfect。 But now you've only
    got a factor of two slowdown instead of a factor of 100。 So that's where the power
    caution ends into the fall。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我将命中率设为99%，现在是 0.99 乘以 1 加 0.01 乘以 101。所以是 2.01 纳秒。这要好得多，虽然不是完美。但现在你只有二倍的减慢，而不是一百倍。所以这就是能量警告结束时的情况。
- en: But it also says that we have to make sure we can deliver very high hit rates
    in order。 to achieve good performance。 Now， when you really think about it。 what
    we're going to see later on in the class is， that memory-- so here we're using
    the cache to cache contents of memory。 But we use memory to cache the contents
    of the hardware。 So really。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但它也意味着我们必须确保我们能够提供非常高的命中率，以便实现良好的性能。现在，当你真正思考时，我们稍后在课程中会看到，内存——在这里我们使用缓存来缓存内存的内容。但我们也使用内存来缓存硬件的内容。所以实际上。
- en: when we think about the average memory access time， it really is the hit time。
    because we find it in this level one in cache。 Plus。 the miss penalty if we don't
    find it in a level one， which is basically equivalent。 to the average memory access
    time for level two。 Because you might actually go to get it out of memory and
    find it。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑平均内存访问时间时，它实际上是命中时间。因为我们在一级缓存中找到了它。加上如果我们在一级缓存中没有找到它时的缺失惩罚，这基本上等于二级缓存的平均内存访问时间。因为你可能实际上需要从内存中取出它并找到它。
- en: It's not a memory that's actually out of disk and so we have to then go out
    to disk again。 Yeah。 [INAUDIBLE]， Oh， that's a good tool。 [INAUDIBLE]， Let's see
    if you can lower that wall。 [INAUDIBLE]。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是实际上存储在磁盘上的内存，所以我们必须再次从磁盘读取。是的。[听不清]，哦，这是个好工具。[听不清]，让我们看看你能不能降低那个墙。[听不清]。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_3.png)'
- en: OK。 All right。 So another reason why we want cache-- oh， yeah。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。好的。那么我们希望使用缓存的另一个原因是——哦，是的。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_5.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_5.png)'
- en: '[INAUDIBLE]， So it should be 10。1 plus 0。1。 Oh， here， it should be a letter。
    Yeah。 I''ll fix that on the side。'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[听不清]，所以应该是 10.1 加 0.1。哦，这里应该是一个字母。是的，我会在旁边修正这个。'
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_7.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_7.png)'
- en: Thank you。 OK。 OK。 So another major reason why we want to deal with caching
    is that remember。 we're having， to walk through these tables。 So here's an example
    of a segment-based system and a single and one level of paging at the。 lowest
    level。 So for every memory reference that we do。 we're going to first look in
    the segment map。 That's in the process。 So that's going to be fast。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 谢谢。好的。好的。那么我们想要处理缓存的另一个主要原因是，记住，我们需要遍历这些表格。这里有一个基于段的系统示例，以及最低级别的单一分页。对于我们每次的内存访问，我们将首先查看段映射。那是在进程中的。所以这将是非常快速的。
- en: but still is going to cross the sample。 And then we're going to have to actually
    go out and work the memory to walk through the。 page table。 In the example I showed
    on the first slide， we had to walk through two levels of memory。 page tables out
    of memory。 So every reference that we're doing is going to be somewhere between
    two to three memory。 references。 So every instruction that we load and we store。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但它仍然会穿越样本。然后我们将不得不实际去外部工作内存，遍历页面表。在我在第一张幻灯片中展示的示例中，我们必须遍历两个级别的内存页面表。所以我们每次的访问都将是介于两到三次内存访问之间。所以每个我们加载和存储的指令。
- en: we can multiply the cost by a factor of two， or a factor of two。 Or if we have
    additional levels or five and so on。 OK。 Now， if you think about it， right， again。
    what I said in the MX slide before， where's the， TOB？
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将成本乘以二倍，或者二倍，或者如果我们有额外的级别，五倍，等等。好的。现在，如果你仔细想想，再次，我之前在MX幻灯片中说过，TOB在哪里？
- en: The TOB is before the cache that we're using to make memory faster。 But before
    we can look up anything in the cache， we first need to get the physical address。
    And so if it takes us multiple memory references just to be able to check in the
    cache， what's。 the point of having a memory cache anyway？ Because the time to
    access that memory cache is going to be dominated by those three memory。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: TOB 是我们用来加速内存的缓存之前的部分。但在我们可以在缓存中查找任何内容之前，我们首先需要获取物理地址。所以如果我们需要多次内存访问才能检查缓存，那缓存有什么意义呢？因为访问内存缓存的时间将会被那三次内存访问所主导。
- en: accesses that we have to give。 OK。 So solution is we're doing all this work
    to do the translation。 We might as well save that result or pass it。 OK。 So this
    cache。 it's called a translation look aside buffer。 It gets a why it has that
    we have named in just a moment。 But first the question is， will this work？ And
    can we get a decent hit rate out of kind of cache translations？
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须进行的访问。好的。所以解决方案是，我们做了所有的工作来进行翻译。我们不如把那个结果保存下来或者传递出去。好的。所以这个缓存被称为翻译旁路缓存。它得名的原因，稍后会解释。但首先，问题是，这种方法行得通吗？我们能从缓存翻译中获得合理的命中率吗？
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_9.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_9.png)'
- en: So why did， when does caching help？ Caching will help us when we have locality。
    No locality。 There is no benefit to caching。 Every access is completely random。
    You won't see any benefit from caching。 But that's not how computer programs typically
    operate and not how computers operate in general。 Right。 So if we look at the
    behavior， we typically see temporal locality。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么缓存会有效？缓存只有在我们有局部性时才有用。如果没有局部性，缓存就没有任何好处。每次访问都是完全随机的，你不会看到缓存带来任何好处。但这不是计算机程序的典型操作方式，也不是计算机的典型操作方式。对。所以如果我们看一下行为，我们通常会看到时间局部性。
- en: That's what polity is called。 So here on the x axis， I have our address space
    and on the y axis。 I have the probability that， we reference a given memory location。
    And you can see that there are peaks。 So if I have access something。 I'm likely
    to access that thing again。 Right。 If I have some global variable and I access
    it。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是所谓的局部性。所以在这里，x 轴是我们的地址空间，y 轴是我们访问给定内存位置的概率。你可以看到有一些峰值。所以如果我访问了某个东西，我可能会再次访问那个东西。对。如果我有一个全局变量，我访问了它。
- en: I'm likely to come back and access that global， variable again。 Where I have
    some variables within a subroutine。 I'm likely to access those variables multiple
    times。 So keeping recently access data closer to the processor， it's going to
    give us better performance。 And now if I access something， it turns out unlikely
    to also， and if you look at this。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我很可能会再次访问那个全局变量。或者我有一些变量在一个子程序内，我很可能会多次访问这些变量。所以将最近访问的数据保留在离处理器更近的位置，将为我们提供更好的性能。现在，如果我访问某个东西，结果证明它不太可能再次被访问，如果你看这个情况。
- en: it's sort of rough here， I'm likely to access things around it too。 Right。 So
    like think about like if I'm reading strength， I'm doing a string length or string
    copy operation。 Well， access one character， I'm likely to access the other characters
    nearby。 So when you think about moving things around， the spatial locality means
    I want to move a block from a lower level of the memory hierarchy。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有点粗糙，我也可能会访问周围的东西。对。所以像是，如果我正在读取一个强度，我做的是一个字符串长度或字符串复制操作。好，访问一个字符，我可能会访问附近的其他字符。所以当你考虑移动东西时，空间局部性意味着我想从内存层次结构的较低级别移动一个块。
- en: one upper level。 Because access one thing that block。 I'm likely to access other
    things in that block。 Okay。 But that's what this picture is doing。 If I access
    something down here like law， why I should move it all。 not just the individual
    item that I access。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个上层。因为访问了一个东西，那一块我可能会访问到其它东西。好的。但这就是这张图所展示的。如果我访问像下面的某些东西，为什么我应该移动它整个块，而不仅仅是我访问的那个单独项目。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_11.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_11.png)'
- en: All right。 So our goal here with caching is all about illusions。 So we want
    to present the illusion that I have memory of scale terabytes that operates at
    speeds of registers。 And has cost at the order of my slowest storage， rather than
    my most expensive story。 The capacities of my largest storage and not my fastest
    story。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。所以我们在这里使用缓存的目标完全是关于制造假象的。所以我们希望展示这样一种假象：我有一个以寄存器速度操作的规模为 TB 的内存，并且成本接近最慢存储设备的成本，而不是最昂贵的存储设备。我的最大存储容量，而不是我最快的存储。
- en: Like it's here registers were talking about hundreds of bytes， which is terrible。
    but I can access these registers in a fraction of a nanosecond。 Right。 whereas
    I have to go out the disk。 It's 10 million nanoseconds。 But at a terabyte。 it
    looks like it's infinite for a program。 So I want that illusion that I have infinite
    fast storage。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 比如这里我们讲的寄存器，只有几百个字节，效率差，但我可以在纳秒的微秒内访问这些寄存器。对。而如果我必须访问磁盘，它需要 1000 万纳秒。但在 TB 级别看起来对程序来说几乎是无限的。所以我想要那种假象——我拥有无限快速的存储。
- en: So we'll do caching at every level of this higher。 So we'll treat， you know。
    so here we have an L one， for the， for the core， the LT cash for the core。 And
    then we have memory as a cash for our SST and our SST is a cash for our hard drive。
    It could be a cash for going to the cloud or cash for cake and so forth。 Okay。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们会在这个更高层级的每个层次进行缓存。我们会处理，比如这里我们有一个L1缓存，核心的L1缓存。然后我们有内存作为缓存用于我们的SST，SST又作为硬盘的缓存。它可能是访问云的缓存，或者其他缓存等。好的。
- en: Now our challenge is that address translation first needs to occur here。 It's
    during my instruction fetch during loads and stores into registers， but the page
    tables。 I need to do that address translation or living out in a memory。 Which
    is operating again at 100 nanosecond versus the fractions in nanosecond for my
    registers。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的挑战是，地址转换首先需要在这里发生。它发生在我的指令获取阶段，加载和存储到寄存器的过程中，但页表，我需要在内存中完成这个地址转换。而内存的运行速度是100纳秒，而我的寄存器的速度是纳秒级别。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_13.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_13.png)'
- en: All right。 So how do we make address translation facts？ The cash， use of translations。
    All right。 And so this is a little different from how you think about a traditional
    cash。 The traditional cash you think about， like， you know， the key for it is
    like a memory location。 The physical memory location and the cash returns。 There's
    the contents of that memory location。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。那么我们如何加速地址转换？使用缓存来保存转换结果。好的，这和传统的缓存方式稍有不同。传统的缓存，你会想到它的键是一个内存位置，物理内存位置，缓存返回的是那个内存位置的内容。
- en: Here we're kind of caching the results of an algorithm。 The algorithm being
    the algorithm that we use for future virtual that returns that page table on。
    And it's indexed not by a physical address， but by a physical page， a virtual
    page number。 So。 we have our processor generating virtual addresses。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们有点像是在缓存一个算法的结果。这个算法是我们用来生成未来虚拟页表的算法。而它的索引方式不是通过物理地址，而是通过物理页和虚拟页号。所以，我们的处理器生成虚拟地址。
- en: our memory management unit that's going through our data cache walking through
    the page table。 generating the translation， and we're going to cash that result。
    So here we have our translation。 look aside， bussler， indexed by virtual page
    numbers， returning physical frame numbers。 along with a whole bunch of bits bits
    from our page table。 All right。 So here's a page table。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内存管理单元通过数据缓存，逐步访问页表。生成转换结果，并且我们会缓存这个结果。所以这里我们有我们的翻译，旁路缓存，按虚拟页号索引，返回物理帧号。还有一堆来自页表的位。好的，所以这里是一个页表。
- en: And we've loaded into our。 Okay。 So this is recording again， virtual page number。
    physical frame number translations。 If we find something in the TLD， we're done。
    We don't need to go out to memory。 We need to look at the page tables。 We don't
    need to do any of that particular stuff。 We have the answer。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们加载到我们的……好的。所以这是再次记录虚拟页号和物理帧号的转换。如果我们在TLD中找到了内容，我们就完成了。我们不需要再去访问内存，不需要查看页表，也不需要做其他任何事情。我们已经得到了答案。
- en: We have the physical frame number。 So， what that name comes from。 what was invented
    by Sir Morris Wilkes。 Prior to cash。 Because I realized on the early computers
    that there was this problem that they were running really slowly because they're
    spending all their time going out to memory。 Just to do address translation。 So
    he created this address translation cache。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有物理帧号。所以，这个名称的来源。是由莫里斯·威尔克斯爵士发明的，在缓存之前。因为他意识到，早期的计算机遇到了一个问题，那就是它们运行非常慢，因为它们花费了大量的时间访问内存，仅仅为了进行地址转换。所以他创建了这个地址转换缓存。
- en: And decided to call it the translation with the side buffer。 But then people
    realized that， wow。 you know， we could catch the result of sensations。 Why don't
    we just also use memory storage to hash the results of going out to memory。 And
    that's where it passes。 And they picked a veteran and a memory translation or
    memory。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们决定将它称为旁路缓存翻译。但随后人们意识到，哇，你知道，我们可以缓存转换的结果。为什么不直接利用内存存储来缓存访问内存的结果呢？这就是所谓的旁路缓存。于是，他们选择了内存翻译作为这个缓存的名称。
- en: look aside， but those are something like that。 Okay。 Now， when we don't find
    something in the TLC。 we just revert back to what we were doing before， which
    is the memory management。 It's just going to traverse through the trees， find
    the result。 And when we find that result。 we'll pass that result in the TLC。 Okay，
    so pulling it all together。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 看旁表，但那是类似的东西。好。现在，当我们在TLC中找不到某个内容时，我们会恢复到之前的操作方式，就是内存管理。它将遍历树，找到结果。当我们找到结果时，我们将把结果传递给TLC。好，将这些内容汇总起来。
- en: The processor generates a virtual address。 We look in the TLC， if we find it。
    we have our physical address， you can go directly with physical memory。 If you
    don't find it。 and we ask the MmU， translate this virtual address to a physical
    address and walk the table。 does all the things it does。 Generate the physical
    frame number， and we pass that translation。 Okay。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器生成虚拟地址。我们查看TLC，如果找到它，我们就有物理地址，可以直接访问物理内存。如果没有找到，我们就请求MMU，将虚拟地址转换为物理地址，并遍历表格。它会做所有的工作，生成物理帧号，然后我们传递该翻译。好。
- en: and of course we have uncranslated。 So there's a couple of questions。 So this
    is all premise on the idea that there is a real problem。 So if I access a page
    as a program。 am I likely to access that page again？ If the answer is no。 then
    there's no benefit to cash in the translation。 The programs are just， you know。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当然我们也有未翻译的内容。所以有几个问题。这一切都建立在有一个真实问题的假设上。所以如果我作为程序访问一页，我是否可能再次访问那一页？如果答案是否定的，那么翻译缓存就没有任何好处。程序就是那样的。
- en: kind of ping ponging all over their memory， never touching the same page， plus。
    would be zero benefit。 But that's not true。 It's not how programs typically behave。
    So if we look at instruction accesses， they spend a lot of time on the same page。
    but your code runs sequential。 Then you have branches， you have things like that，
    but in general。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一种在内存中不断跳跃的方式，永远不碰同一页，而且结果是零效益。但这并不正确。程序通常不会这样行为。所以如果我们看指令访问，它们会在同一页花费很多时间。但是你的代码是顺序执行的。然后你有分支、还有类似的东西，但总体来说。
- en: we will stay on the same page。 Periodically， you know。 call some library or
    call some sub-routine and change pages。 But many of your instruction fetches will
    be on the same page。 So we'll gain some benefit from passion that translation。
    Stock accesses。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会停留在同一页。周期性地，调用一些库或子例程，换到另一页。但是许多指令获取会停留在同一页。所以我们会从翻译缓存中获益。栈访问。
- en: definitely locality of reference。 We grow our stack， incrementally shrink our
    stack， incrementally。 So you're going to spend most of the time on the stack on
    the same page。 Periodically。 you'll go up or down a page。 Data accesses， a little
    bit more complicated。 Many times you will have low quality， but not always， right？
    So the example I gave earlier。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对存在局部性参考。我们递增地增长栈，递减地缩小栈。所以大部分时间你都会在同一页上停留。周期性地，你会上下翻动页面。数据访问则稍微复杂一些。很多时候你会有低质量的访问，但并不总是如此，对吧？比如我之前给的例子。
- en: where I'm going through the characters in a string。 those will all be on the
    same page and empirically help these values that say crosses your page。 But if
    I have a lookup table， you know， I might be doing random accesses。 Why is the
    database。 it might be a lot of random accesses to that data structure。 So it's
    going to vary。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在字符串中遍历字符时，那些都在同一页上，实验证明这些值会跨越页。但如果我有一个查找表，你知道的，我可能在做随机访问。为什么是数据库呢，可能会有很多随机访问这个数据结构。所以它会变化。
- en: But definitely for stack， definitely for instruction fetch。 we'll see that we
    have a lot of page with all。 Okay。 Can we have a hierarchy of the tailgreens？
    Yes。 we can have multiple levels of field these operating with different organizations。
    Yeah， question。 Yeah， so the question is when the processor is going through the
    tool B。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于栈，肯定是如此，对于指令获取也是如此。我们会看到有很多页面都被使用。好。我们能有一个页表的层次结构吗？可以，我们可以有多个不同组织的层次结构来操作。是的，问题是什么？是的，问题是当处理器通过TOB时。
- en: does it have to go through the MME or can go directly with that。 So again。 the
    idea is that you ask the TOB first， it's the cache。 if it has that translation
    from the virtual page number， the physical page number， the doc。 If it doesn't，
    then you ask the memory management unit， you have to have a TOB miss。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 是否必须通过MMU，还是可以直接访问？所以再说一次，关键是首先询问TOB，它是缓存。如果它有虚拟页号到物理页号的翻译，返回。如果没有，再询问内存管理单元，就会出现TOB缺失。
- en: then you go to the member management unit， and it walks the freeze。 Generates
    the translation from that virtual page number to the physical page frame。 and
    then it tells the TOB， here is that translation and all of the bits that are associated
    with it。 hash this for the future。 And then you go out to the path。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你去访问成员管理单元，它会处理冻结。生成从虚拟页号到物理页框的转换。然后它会告诉TOB，这就是转换以及与之相关的所有位。为未来进行哈希处理。接着你就会走到路径那里。
- en: So this all happens before we go to the cache and that's why it has to be your
    test。 If we don't have a good hit rate in the TOB， then we're not going to move
    matter if we have a very high hit rate in the cache。 we're going to spend a lot
    of memory access is just to get to our on-track path。 Yeah。 so this is actually
    very important。 So this extra path here where the CPU can generate physical addresses。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这一切都发生在我们访问缓存之前，这就是为什么它必须是你的测试。如果我们在TOB中的命中率不好，那么即使我们在缓存中有非常高的命中率，也不会有任何影响。我们将花费大量的内存访问时间仅仅是为了找到我们正确的路径。是的，所以这实际上非常重要。因此，这条额外的路径是CPU可以生成物理地址的地方。
- en: So you think about it， the operating system needs to be able to go in and manipulate
    things like talk directly to devices or memory map or be actually able to set
    up page tables。 And so there are a lot of cases where the operating system needs
    to be able to directly write the physical memory。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你要考虑，操作系统需要能够进入并操作一些东西，比如直接与设备交互或内存映射，或者实际上能够设置页表。因此，在很多情况下，操作系统需要能够直接写入物理内存。
- en: And so then in that case， you know， there's no translation that happens。 We're
    operating in the physical address space of the machine as opposed to in some processes
    for the address space。 Otherwise， there'd be like no way to set up page tables。
    Yeah。 Correct。 The question is。 we should do user processes from being able to
    generate these unferencing。 Absolutely。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这种情况下，知道没有发生地址转换。我们在机器的物理地址空间中操作，而不是在某些进程的地址空间中。否则，就没有办法设置页表。是的。正确。问题是，我们应该阻止用户进程能够生成这些未经翻译的地址。绝对应该。
- en: But if we didn't， then a user process would read any physical memory。 So。 dual
    mode operation requires that if you're going to generate physical addresses。 you
    have to be running like a protective mode， a phenomenon。 Any other questions？
    Yeah。 Yeah。 So the question is whether there's something that indicates whether
    the CPU is access and translated or un-ventilated addresses。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果没有的话，那么用户进程将能够读取任何物理内存。所以，双模式操作要求如果你要生成物理地址，必须处于保护模式或某种现象下。还有其他问题吗？是的。是的，问题是有没有什么东西表明CPU正在访问和转换的地址，或者是未经通风的地址。
- en: So typically， there might be something like reserved instructions。 And so those
    instructions can only execute on the request of which level is at the final level。
    that allow you to do directly， the loads and stores that are absolutely a mark
    going through translation。 But it's going to be our correct agenda。 Yeah。 Yeah。
    So the question is。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 所以通常，可能会有一些类似保留指令的东西。这些指令只能在请求特定级别时执行，直到最终级别。它们允许你直接进行加载和存储，完全不经过转换。但这将是我们正确的议程。是的。是的，问题是。
- en: can I give some examples of why the kernel would want to be un-ventilated addresses。
    So two easy examples would be like the graphics frame buffer is typically at a
    very specific location in physical address space。 And for performance， I might
    want to be able to read and write from the kernel directly into the graphics frame
    buffer without having to go through any kind of cancellation。 I could also map
    windows and things like that， from the frame buffer into various address spaces。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我能举一些例子，说明为什么内核需要使用未经通风的地址吗？两个简单的例子是，图形帧缓冲区通常位于物理地址空间中的一个非常特定的位置。为了提高性能，我可能希望能够从内核直接读写图形帧缓冲区，而不需要经过任何形式的取消。我还可以将窗口等内容从帧缓冲区映射到各种地址空间中。
- en: but those would then go through address translation。 The other key reason why
    you want to do it is how do you set up the page tables in the first place。 Like，
    you need to say， tables are located in physical memory。 And so to set those up。
    I need to be able to read and write directly to the physical memory。 What are
    your questions？ Okay。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些地址最终会通过地址转换。你想这么做的另一个关键原因是，如何在第一步设置页表。比如说，你需要知道，页表位于物理内存中。因此，为了设置它们，我需要能够直接读写物理内存。你有什么问题吗？好的。
- en: So the question is， are we assuming that we pass after every access。 Yeah， so
    the TLC。 So we're only going to need to update the TLC when we make a change to
    something that the TLC is passing。 For example， if。 So when we do a translation
    on the MME the other hand。 that's a point we'll put it into the TLC。 The TLC tracks
    whether something's been recently accessed。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 所以问题是，我们是否假设每次访问后都会通过缓存？是的，对于 TLC（Translation Lookaside Buffer），我们只在对 TLC 中的内容进行更改时才需要更新。例如，当我们进行
    MME 翻译时。那时我们会将其放入 TLC 中。TLC 跟踪某个内容是否被最近访问过。
- en: So the TLC will be updated when we do a week or a right。 And similarly， when
    we do a right。 we might have a dirty bit that tracks that that underline changes
    the modified。 And so that would cause a TLC update。 But we're going to go into
    this more detail。 So on the previous slide， it says if the TV misses， then we
    check the catch。 Yeah。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，TLC 会在我们进行读或写时更新。类似地，当我们进行写操作时，可能会有一个脏位（dirty bit），它跟踪缓存行是否被修改。这会导致 TLC 更新。但我们将会详细讨论这一点。在上一张幻灯片中，提到如果
    TV 缓存未命中，我们会检查其他缓存。是的。
- en: so if the TV misses， then we're just going to do translation using memory management
    unit。 And that's going to walk the trees。 And remember the memory cache is hashing
    the thing that are in memory。 And that could include page table entry for the
    page tables and so on。 So we're always going to do all of our reason rights to
    the class。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是 TV 缓存未命中，我们将使用内存管理单元进行翻译。它会遍历树形结构。并且请记住，内存缓存会对内存中的内容进行哈希处理。这可能包括页面表条目、页表等。因此，我们始终会将所有的写入操作指向缓存。
- en: That way potentially you might find that page table entries that are relevant
    to the translation are actually in the past。 which case we get to say on the processor。
    We never actually have to go out to name them。 So is the TV before the one cash。
    Yes， the table is before the open cash。 We're getting a little head。 We're going
    to have a picture that shows what a modern process for our technical looks like。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这样你可能会发现，实际与翻译相关的页面表条目已经在缓存中了。在这种情况下，我们可以在处理器上继续操作，而无需访问内存。因此，TV 缓存是在一级缓存之前吗？是的，表格是在开放缓存之前。我们稍微提前了一些。接下来我们会展示一个图像，显示现代处理器的工作流程。
- en: And you'll see that there's actually multiple。 And there's actually shared。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 而且你会发现实际上有多个缓存。并且它们是共享的。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_15.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_15.png)'
- en: So， good question。 What organization， what kind of cash is a TV？ Well， you think
    about caches。 there's a lot of different parameters that we can use in picking
    what kind of organization you have。 So there's the size， and we have all of it
    in our。 There's the associativity， except all size。 There's the number of sites。
    Right。 And then there's the line size。 Now， remember。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 好问题。那么，TV 缓存是什么类型的缓存？嗯，考虑缓存时，有很多不同的参数可以用来选择缓存的组织方式。例如，它的大小，我们所有的缓存都包含其中。还有它的关联性，大小等。还有缓存行大小。现在，记住。
- en: this is something located on the process of die。 So every transistor is incredibly
    expensive。 limited amount of area implemented。 And so making the design trade
    off properly。 It's going to be really important for performance。 There's also
    a right policy。 So when we store something into make a change。 Is it right or
    is it right back？
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是位于死循环过程中的内容。因此，每个晶体管都非常昂贵。实施的区域有限。所以正确地做出设计权衡将对性能非常重要。还有一个正确的策略。那么，当我们存储某些内容以进行更改时，它是正确的吗？还是应该回滚？
- en: So how might our organization of the TV。 Different from the organization of
    a traditional data capture and stuff。 Answer that question。 You can probably take
    a look and make sure everybody remembers all the different types of class organizations
    from 60 and C。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何组织 TV 缓存？与传统数据缓存和存储的组织方式有何不同？要回答这个问题，你可以查看一下，确保每个人都记得 60 和 C 中各种缓存组织类型的内容。
- en: Okay， before we do that， let's look at why things might not be in a past。 So
    why we might have a cat to miss。 So the first， there's three plus one， I call
    it sources of cash。 So the first is compulsory。 The cold hard track life that
    the first time you go to access something。 it's not going to be in the catch。
    And so you have to go out to memory， retrieve it。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，在我们继续之前，先来看看为什么某些内容可能不在缓存中。那么为什么我们可能会错过某些内容呢？首先，有三个加一个，我称之为缓存的来源。第一个是强制性的。那就是你第一次去访问某个内容时，它不会在缓存中。因此，你必须去内存中取回它。
- en: and then put it into the catch。 Now， if you've got a long 11 program， you know。
    you've got billions of instructions and these cold start effects might be minimal。
    But if every time you contact switch， you have to slush the cash。 and you're always
    going to be faced with compulsory misses。 Now， it's also。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将其放入缓存中。如果你有一个较长的程序，你知道，程序中有数十亿条指令，而这些冷启动效应可能是微乎其微的。但如果每次你进行上下文切换时，都必须刷新缓存，并且你总是会遇到强制性缺失（compulsory
    misses），那么情况就不同了。现在，情况也是这样。
- en: I think a little misleading when we call it compulsory because we actually can
    get around。 Because I know that I'm going to， like， I， you know， I represent the
    particular block。 That first reference of the block， that's going to cause a multiple
    miss。 If I know that I'm doing sequential access， I know I'm going to access the
    next block。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为将其称为强制性有些误导，因为实际上我们可以规避它。因为我知道我将要访问某个特定的块。那个块的第一次引用，肯定会导致多次缺失。如果我知道自己正在进行顺序访问，我知道接下来会访问下一个块。
- en: I could actually pre-search that block so that by the time I go to request that
    block。 the cash has it already。 I avoid that compulsory miss。 I want to trade
    off with doing pre-fetching。 eight on a time to go into the benefit is you can
    avoid some of these cold start misses。 The downside is you might be kicking something
    valuable out of the path in order to proof at something that we actually don't
    end up using。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上可以提前预取那个块，这样等我去请求那个块时，缓存已经有了。我避免了强制性缺失。我希望通过进行预取来权衡这一点。预取的好处是可以避免一些冷启动缺失。缺点是，你可能会将一些有价值的数据从缓存中踢出去，以便为一个我们最终不会使用的数据项腾出空间。
- en: Okay。 Next type of miss is a capacity miss。 So this is where the cash doesn't
    have less space。 You can't contain all of the blocks that are doing the options。
    The solution。 Go out and buy a bigger path。 And so when you look at process respects。
    we'll see they have an instruction cache， a beta cache， shared passes， all one
    deltings， all foods。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，下一个缺失类型是容量缺失（capacity miss）。这是当缓存没有足够的空间时。它无法容纳所有正在执行操作的块。解决方案是，出去买一个更大的缓存。所以，当你查看处理器规格时，我们会看到它们有指令缓存、数据缓存、共享缓存、所有的删除缓存、所有的食品缓存。
- en: And the difference when you look at the lowest costs。 the i3 versus i9 will
    be in the size of the passes。 And so that's one of the most expensive parts of
    a processor because I take up a lot of area and the process of that。 So a cheaper
    processor， smaller die， less space for that。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 而当你查看最低成本的差异时，i3 和 i9 之间的区别将在于缓存的大小。因此，这也是处理器中最昂贵的部分之一，因为它占用了大量的面积和处理过程。所以，较便宜的处理器，较小的芯片，减少了用于缓存的空间。
- en: But then I'm going to have more capacity misses。 And so that's part of the reason
    why。 even though the same architecture。 One processor might be much slower on
    workloads than another processor。 And that's a good example for that。 Okay， another
    source is what we call conflict or collision misses。 This is where one of two
    or more data items， collab。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但接下来，我会遇到更多的容量缺失（capacity misses）。这也是为什么，即使使用相同的架构，一个处理器在某些工作负载上的表现可能比另一个处理器要慢的原因。这就是一个很好的例子。好吧，另一个来源是我们所说的冲突缺失（conflict
    misses）或碰撞缺失。这是当两个或更多的数据项发生冲突时发生的情况。
- en: And so we end up having to replace one to store the other。 but then we go and
    access that thing that you just replaced。 And so you kind of can end up in a form
    of crash， the multiple data items that map to the same location in the path。 So
    solutions， again， spend more money and get a bigger cash。 Or make it have more
    social。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们最终不得不替换一个数据项来存储另一个。但是，随后我们访问的是刚刚被替换的数据项。所以你可能会陷入一种崩溃的形式，多个数据项映射到路径中的同一位置。因此，解决方案，还是花更多的钱买更大的缓存，或者让缓存具备更多的社会性。
- en: Make it set associative director， make it fully associated or more sets。 Or
    include the。 but reduce the conflict mystery。 And finally， there's one that you
    don't see。 talk about as much as a， which is called parents misses。 These are
    a form of invalidation。 But for example， if I'm passing some location in memory。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用集合关联的结构，或者使其完全关联，或者增加更多的集合。但减少冲突缺失。最后，还有一种你不常听到的缺失类型，叫做父缺失（parent misses）。这是一种无效化的形式。例如，如果我正在传递某个内存位置。
- en: and there's a direct memory access controller and IO controller that's leading
    something from the disk。 And it reads it for a block from the disk and writes
    it into memory。 That is what I have in the past。 I've now invalidated the contents
    of the cache。 That DNA operation invalidated。 Or， for example， if I have a multi
    processor and another processor writes the same memory location that I have cash。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个直接内存访问控制器和IO控制器，从磁盘读取某些东西。它从磁盘读取一个块并将其写入内存。这就是我过去的操作。我现在已经使缓存的内容失效。那个DNA操作使其失效。或者，例如，如果我有一个多处理器，而另一个处理器写入我缓存的相同内存位置。
- en: Now my copy of that memory location is invalidated。 A lot of work goes into
    the invalidation protocols， the multi processes。 Okay。 Now。 how do we find something
    in a page？ We take our address and we break it up into components。 So our block
    is our minimum quantum or unit and transfer。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我复制的那个内存位置已经失效。大量的工作进入了失效协议，多进程的处理。好的。现在。我们如何在页面中找到某个内容？我们将地址分解成各个部分。所以我们的块是最小的量子或单位，用于传输。
- en: When we think about transferring something from a lower level to an upper level。
    we move it in blocks。 But when we think about moving some memory from blocks from
    memory into a processor path。 That block size might be something like 16 bytes
    or something like that。 When you think about going out to disk， it might be something
    like four kilobytes that we move into one。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑将某些东西从较低层次传输到较高层次时，我们按块移动它。但是当我们考虑将一些内存从块从内存移动到处理器路径时。那个块的大小可能像16字节或类似的东西。当你考虑去磁盘时，它可能是像四千字节那样的一个块被移动。
- en: And so， at each level of a hierarchy， we think about what's the block going
    on already that we're moving。 Now the data selects you the lower order bits are
    used select within that block。 So the number of bits we allocate to the offset
    is going to control the size of our blocks。 Well。 not all passionate applications
    that will have that。 Like in the case of a TLE， you know。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在每一层级的层次结构中，我们考虑的是我们正在移动的块。现在数据选择你，低位用于在那个块中选择。所以我们分配给偏移量的位数将控制我们的块的大小。嗯。并不是所有的应用程序都会有这个需求。就像在TLE的情况下，你知道。
- en: we don't have that。 Because we're just returning the translation。 Now we have
    the index。 which is used to identify a potential set in the cache that would have
    the data。 And then we use the tab to actually identify whether what's stored in
    the cache is the thing that we're looking for。 All right， so let's go through
    the three different types of cache organizations using this model for highly funded
    in the cache。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有这个问题。因为我们只返回翻译。现在我们有了索引，用来标识缓存中可能包含数据的一个集合。然后我们使用标签来实际识别缓存中存储的内容是否是我们要找的东西。好了，接下来让我们通过这个模型，回顾三种不同类型的缓存组织，针对缓存中的高度资金配置。
- en: The first one we're going to review is a direct map。 So we have a direct map
    path。 it'll have two to the end bytes that it's storing。 The upper 32 minus n
    bytes is going to be our cap。 The lower our bits right。 the lower end bits is
    going to be our offset into the block。 So in the three。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要回顾的第一个是直接映射。所以我们有一个直接映射路径。它将存储2的n次方字节。上面的32减去n个字节将是我们的上限。最低的n位将是我们在块中的偏移量。所以在这三种情况下。
- en: that's what will be the bytes left。 So this says our blocks are going to be
    two to the end in size。 So here's an example of our path。 So here we have blocks
    that each one of these lines is a block。 The one kilobyte direct map path that
    is 32 bytes blocks。 That's a bit as 32 bytes。 How many bits do we need？ This is
    powers of key。 All right。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是剩下的字节数。所以这说明我们的块将是2的n次方大小。所以这里有一个路径的例子。所以这里我们有块，每一行就是一个块。1千字节的直接映射路径是32字节的块。那就是32字节。我们需要多少位？这是以2为底的幂次。好的。
- en: so we're going to take our lower five order bits。 That's our byte。 That's how
    we're going to be able to sell up a particular。 We're going to take the next。
    Five and use those as our cash index。 Again， you can see here we have 42 blocks。
    A two to the five。 So we select that。 Then we use our tag。 Let's see。 Okay， the
    thing that's cashier。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们将取出最低的五位。这就是我们的字节。这就是我们能够设置特定值的方式。然后我们取下一个五位，将其用作我们的缓存索引。再次，你可以看到这里我们有42个块。2的五次方。所以我们选择它。然后我们使用我们的标签。让我们看看。好的，那就是收银员的事情。
- en: the block that's cashier is not the block I'm looking for。 It's going to use
    our tag to check if there's a match。 There's a comparator there。 If it matches。
    we know we found the block we want。 Now we just need to fight。 And that's where
    we're going to use the byte select or treat the actual。 That's a direct map。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存中的块不是我正在寻找的块。它将使用我们的标签来检查是否匹配。那里有一个比较器。如果匹配，我们知道我们找到了我们想要的块。现在我们只需要选择字节。这就是我们将使用字节选择器或处理实际内容的地方。这是直接映射。
- en: For a set associative cash， the way to think about it is now we have basically。
    Anyway， anyway。 set associative cash。 Now we're going to have any direct map passes。
    All right。 Now。 an important consideration here is that。 Whenever we compare caches。
    we assume the total number of entries is always the same。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集合关联缓存，思考的方式是：现在我们基本上拥有了。总之，集合关联缓存。现在我们将没有任何直接映射通过。好吧。现在这里一个重要的考虑因素是：每当我们比较缓存时，我们假设总条目数始终相同。
- en: So we have not doubled the number of entries by going to a two way set associative。
    In fact。 it's the same number of entries are just organized into。 These banks
    of direct map caches that are operating in parallel where each。 Okay， so here。
    our cash index is used again to select one of these。 Sets。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 所以通过使用二路集合关联，我们并没有使条目数量翻倍。事实上，条目数量是相同的，只是组织成了这些直接映射缓存的银行，并且它们是并行工作的，每个缓存都能独立工作。好了，所以在这里，我们的缓存索引用于选择其中一个集合。
- en: And then we take our cash tag and we're going to use。 And we're going to use
    the same number of entries。 And we're going to use the same number of entries。
    And we're going to use the same number of entries。 And we're going to use the
    same number of entries。 And we're going to use the same number of entries。 And
    we're going to use the same number of entries。 And we're going to use the same
    number of entries。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用我们的缓存标签，并且我们将使用相同数量的条目。我们将使用相同数量的条目。我们将使用相同数量的条目。我们将使用相同数量的条目。我们将使用相同数量的条目。我们将使用相同数量的条目。我们将使用相同数量的条目。
- en: And we're going to use the same number of entries。 The results of those comparators
    have to go through a bunch of gate logic and everything。 And that's going to feed
    into a multiplexer。 That multiplexer will take the block and then provide the
    block。 And then we can use our。 These are our bytes select the select the actual。
    Fight from that block。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同数量的条目。这些比较器的结果必须通过一堆门逻辑和其他组件。然后这些会传递到多路复用器中。该多路复用器将获取块并提供该块。然后我们可以使用我们的。这里是我们的字节选择器，选择实际的内容。
- en: So there's a trade off。 But now we have more places to places in this case where
    we could store a potential item in the cap。 So that's going to help us with reducing
    our conflict。 This way。 But that is a lot more logic。 We have multiplexers and
    it was just two。 And I just want to get to eight。 You can't build a multiplexer
    that has eight inputs。 You typically have like a tree of multiplexers。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是一种权衡。但现在我们有更多的地方可以存储潜在的项。所以这有助于我们减少冲突。以这种方式。但那会涉及更多的逻辑。我们有多路复用器，它们只有两个。而我只是想达到八个。你不能建造一个具有八个输入的多路复用器。通常你会使用一个多路复用器的树形结构。
- en: Each of those has a little bit of a big delay associated with it。 And so when
    we start to add up all these data， a set of those that are passed is going to
    run slower。 And a direct map。 So， we've made the access time higher or a little
    bit。 But we get the benefit of reducing the conflict。 And also takes up more area
    because all multiplexers and gate logic and all。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些每一项都有一定的延迟。因此，当我们开始将所有这些数据加起来时，传递的那些数据集合会运行得更慢。和直接映射一样。所以，我们增加了访问时间，虽然只是稍微增加了一点。但我们可以通过减少冲突来获得好处。同时也需要更多的空间，因为所有的多路复用器、门逻辑等都需要占用空间。
- en: Counts against their transistor count that we have on the bottom。 It's more
    expensive to implement a set of sensitive。 But you know。 if we're going to do
    set associated。 What happens to which is make everything。 To compare every single
    country rather than just breaking things up。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这会影响我们底部的晶体管数量。实现一组敏感的操作更为昂贵。但你知道，如果我们要做集合关联的话，结果就是让每一项都进行比较，而不是仅仅将事物拆开。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_17.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_17.png)'
- en: That's what we get to do a fully associated。 So now there's no index。 Our tag
    is everything other than our fight。 And so attached to each of these entries blocks。
    Is a tag or a big comparator。 This takes the most amount of additional logic to
    implement。 And that's going to make it slower。 But we have no conflict misses。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们进行完全关联时所能做的。因此，现在没有索引了。我们的标签是除了我们的末尾之外的所有东西。并且附加在这些条目块上的每个条目上都有一个标签或者一个大的比较器。这需要最多的额外逻辑来实现。这会使得它变得更慢。但是我们没有冲突未命中。
- en: Like any block can go anywhere in the class。 Well。 I'm not going to have the
    problem of two blocks going into the same place。 Now。 where do we put a block
    in a cache？ How do we decide？ So let's look at an example。 So here is an 32 block
    address space。 We've got a cache that holds eight lines。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何块都可以放在类中的任何位置。好吧。我不会遇到两个块进入同一位置的问题。现在，我们将块放入缓存中，应该怎么决定呢？让我们来看一个例子。这里有一个32块地址空间。我们有一个包含八条线的缓存。
- en: So where would block 12 go in our eight block？ Well， it's easy in a direct map
    cache。 There's only one place in the 12 mod of the block four。 That's the only
    place it can go。 Now that we're going to have a problem， right？ Because any other
    block from our 30 block address space。 That is not a equal to four。 What happens
    at our address， you know。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，块12应该放到我们八个块的哪儿呢？在直接映射缓存中很容易。12模4的唯一位置就是这里。它只能放在这个地方。现在我们会遇到问题，对吧？因为我们的30块地址空间中的其他任何块。如果不是等于4的地址，会发生什么呢？
- en: stride pattern or whatever access pattern is one of those。 And we're going to
    just go back because we're going to replace this block with that other request。
    And then we're going to make a request for this block and replace that other block。
    And we're just going to ping on back and forth。 And a set associative cache。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅模式或任何访问模式都可能是其中之一。我们将只需返回，因为我们将用另一个请求来替换这个块。然后我们会请求这个块并替换另一个块。我们就会来回地进行切换。然后是一个集合关联缓存。
- en: It can go anywhere and set zero， which has two options。 These two ways set associative。
    It's sort of a 12 mod four。 Again， recognize here we have the caches have the
    same size。 eight block hash。 Both cases。 But now we have two different places
    that we can put that block。 That's going to reduce the likelihood that we're just
    being home between， you know。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以放在集合零中，那里有两个选项。这是两路集合关联的。它有点像12模4。再次强调，这里我们有两个缓存，它们的大小相同。八个块哈希。无论哪种情况。但现在我们有两个不同的位置可以放这个块。这将减少我们只是不断碰撞的可能性。
- en: like we might have in the graph。 And then if we look at a fully associative
    cache。 it can go anywhere。 Again， we reduce the conflict this way down to zero。
    But it takes more hardware and explore the answers。 New questions。 So， which block
    do we replace？
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在图中可能遇到的那样。然后如果我们看一个完全关联缓存，它可以去任何地方。再一次，通过这种方式我们将冲突降到了零。但它需要更多的硬件并且会探索更多的答案。新的问题。那么，我们该替换哪个块呢？
- en: What do we have in this？ Well， it's really easy with a direct map cache。 We
    only have one choice。 Right。 It only maps to one location。 With a set associative，
    fully associative。 Well。 now we have a choice。 And so we need some block replacement
    algorithm that's going to pick between the potential location that we could use。
    So we can， you know， some of the algorithms might think about are random。 Why
    random？ Well。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下我们得到了什么？好吧，使用直接映射缓存是很容易的。我们只有一个选择。对吧？它只映射到一个位置。使用集合关联，完全关联缓存。好吧，现在我们有了选择。所以我们需要一些块替换算法，用来在我们可以使用的潜在位置之间做选择。所以，我们可以考虑的算法之一是随机的。为什么是随机的？嗯。
- en: really easy to implement a random number generator in part。 It's actually kind
    of very complicated to make it more random， not firmly dependent on that。 And
    all we know is， but you can do something that's relatively good。 It's come a two
    around number one。 Another alternative。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 实现一个随机数生成器在某部分其实非常简单。实际上，要让它更随机一点，并且不依赖于那个固定的方式，这会变得相当复杂。我们所知道的只是，你可以做一些相对较好的事情。它是围绕着第一个数值来的。还有另一种选择。
- en: why do we use something like these recently used？ The which of those blocks，
    we have locality。 so I'll show you temporal locality， which of those blocks would
    use farthest in the class。 That's the one we're going to admit and replace with
    the block that we want to explore。 Okay。 so here's an example of a workload。 It's
    just a random， you know， kind of benchmark workload。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们使用像最近使用过的这样的策略呢？我们有哪些块有局部性？我会展示一下时间局部性，哪些块在课堂中使用最远的。那就是我们要替换的块。好的。这是一个工作负载的示例。它只是一个随机的，你知道的，基准工作负载。
- en: And we're sort of different axes to look at for casual organization。 So we have
    the degree of associativity。 So two way， four way， eight way。 You have choice
    of algorithm for replacement。 And then here on the， on the Y side。 we have rows
    that are the size。 I want to be a jerk。 Well， for small caches。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从不同的角度来看待缓存组织。所以我们有关联度的程度。比如二路、四路、八路。你有替换算法的选择。然后在这里，在 Y 轴上。我们有行，这是大小。我想做个坏人。嗯，对于小缓存。
- en: especially if it's actually kind of independent， I guess， of the， the system。
    There's anywhere from 0。5 to 0。6% difference between using our new and using random。
    which is actually pretty significant。 The point six is， is what applies， you saw，
    then we looked at。 you know， what we needed to have as mistakes。 On the other
    hand。
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是如果它实际上有些独立的话，我猜，是的，系统之间有大约 0.5% 到 0.6% 的差异，这实际上相当显著。那个 0.6% 是，正是适用的，你看，然后我们看了，你知道，我们需要什么作为错误。另一方面。
- en: stop and think about it for a moment。 Implementing LRU， it's going to require
    extra data。 Like you have to have a clock， you have time stamps。 You have to have
    a lot of logic to actually be able to go through and compare each entry， the scene。
    which has the oldest time stamp process。 And so， is it worth it to spend that
    for a point six percent gain？
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 停下来想一想。实现 LRU，它需要额外的数据。比如你必须有一个时钟，时间戳。你必须有很多逻辑才能实际遍历并比较每个条目，看看哪个有最旧的时间戳。因此，值得花费那么多精力来换取
    0.6% 的增益吗？
- en: Maybe， but， you know， we have to really look a lot deeper into it because it's
    going to be a lot of software or we try to do it in hard work and do a lot of
    hardware overhead implemented。 On the other hand， when we look at the larger caches。
    there's really no difference between LRU and random。 And given that random is
    so easy to implement in hard work， we would just pick a random model。 Now。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 也许吧，但是，你知道，我们必须深入地去看一下，因为它会涉及大量的软件，或者我们尝试在硬件中实现，付出很大的硬件开销。另一方面，当我们看到更大的缓存时。LRU
    和随机之间其实没有什么区别。鉴于随机算法在硬件中如此容易实现，我们就选择一个随机模型。现在。
- en: big caveat here， giant aspect that I have to add here is this is just one workload
    running on this organization's box and replacing box。 Before I made a decision
    like that， I'd want to look at a lot of different representative workloads to
    determine。 you know， what might be the best algorithm to use。 Okay。 Now， how do
    we handle writes？
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有个大警告，巨大的方面是，我必须补充的是，这只是一个工作负载在这个组织的盒子和替换盒子上运行。在我做出这样的决定之前，我想要查看很多不同的代表性工作负载，以确定，你知道，可能最好的算法是什么。好吧。现在，我们如何处理写操作？
- en: If you remember， we have two choices for writes。 One approach is write for it。
    So when I make a write to the cache， I also write the next level of the memory
    viral。 So the cache only ever contains the same data that's in the backing memory
    or pages。 All right。 Now。 the other alternative is write back。 So here I write
    things to the cache and it's only when I'm going to evict it from the cache or
    replace it。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得，我们有两种写操作选择。一种方法是写穿透。所以当我向缓存写入数据时，我也会写入内存的下一级。所以缓存中永远只包含与备份内存或页面中相同的数据。好吧。现在。另一种选择是写回。所以在这里，我将数据写入缓存，只有当我将其从缓存中驱逐或替换时。
- en: But then I go and I write that block to the next level of the memory horror。
    So now I got to keep track of is the data in the particular block， queen。 as in
    it perfectly matches what's in the backing store， or is it dirty， in which case。
    I have to write it back。 I'm going to evict it from the closer。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 但是接下来我去将那个块写入下一级的内存层次。所以现在我必须跟踪的是特定块中的数据，是否干净。就像它是否与备份存储中的数据完全匹配，还是脏的，如果是这样的话，我必须将它写回。我将从缓存中驱逐它。
- en: So let's think about some of the pros and cons。 I would write through。 I get
    the advantage that a weakness can't result in a life。 Okay， that's a little complicated。
    What does that mean？ Think about it。 I go to read something and I check the cash。
    It's not in the cash。 What am I going to do？ I'm going to go to the backing memory，
    read that item。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们考虑一下它的一些优缺点。我会选择写穿透。这样我就可以得到一个好处，即弱点不会导致故障。好吧，这有点复杂。这是什么意思？想一想。我去读取某些东西并检查缓存。它不在缓存中。我该怎么办？我要去备份内存，读取那个项。
- en: and cash it in store in the cash。 Pass it。 All right。 But what if the cash is
    full？
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 并且将其现金存储在现金中。通过它。好吧，但是如果缓存满了呢？
- en: I have to pick a block in the cash from a place。 What happens if I pick a block
    that's dirty to replace。 If it's not right through， well， first of all， if it's
    right through none of the blocks will be good。 If it's right back， then that block
    won't be dirty。 I mean， I have to write it back to none。 So this is a little weird，
    right？ The processor is doing a read from memory and ends up having to do a lot。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我得从缓存中挑选一个块。如果我选中了一个脏块来替换会怎样？如果是直写，那就没有问题，因为所有块都会更新。如果是写回，那块数据就不会是脏的了。也就是说，我得把它写回内存。所以这就有点奇怪，对吧？处理器从内存读取数据时，最终不得不做很多工作。
- en: So that's where having rights， I'm going to throw on a read。 The other downside
    here though。 is imagine I'm doing a ton of rights。 Well， processor operates in
    the nanoseconds memory hundreds of nanoseconds。 So every write I do is going to
    take 100 nanoseconds to go out from memory and write it。 So I'm going to make
    my processor run 100 times slower。 So the solution is to put a buffer。
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这就是拥有写操作时的一个问题。我会丢到缓存里。这里的另一个缺点是，想象一下我做了很多写操作。嗯，处理器的操作时间是纳秒级别，内存则是几百纳秒。所以我每次写操作都需要100纳秒才能从内存写出。所以这会让我的处理器变得慢100倍。所以解决办法是使用缓冲区。
- en: And now when I do writes， the writes get buffered and eventually make it out
    for the memory。 I can return as soon as I put something into the write buffer。
    But now that's going to gate house how far ahead I can get。 If I fill the write
    buffer and now I'm back to running the speed of memory。 Alternatively。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我进行写操作时，写入会被缓冲，最终会写入内存。我只要把数据放入写缓冲区，就能立即返回。但现在，这会限制我能多快地执行。如果缓冲区满了，我就得恢复到内存的速度。或者说。
- en: if I do write back， then think about it。 If I've got a counter that I'm just
    sitting there updating。 That's all those updates are going to get absorbed by
    the catch with write back。 So I'm writing it cache speeds。 And then periodically
    when I end up having to evict that block。 I'm going to write it back to memory
    speed。 But most of my writes are going to operate at the speed of the path。
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我采用写回策略，那就得考虑一下。如果我有一个计数器，正在不断更新。所有这些更新都将通过写回被吸收到缓存中。因此，我写入的速度是缓存的速度。而当我最终不得不驱逐那个数据块时，我会以内存的速度将它写回。但我大部分的写操作都会以缓存的速度进行。
- en: And so it's really good for absorbing rights not holding up the processor on
    rights。 But the downside complexity。 I've got to keep track of some of the data
    in the cache。 It's clean。 Some of the data is dirty。 When I'm doing replacement。
    I've got to figure out am I going to replace something clean for us because that's
    free。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，它对于吸收写操作很有效，不会让处理器在写操作上卡住。但缺点是复杂性。我必须跟踪缓存中的一些数据，知道它们是干净的，还是脏的。当我进行替换时，我得弄清楚，我是要替换掉干净的数据块，还是脏的数据块，因为干净的数据块是免费的。
- en: Or am I going to put it might be something I'm using a lot。 So instead I want
    to play something dirty， get a schedule。 So it gets a lot more complicated。 as
    we'll see later in the lecture。 So that's the tradeoff between these two。 But
    again。 there's the issue where we've misses， it causes to replace a block that's
    dirty。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 还是说我可能会加入一些我经常用到的内容？所以我想做些复杂的事情，重新安排一下时间表。这样就变得更加复杂了。正如我们稍后在讲座中看到的那样。所以这是这两者之间的权衡。但同样的问题是，我们错过了，这导致我们不得不替换掉一些脏数据块。
- en: which means you then have to do a write back on that block。 Questions。 Okay。
    so administrative stuff。 So I have office hours on Tuesdays and on Thursdays。
    And I've been seeing people in the office hours。 More people can come by。 Project
    two design doc is due tomorrow。 Friday， the 11th。 And hard to believe it。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你得在那个数据块上执行写回操作。问题？好吧，一些行政事务。我的办公时间是周二和周四。我已经在办公时间接待了很多人，更多的人可以来找我。第二个项目的设计文档截止日期是明天，星期五，11号。真不敢相信。
- en: but a week from today， we have our second midterm。 And it's going to cover everything
    up until a blue lecture 16。 So Monday。 And the TAs are going to do a new session
    on the 16th of the day before exam details will be posted in the job。 Questions。
    Yeah。 So the question is， is the first midterm in the state。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 但是从今天起一周后，我们将迎来第二次期中考试。考试内容将涵盖直到蓝色第16讲为止的所有内容。所以是星期一。而且助教们将在考试前一天的16号进行一个新的复习环节，具体的考试详情将会发布在工作区。问题？是的。问题是，第一个期中考试的内容会包括这些吗？
- en: The answer is sort of sort of。 So， are we going to specifically ask questions
    about things that were on the first midterm。 not directly， but we'll assume you
    have not heard out of your cash。 So。 we're going to have all of the content from
    the term one。 So we may rely on concepts that come from the term。 It's a root。
    When you're studying， you know。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 答案有点模糊。所以，我们会特别问一些关于第一次期中考试的内容吗？不会直接问，但我们假设你没有遗漏你的缓存内容。所以，我们会涵盖所有的第一学期内容。我们可能会依赖学期中的一些概念。这是根本问题。当你在学习时，你知道。
- en: remember that for your folks in policy， don't please， you know。 write the stuff
    from the beginning of the semester。 Okay。 So， we look at all these different tasks。
    What kind of organization would make the most sense given what we need to do here。
    given that it's on the critical path to getting to the cash is on the critical
    path for every single memory operation。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，对于你们这些政策方面的人，请不要写出学期开始时的内容。好的。所以，我们来看这些不同的任务。考虑到我们需要做的事情，什么样的组织方式最有意义呢？考虑到这是到达缓存的关键路径，因为每一个内存操作都在关键路径上。
- en: So， whatever going to pick as an organization， whatever one of the policies
    have to be around a real class。 So， there's a question about would write that
    faster because you go to a memory， and less。 And the answer is yes。 Right back。
    Going， rights are going to mean memory less often right through every single right
    has to make it to the memory one of the case。 Module of the fact that we can buffer。
    Okay， so。 So， we can't be before the path。 Right。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，无论我们选择什么样的组织方式，所有的策略必须围绕一个实际的类展开。所以，关于是否通过减少内存访问来加速写入的问题，答案是肯定的。对吧，回写。写入会意味着更少的内存访问。每次写入都必须到达内存，这也是我们可以缓存的一个因素。好的，所以，我们不能在路径之前做。
- en: And so it's critical that the field will be the translations occur at CPE speeds。
    All right。 the current memory speeds， and we've lost the benefit of having a path。
    Every access to this physically addressed path。 So。 that's going to argue for
    something like direct or something of low associated。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关键是字段的转换必须以CPE速度发生。好的，目前的内存速度，我们已经失去了有路径的好处。每次访问这个物理寻址路径时，都会受到影响。所以，这将支持像直接映射或低关联性这样的方案。
- en: I've been crazy associated with the conflict this way。 But we need a lot more
    comparative logic and muxes and all of this stuff that's going to make that look
    up slow。 But the counterpoint to this is conflicts， conflict misses are really
    expensive。 And so that kind of argues for a fully associated class。 Again。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直在与这种方式的冲突关联。但我们需要更多的比较逻辑和多路选择器，以及所有这些东西，这将使查找变慢。但是与此相对的是，冲突，冲突未命中是非常昂贵的。因此，这种情况支持完全关联的缓存。再一次。
- en: there's this potential issue of flash。 Because it's correct map or because of
    low associated。 So。 if you think about it， like what are we using the lower bit
    to the virtual number of an index。 Well。 that means that the first page of code
    first page and stack first page of heat。 Are all going to collide for the same。
    My instruction fetch。 Gets cash。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个潜在的问题，就是闪存。因为它是正确的映射，或者因为低级别的关联。因此，如果你想想看，我们把低位用于虚拟索引的数字，意味着代码的第一页，堆栈的第一页，热缓存的第一页都会发生冲突。我的指令获取会命中缓存。
- en: And then that instruction is going to read something from memory and store it
    on the stack。 And then I'm going to do the data fetch from the heat。 I flush the
    entry replace the entry for instruction。 And then as soon as I write to the stop。
    I flush the entry for data。 And then I just， you know， rinse and repeat。 And so，
    again。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，指令会从内存中读取某些内容并将其存储到堆栈上。然后，我会从热缓存中获取数据。我刷新条目，替换指令的条目。然后，一旦我写入堆栈，我就会刷新数据条目。然后，我就这样，重复这个过程。因此，再次。
- en: running it through to the speeds of memory， not a patch。 So， my saying said
    I use a whole other。 And then I use a whole other thing。 And then I use a whole
    other thing。 And then I use a whole other thing。 And then I use a whole other
    thing。 And then I use a whole other thing。 And then I use a whole other thing。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将其运行至内存速度，不是补丁。因此，我说过我使用完全不同的东西。然后我使用完全不同的东西。然后我使用完全不同的东西。然后我使用完全不同的东西。然后我使用完全不同的东西。然后我使用完全不同的东西。然后我使用完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then I use a whole other thing。 And then I
    use a whole other thing。 And then I use a whole other thing。 And then I use a
    whole other thing。 And then I use a whole other thing。
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另一个完全不同的东西。
- en: And then I use a whole other thing。 And then I use a whole other thing。 And
    then I use a whole other thing。 And then there's this entry value or any value。
    And then there's some access bits。 Read， write， you know， read only， execute only，
    so on。 And then there's this column， application specific ID。 Remember that？
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我使用了另外的一些东西。接着我又使用了另外的一些东西。然后是这个条目值或任何值。接下来是一些访问位。读取、写入，你知道的，只有读取、只有执行，等等。然后是这个列，应用程序特定ID。记得吗？
- en: I'm going to come back to that in just a moment。 Now when we look at how the
    processor is organized。 So I'm going to do a little bit of 150 architect for a
    moment。 You actually overlap to the lookup with the rest of the pipeline。 So there
    are PLB stages in the pipeline。 So here， when you are instruction fetch。
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我马上就会回到这个问题。现在，当我们看看处理器是如何组织的。我将暂时进行一点150架构方面的讲解。实际上，你会将查找与管道中的其他部分重叠。所以管道中有PLB的几个阶段。所以在这里，当你进行指令获取时。
- en: we have our instruction， for our virtual address。 You do a TLD lookup。 You can
    work that into a physical address。 And then we look at instruction cache in the
    instruction。 We're treating it， begin decoding of it。 And then we start to fetch
    the registers that are associated with that instruction。 Then we do our ALU or
    effective address operations like it's being a load or store。
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有我们的指令和虚拟地址。你进行TLD查找。然后将其转化为物理地址。接着我们查看指令缓存中的指令。我们开始解码它。然后我们开始获取与该指令相关的寄存器。接着我们进行ALU或有效地址操作，类似于进行加载或存储。
- en: We're doing a later store。 Got a new address translation。 And so I'm going to
    have PLB operation and look up in the PLB。 And then we're loading and storing
    data。 And so when it has a cache， I think it will be in the load。 So we're going
    to look at the data cache。 And then we might do right back into the register or
    a write if we're doing a write for a few moments。
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在做后续存储。得到一个新的地址转换。所以我会有PLB操作并在PLB中进行查找。然后我们加载和存储数据。所以当它有缓存时，我认为它会在加载中。因此我们会查看数据缓存。然后我们可能会回写到寄存器中，或者如果我们在做写操作，我们会稍微等待几秒钟。
- en: Now， organization， it's a 64 entry on chip PLB。 Really counter-oracle decision
    that they made at the time is to have a software based PLB。 So what does that
    mean？ That means when we have a PLB miss。 it's going to trap into the operating
    system。 The operating system is the new software to decide which entry to replace。
    Think about that for a moment。 We're talking about operating at the nanoseconds。
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，组织上，它是一个64条目的片上PLB。实际上当时做出的反直觉的决定是使用基于软件的PLB。那么这意味着什么呢？这意味着当我们发生PLB未命中时，它会触发到操作系统。操作系统是新的软件来决定替换哪个条目。想一想这个问题。我们在谈论的是在纳秒级别操作。
- en: And all of a sudden， I'm telling you that if you don't find it。 we're going
    to call out to the operating system， and spend thousands of nanoseconds to try
    and figure out what to do。 How can that work？ Well， it's all because if you think
    about it。 if we miss the PLB on a regular basis， it's really expensive。
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 突然之间，我告诉你，如果你找不到它，我们将调用操作系统，花费数千纳秒来尝试弄清楚该怎么做。这怎么可能运作呢？嗯，这一切都因为如果你想一想，如果我们经常发生PLB未命中，那真的非常昂贵。
- en: And so we want to make the frequent case as frequent as possible。 And so we
    can be a little bit more intelligent in how we replace objects in the translations
    in the PLB。 We're going to drive up our pitway and that's going to make the frequent
    case more frequent。 and that's going to make our effective access problem up low。
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们希望使频繁发生的情况尽可能频繁。因此我们可以在如何替换PLB中的对象时更加智能。我们将提高我们的路径效率，这将使得频繁的情况变得更频繁。这样就能让我们的有效访问问题变得更少。
- en: So that was the argument that the developers had of the chip architect to the
    chip。 but it was really counter-oracle at the time。 The people didn't believe
    I could make the software perform fast enough。 Okay。 So it has this ASID。 Remember
    I mentioned that we're going to come back to that。 This is the application specific
    ID。 Now what it is， is it's a context。
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 所以那是开发人员和芯片架构师之间关于芯片的争论。但当时它确实是反直觉的。人们不相信我能让软件运行得足够快。好的。所以它有这个ASID。记得我提到过我们会回到这个点吗？这是应用程序特定ID。它的作用是，它是一个上下文。
- en: So the operating system concept is one at loads an entry into the PLB。 It's
    saying， hey。 this TOB entry is associated with this process。 Why is that important？
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 所以操作系统的概念是将一个条目加载到PLB中。它在说，嘿，这个TOB条目与这个进程相关。为什么这很重要？
- en: Why do I need to know what process owns a particular PLB entry？ Exactly。 If
    I don't know who owns a particular PLB entry， I'd imagine I didn't have applications
    specific IDs。 What happens at a context？ A changed the address space。 It means
    the virtual。 the physical translations all change。 It means I have to flush my
    PLB。
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我需要知道哪个进程拥有特定的 PLB 条目？没错。如果我不知道哪个进程拥有特定的 PLB 条目，我就想象我没有应用程序特定的 ID。那在上下文中会发生什么？A
    改变了地址空间。这意味着虚拟地址和物理地址的转换都发生了变化。那就意味着我必须刷新我的 PLB。
- en: It means compulsory cold start misses。 It means really bad performance。 So the
    trade-off here is going to take up some more precious space on our processor die。
    The Aggies application specific identified。 But it means that we now don't have
    to necessarily watch the PLB every time the conflict switch to another program。
    Every time the switch process and switch addresses is still be able to have valid
    translations stored in the TOB because any look-ups in the TOB are going to rely
    on that application specific ID。
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着强制冷启动未命中。这意味着性能非常差。所以这里的权衡是，它将占用更多宝贵的处理器空间。应用程序特定的标识符。但这也意味着，我们不必每次切换进程时都监控
    PLB。当进程切换和地址切换时，仍然能够在 TOB 中存储有效的翻译，因为 TOB 中的任何查找都会依赖于应用程序特定的 ID。
- en: You don't have to just match the virtual page number。 You also have to match
    the ASIB in order for it to be a valid translation。 Okay。 All right。 So。 a little
    bit of a 150 regression is the way I showed you the TOB organization。 We have
    the TOB。 then we have the cap。 We look at the TOB and even if we get a hit。
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要仅仅匹配虚拟页号。你还必须匹配 ASIB，才能确保它是有效的翻译。好的。好吧。那么，像我之前展示给你看的 TOB 组织方式的 150 回退就是这样。我们有
    TOB，然后我们有 cap。我们查看 TOB，即使我们得到了命中。
- en: we first have to do that translation before we can actually do anything with
    the memory cap。 There's actually a way where we can overlap looking up in the
    cap with doing the translation look up in the TOB。 And it's going to work like
    this。 Okay。 So you think about our virtual address， right？
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须先完成翻译，才能真正操作内存缓存。其实有一种方法，可以将缓存查找与 TOB 中的翻译查找重叠进行。它会像这样工作。好的。那么，你可以想象我们的虚拟地址，对吧？
- en: You do the TOB look up。 That gives us the physical page number and it gives
    us the offset。 The offset is this lower 10 bits of our address。 In this case。
    we're going to have one fill about pages。 So machine to TOBs and caches do a correct
    that allows them to simultaneously start looking in the cash as we're doing your
    address translation。 And it's going to work because we want to set things up so
    we have perfect overlap between the offset and the index and byte。
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 你做 TOB 查找。这会给我们物理页号，并且给我们偏移量。偏移量是我们地址的低 10 位。在这种情况下，我们将处理关于页面的填充。所以，机器到 TOBs
    和缓存做了一个修正，允许它们在我们进行地址翻译时同时开始查找缓存。而且它会有效，因为我们希望设置好环境，让偏移量、索引和字节之间完美重叠。
- en: Why does this work？ Because on our translation， we have the offset right away。
    We don't change the offset when we're going doing translation。 The offset is within
    a page。 We have those bits available right away， right away。 and we're just waiting
    for the bits that are associated with the TOB， the physical page。 All right。
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这样有效？因为在我们的翻译中，我们立刻就有了偏移量。我们在进行翻译时不会改变偏移量。偏移量是在一个页内。我们立刻就能获取到这些位，立刻。我们只是等待与
    TOB 相关的位，物理页。好的。
- en: so here's how it's going to work。 We're going to take our catch。 It's going
    to be a four kilobyte cap。 Each block is four bytes in size。 Or by size or by
    half。 I'm going to enter using our class。 So we're going to enter the index。 10
    for byte blocks。 How many bits do we need for a byte slot？ So we need 12 bits
    of a lower 12 bits。
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它将如何工作呢？我们将使用缓存，它是一个四千字节的缓存。每个块的大小是四个字节。或者按字节大小，或者按半字节大小。我将使用我们的类来输入。因此，我们将输入索引，10
    个字节块。为了字节槽，我们需要多少位？所以我们需要 12 位的低 12 位。
- en: And then we're going to be our index and our bytes。 So we can simultaneously
    select the particular line that we want， the block。 and then select the byte within
    that block。 And then as soon as the TOB gives us a gauge number。 we can compare。
    And if the TOB matches our tag， here's the byte。 If it doesn't。
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们会得到我们的索引和字节。因此，我们可以同时选择我们想要的特定行，块。然后在该块内选择字节。然后，TOB 一旦给出基准号，我们就可以进行比较。如果
    TOB 和我们的标签匹配，那么就是该字节。如果不匹配。
- en: it's a miss in the cache， you have to go off and do the sets for a moment。 But
    it allows us to overlap that look up in the cache with the actual translation
    steps。 Okay， now。 if we make our cache be eight kilobytes， we don't have perfect
    overlap。 Take 150， 150， 150，000。 and we'll learn how to make that with it。 Okay，
    another option will be if we made our caches be virtually addressed。
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缓存未命中，你必须去做一些额外的设置。但是它允许我们在缓存查找与实际的转换步骤之间进行重叠。好的，现在，如果我们将缓存设置为8KB，我们就无法完全重叠。取150，150，150,000。我们将学会如何处理它。好的，另一个选择是，如果我们让缓存虚拟寻址。
- en: If our caches were virtually addressed， then we could look up directly in the
    cache with our virtual address。 What's the disadvantage of a virtually addressed
    tag？ Exactly。 So every time we did a process switch， we'd have to flush the test。
    or we'd have to add application specific identifiers to cache one。 It would increase
    complexity。
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的缓存是虚拟寻址的，那么我们可以直接通过虚拟地址在缓存中查找。虚拟寻址标签的缺点是什么？没错。所以每次我们进行进程切换时，我们必须清空缓存，或者我们需要为缓存添加特定的应用程序标识符。这会增加复杂性。
- en: And so for both of those reasons， we typically use caches， oh， the third reason
    why they're shared。 I'd imagine we want to share the same physical memory across
    multiple processes。 If they have different virtual addresses for that same physical
    address。 then we could end up even with applications for identifiers with multiple
    copies of the same data in effect to not eligible or a migrate。
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 所以出于这两种原因，我们通常使用缓存，哦，第三个原因是它们是共享的。我想我们希望在多个进程之间共享相同的物理内存。如果它们为相同的物理地址有不同的虚拟地址，那么我们可能会遇到带有多个相同数据副本的应用程序标识符，从而导致无法访问或迁移。
- en: So for all of those reasons， we make our caches typically be physically addressed。
    Okay。 so here's an actual。 So the question is how can we read more than one bite
    in time。 So we can read up to a word， right， our block sizes or word is the word
    side of the machine。 which is what most machines are。 So the most in this case
    we could read the word at a point。 Again。
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 所以出于所有这些原因，我们通常将我们的缓存设为物理寻址的。好的，所以这里是一个实际的例子。那么问题是我们如何一次读取超过一个字节？我们最多可以读取一个字，好的，我们的块大小或字是机器的字大小，这也是大多数机器的配置。所以在这种情况下，我们最多可以读取一个字。再说一次。
- en: if you take 152 or take 250 to see all sorts of different platforms。 organizations
    that have larger block sizes and can deal with larger size classes。
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你乘坐152或250，你将能看到各种不同的平台。那些拥有更大块大小并且能够处理更大尺寸类别的组织。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_19.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_19.png)'
- en: Okay， so here's a modern example of modern x86 processors of Skylake， Cascade
    Lake and so on。 And it's a little hard to see here on the side， but there are
    three。 So there's a TV down here。 which is a data TLC。 There's another TV up here，
    which is an instruction program。 And then there's another TV here that's a shared。
    There's a question here that's each different pass have it on TV。
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这是现代x86处理器的一个现代例子，比如Skylake、Cascade Lake等等。侧面有点难看清，但这里有三个。所以这里有一个TV，它是数据TLC。还有另一个TV在这里，它是指令程序。然后还有一个TV，它是共享的。这里有个问题，每个不同的传递都有它自己的TV吗？
- en: No， so the TVs are separate from the passion。 So this case。 We can have。 For
    example。 a bunch of different。 Passions， so we have L one instruction test L one，
    beta， cash。 and to combine cash instruction data。 And I'll read that that's shared
    across multiple course so the one passes now to cash is those are。 Individual
    course， and then the other thing that will be over here， but you know。
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 不，电视是与激情分开的。所以在这种情况下，我们可以拥有。例如，一堆不同的激情，我们有L1指令缓存L1，beta，缓存。并结合指令数据缓存。我会读取它，这在多个课程之间共享，所以一个传递现在到缓存的是那些。个别课程，然后另一个事情会在这里，但你知道的。
- en: will be shared across multiple courts。
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 将会在多个课程之间共享。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_21.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_21.png)'
- en: Similarly， we can have multiple different TLDs so L one instruction。 and then
    a shared out three or two rather shared。 And， and again。 there's all different
    sizes for these all the kinds of social utility， some weird one。 but a login way
    said， essentially。 And this is all where they looked at and look at lots of different
    workloads。
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以拥有多个不同的TLD，比如L1指令缓存，然后是共享的三或二级缓存。并且，再次强调，所有这些都有不同的大小，适用于各种社会效用，一些是奇怪的，但本质上就是这样。所有这些都是根据他们对各种工作负载的观察来设计的。
- en: And then decided， you know， for the cost of making the chip and the limit on
    the number of this and this is sort of price performance that they're trying to
    get。 What's the right architecture use？ More servers， you know， the class of processor。
    the larger all of the classes are going to be。 The more consumer， you know。 it's
    going into a Chromebook or something expensive in a platform is cash is going
    to be much smaller。
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后决定，您知道，制造芯片的成本和该数量的限制，这就是他们试图实现的价格性能比。使用什么样的架构才是正确的？更多的服务器，您知道，处理器类别。所有类别的处理器都会更大。更多的消费品，您知道，它进入了一个Chromebook或者类似的东西，平台的缓存会更小。
- en: It's all trade off and forms of capacity versus prices versus performance。 Okay。
    So what's going to happen on a concert switch？ Well， again， you know。 if we don't
    have application specific IDs， we just changed what the virtual physical map and
    flow。 So those entries are no longer valid and need to flush them all。
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这完全是容量、价格与性能之间的权衡。好的。那么，在一个切换场景下会发生什么呢？嗯，再次强调，如果我们没有应用特定的ID，我们只改变虚拟物理映射和流。所以这些条目不再有效，需要将它们全部刷新。
- en: And that's going to be expensive because what we do， we context with all the
    time between processes。 not just between the same process。 Alternatively， we put
    in an application specific ID or process ID in the TLD and then we don't have
    to do it。 So most modern architectures， they include some form of process or application
    specific ID。 they get stored in a field that way we don't have to。
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这会非常昂贵，因为我们在进程之间的上下文切换时不断进行操作，不仅仅是同一个进程之间。或者，我们可以在TLD中放入一个应用特定的ID或进程ID，这样我们就不需要做这些操作。所以，大多数现代架构包含某种形式的进程或应用特定的ID，它们存储在一个字段中，这样我们就不需要每次都做这些操作。
- en: What happens if we change the translation tables。 So we move a page from memory
    out to the disk or vice versa。 We bring a page in from the disk into memory。 Well。
    now there's going to be a difference between what that page table on three is
    in the page table and what's in the field。 So then we have to invalidate that
    field， the entry。 That's called to be consistency。 Okay。
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们改变了翻译表，会发生什么呢？我们把一页从内存移到磁盘，或者反过来。从磁盘将一页带入内存。那么，现在页表和字段之间会有差异。所以我们必须使该字段失效，条目失效。这叫做一致性。好的。
- en: With virtual index cash。 You need to flush the caption。 So that's again a reason
    why we do not want to have a work to get passed because every time we come to
    switch。 we have to flush the path。 So let's pull all of this together。 So what
    we saw the word beginning of this lecture was the general we have a virtual address。
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于虚拟索引缓存，您需要刷新缓存。所以，这也是我们不希望有工作被传递的原因，因为每次切换时，我们都需要刷新路径。那么，让我们将这些内容整合起来。我们在本讲的开头看到的是，我们有一个虚拟地址。
- en: We take the offset， copy over to the physical。 Memory management unit uses the
    page table base register to find the root table。 Use our P1 index to index into
    that table to find the physical page frame for our second level。 These are two
    index index into that second level table and get our physical plane of the page
    frame。 We're looking for memory and then the offset gives us the data that we
    want to treat。
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获取偏移量，复制到物理内存中。内存管理单元使用页表基寄存器找到根表。使用我们的P1索引进入该表，找到第二级的物理页框。这两个索引索引到第二级表，并获得我们所需的物理页面框架。我们正在寻找内存，然后偏移量给我们想要处理的数据。
- en: We can replace this translation process with a TV。 All right。 so we now just
    provide this virtual page number into the TV and it gives us back the physical
    page number。 Similarly， we'll actually go to read the data or write the data in
    that location。 We can use a tab。 All right， and so we're going to take our physical
    address divided up into a tag index， byte so up。
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用TV替代这个翻译过程。好吧，所以我们现在只需提供这个虚拟页号到TV，它就会返回给我们物理页号。同样，我们实际要读取数据或写入数据时，也可以使用标签。好的，因此我们将物理地址分成标签索引，字节选择。
- en: using index to select one of these sets。 The tag to map and then the byte select
    to actually so up the data that we're going to achieve。 Okay。 So this combination
    of TV and caching is again allows the operation closer to process or speeds instead
    of operating at normal speeds。
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用索引选择其中一个集合。标签进行映射，然后字节选择实际提取我们要实现的数据。好的。所以，TV和缓存的这种组合再次让操作更接近进程速度，而不是以常规速度运行。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_23.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_23.png)'
- en: All right， so what happens when that virtual physical translation。 The MME walks
    the trees and it generates a page。 Or we just don't have permission to find a
    read the current data area。 This is going to cause a fault or crap。 It's synchronous。
    Interrupts the current instruction causes it to be terminated。 Perhaps this into
    the purpose。 Now。
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么当发生虚拟物理转换时会发生什么？MME 会遍历树结构并生成一个页面。或者我们可能没有权限查找或读取当前的数据区域。这将导致故障或错误。它是同步的。中断当前的指令，导致它被终止。也许这正是目的所在。现在。
- en: in the kind of we run the page fault hammer and you realize that Oh。 this is
    actually something we can see。 So it might be that Oh， ran off the end of the
    stack。 We'll just allocate another step and end off the end of the key。 We'll
    allocate additional data from pages。 Or it could be we did a floor。 And that right。
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们运行页面故障处理程序时，你会意识到哦，这实际上是我们可以看到的内容。所以可能是哦，栈溢出了。我们只需要分配另一个栈并结束在关键点上。我们会分配额外的数据页面。或者可能是我们做了一个地板操作。对吧？
- en: because it's a page marked。 They actually now need to actually copy it and update
    both the parent and child。 Or it could be that that page is out on this。 You can
    use memory as a cash for this。 And you think about this is like kind of flip things
    upside down。 You normally think of， you know。 the software running on top of a
    hardware。 Now it's kind of the other way around the hardware is going to fall
    and then it's going to go after the software。
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它是一个被标记的页面。实际上它们现在需要复制它并更新父页面和子页面。或者可能是那个页面就在这个地方。你可以将内存作为缓存来使用。你会发现这就像是把事情翻过来。你通常会认为，软件是运行在硬件之上的。现在情况有点相反，硬件将会先运行，然后才会去处理软件。
- en: What do I do next？ When the software is going to tell the hardware what to be
    next instead of the other world。 But this notion of demand aging again is really
    powerful。 Like we think about modern programs。 I'm always amazed because every
    time I buy a laptop every time I buy a computer。 I just double the amount of physical
    RAM I put in it。 And yet I always run out of number。
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我该做什么？当软件需要告诉硬件接下来该做什么，而不是其他方式时。但这种需求驱动的概念实际上非常强大。想想现代程序。我总是很惊讶，因为每次我购买一台笔记本电脑，每次我购买一台计算机时，我都会将物理内存的容量翻倍。然而，我总是会用完内存。
- en: Because I'll get bigger。 I hate using help。 It just gets bigger every word。
    Does it do anything different than like this show slides。 I don't know。 I think
    now actually they have this whole mode where it doesn't seem learning and it will
    be automatic。 And it will post you on a presentation。 I don't really need that。
    But it doesn't。 Right。
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它会变得更大。我讨厌使用帮助功能。它变得越来越大。它和像显示幻灯片之类的功能有什么不同吗？我不知道。我现在认为他们其实有一种模式，它看起来不像是学习，而是自动进行。而且它会为你发布一个演示。我真的不需要那个。但它并不执行。对吧？
- en: And so it's a challenge。 Our programs are getting bigger and bigger。 But even
    if we add more memory and you grow the amount of memory per machine。 we want to
    run more things。 We want to do more things with machines。 Right。 But we actually
    look at those programs。 And we spend like 10% of the code。
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是一项挑战。我们的程序变得越来越大。但即使我们增加了更多内存并扩大了每台机器的内存容量。我们也希望运行更多的任务。我们希望在机器上做更多的事情。对吧？但是当我们实际查看这些程序时，我们发现代码的
    10% 是我们投入的。
- en: I'm not using all those options features right now。 Even though the phone is
    loaded on running on my machine。 So we really don't need to keep all of that in
    memory。 At the PowerPoint binary， probably like。 you know， a big about don't need
    to use up a big about my process memory。
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我现在并没有使用所有那些选项和功能。尽管手机已经加载并在我的机器上运行。所以我们其实并不需要把所有内容都保留在内存中。在 PowerPoint 的二进制文件中，可能是像你知道的那样，大部分都不需要占用大量的进程内存。
- en: And we think about like what is actually running and we're going to program。
    It's much smaller。 And that's what we want to make sure we keep in memory。 So
    we're going to use memory as a task for this。 Right。 Because memory is expensive
    and small。 And it's the same thing I was doing with my Instagram and my on chip
    caches。
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们思考到底是什么在运行时，我们要编写的程序是更小的。这才是我们要确保保留在内存中的部分。所以我们会把内存作为任务来使用。对吧？因为内存是昂贵且有限的。这就像我在使用
    Instagram 和芯片上的缓存时一样。
- en: We only keep the things in the cash that are being actively used for anything
    else。 Yeah。 Yeah。 So the question is that the difference between software hardware
    paid for home。 And the time we don't want to implement everything in software。
    So the hardware people occurs because memory management unit encounters some error。
    Like。
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只保留那些正在被积极使用的缓存中的内容，其他的就不保留了。是的。是的。所以问题在于软件和硬件之间的区别。我们不希望所有的东西都在软件中实现。因此，当内存管理单元遇到一些错误时，硬件人员会发生错误。例如。
- en: there's all these little checks that does run off the end of the table。 And
    so， you know。 the segment valid or the entry valid is the access match the permissions，
    you know。 the request or permission level match， the current， the permission level
    on the PPE。 is because of fault denhering。 Now you could try to， as a hardware
    developer architect， figure out。
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多小检查会从表的末尾运行。所以你知道，段有效或条目有效，访问权限是否匹配，权限级别是否匹配，当前权限级别是否与PPE上的匹配，都是由于错误处理的原因。现在，作为硬件开发者，你可以尝试去弄清楚。
- en: what are all the possible faults， that can happen and how should I handle all
    of those？
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可能发生的故障有哪些，我应该如何处理这些故障？
- en: And now I greatly can strain what my operating system can do。 So what we see
    is when the hardware impounder， of the situation like that， it throws up its hands。
    This is why I have no idea what to do。 Operating systems， you tell me what to
    do。 That's actually really good to do now， as an operating system developer。
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我可以大大地扩展我的操作系统能做的事情。所以我们看到的是，当硬件受限时，像这种情况，它会束手无策。这就是为什么我不知道该怎么做。操作系统，你告诉我该怎么做。这实际上是现在作为一个操作系统开发者要做的事情。
- en: I can decide what's the best way for me to handle this， and how I handle it
    might be different。 If I'm building a server， I'm going， to handle it differently
    than if I'm。 building a laptop for interactive use。 Mostly what I'm running is
    lots of big batch jobs。 That's different。 If I'm building a database engine。
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以决定最适合我处理的方式，而且我处理的方式可能会不同。如果我在构建服务器，我会用不同的方式处理它，而不是在构建用于交互式使用的笔记本电脑时。大多数情况下，我运行的是大量的大批量任务。这是不同的。如果我在构建数据库引擎。
- en: I might implement it differently from how I implement。 page fault handling on
    a network file of appliance。 So by doing things in software。 we get a lot more
    control， when we get in hardware。 OK， so we are just about out of time。 What I
    want to leave you with is one more slide。 So if you think about how page fault
    flow。
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我可能会和我在网络文件设备上实现页面错误处理的方式不同。所以通过软件实现，我们可以获得更多的控制，而不是在硬件上实现。好了，我们快没时间了。我想给你留下最后一张幻灯片。所以如果你想想页面错误的流程。
- en: In the normal case， generate an instruction， go to a memory management unit，
    define the page。 in the page table， and the operation， will conclude as intended，
    read， write， instruction fetch。 But we can also have the case where the memory
    management unit。 walks through the page table where it looks， because it has a
    cache in the tool B。
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常情况下，生成一条指令，访问内存管理单元，定义页面。在页面表中，操作将按预期完成，读、写、指令取回。但我们也可以遇到内存管理单元遍历页面表的情况，因为它在工具B中有缓存。
- en: and we find it's not in the page table。 We generate the page fault。 And so in
    that case。 the operating system now takes over。 Once the page fault handler figures
    our own things out。 on disk， pulls it into memory， updates the page table， entry，
    reschedules。 so puts it back on the ready field， that read， now we can retry it，
    and the operation will succeed。
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们发现它不在页面表中，我们就会生成页面错误。所以在这种情况下，操作系统接管了。一旦页面错误处理程序搞定一切，读取磁盘，把它载入内存，更新页面表条目，重新调度，将它放回准备队列，然后我们就可以重试了，操作将成功。
- en: And so what we're going to talk about next time， is exactly how that page fault
    handler works。 OK。 thank you。 [INAUDIBLE]， (tense music)。
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 所以下次我们要讨论的内容，正是这个页面错误处理程序是如何工作的。好的，谢谢。[无法听清]，（紧张的音乐）。
- en: '![](img/7eec25f2340e3828def04fe91e3bbaa9_25.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eec25f2340e3828def04fe91e3bbaa9_25.png)'
- en: you。
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你。
