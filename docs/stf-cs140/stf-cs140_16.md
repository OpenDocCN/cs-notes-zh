# 虚拟内存

CS 140 课程讲义

2014 年春季

约翰·奥斯特豪特

+   本主题的阅读材料来自*操作系统：原理与实践*：第八章。

+   如何使一个内存被多个并发进程共享？

+   单任务（无共享）：

    +   最高内存保存操作系统。

    +   进程从 0 开始分配内存，直到操作系统区域。

    +   例如：早期批处理监视器只能一次运行一个作业。它可能会破坏操作系统，操作员会重新启动操作系统。一些早期个人计算机类似。

+   共享内存的目标：

    +   多任务：允许多个进程同时驻留在内存中。

    +   透明性：没有进程应该意识到内存是共享的事实。每个进程必须运行，无论进程的数量和/或位置如何。

    +   隔离：进程不能相互破坏。

    +   效率（CPU 和内存）不应该因共享而严重降低。

+   加载时重定位：

    +   最高内存保存操作系统。

    +   第一个进程加载在 0 处；其他进程填充空白空间。

    +   当加载一个进程时，重新定位它，使其能够在其分配的内存区域中运行，类似于链接：

        +   链接器在可执行文件中输出重定位记录

        +   类似于目标文件中的信息：指示哪些位置包含内存地址

        +   操作系统在加载进程时会修改地址（添加基地址）

    +   这种方法存在哪些问题？

## 动态内存重定位

+   在加载程序时静态重定位程序时，添加硬件（*内存管理单元*）在每次内存引用时��态更改地址。

+   每个进程生成的地址（称为*虚拟地址*）在硬件中被转换为*物理*地址。这在每次内存引用时发生。

+   导致内存的两种视图，称为*地址空间*：

    +   虚拟地址空间是程序看到的内容

    +   物理地址空间是内存的实际分配

## 基址和绑定重定位

+   两个硬件寄存器：

    +   基址：对应于虚拟地址 0 的物理地址。

    +   绑定：最高允许的虚拟地址。

+   每次内存引用时，虚拟地址与绑定寄存器进行比较，然后加上基址寄存器以生成物理地址。绑定违规会导致操作系统陷入陷阱。

+   每个进程似乎有一个完全私有的内存，其大小由绑定寄存器确定。

+   进程彼此之间和操作系统之间隔离。

+   加载进程时不需要进行地址重定位。

+   每个进程都有自己的基址和绑定值，这些值保存在进程控制块中。

+   操作系统在关闭重定位的情况下运行，因此可以访问所有内存（处理器状态字中的一个位控制重定位）。

    +   必须防止用户关闭重定位或修改基址和绑定寄存器（PSW 中的另一个位用于用户/内核模式）。

+   问题：操作系统一旦放弃控制权，如何重新获得控制权？

+   基址和绑定是便宜的（只有 2 个硬件寄存器）和快速的：加法和比较可以并行进行。

+   基址和绑定重定位有什么问题？

## 多个段

+   每个进程分布在几个可变大小的内存区域中，称为段。

    +   例如，一个段用于代码，一个段用于堆，一个段用于栈。

+   *段表*保存进程的所有段的基址和限制，以及每个段的保护位：读写对比只读。

+   内存映射过程包括表查找+添加+比较。

+   每个内存引用必须指示一个*段号*和*偏移量*：

    +   地址的高位选择段，低位选择偏移量。

    +   例如：PDP-10 使用高阶地址位选择高段和低段。

    +   或者，段可以由指令隐式选择（例如代码与数据，堆栈与数据，或 8086 前缀）。

+   分段的优点：灵活性

    +   分别管理每个段：

        +   可以独立地增长和缩小

        +   交换到磁盘

    +   可以在进程之间共享段（例如，共享代码）。

    +   可以将段移动到紧凑的存储器并消除碎片。

+   分段存在哪些问题？

## 分页

+   将虚拟内存和物理内存划分为称为*页面*的固定大小块。最常见的大小是 4 K 字节。

+   对于每个进程，*页表*定义了该进程每个页面的基址，以及只读和“存在”位。

+   页表存储在连续的内存中（硬件中的基址寄存器）。

+   翻译过程：页面号始终直接来自地址。由于页面大小是 2 的幂，不需要比较或添加。只需进行表查找和位替换。

+   易于分配：保持一个可用页面的空闲列表并获取第一个。易于交换，因为一切都是相同大小，通常与磁盘块大小相同。

+   问题：对于现代计算机，页表可能非常庞大：

    +   考虑 x86-64 寻址架构：64 位地址，4096 字节页面。

    +   理想情况下，每个页表应该适合一页。

    +   大多数进程很小，因此大多数页表条目未使用。

    +   即使是大型进程也会稀疏地使用它们的地址空间（例如，代码在底部，堆栈在顶部）

+   解决方案：多级页表。Intel x86-64 寻址架构：

    +   64 位虚拟地址，但实际上只使用了低 48 位。

    +   4 K 字节页面：虚拟地址的低 12 位保存页面内的偏移量。

    +   4 级页表，每个索引使用 9 位虚拟地址。

    +   每个页表适合一个页面（页表条目为 8 字节）。

    +   可以省略空页表。

+   下一个问题：页表太大，无法加载到重定位单元中的快速存储器中。

    +   页表保留在主存储器中

    +   重定位单元保存顶级页表的基址

    +   使用 x86-64 架构，必须进行 4 次内存引用才能翻译虚拟地址！

## 翻译后备缓冲区（TLB）

+   解决页面翻译开销的方案：创建一个最近翻译的小型硬件高速缓存。

    +   每个缓存条目存储虚拟地址的页号部分（对于 x86-64 为 36 位）和相应的物理页号（对于 x86-64 为 40 位）。

    +   典型 TLB 大小：64-2048 条目。

    +   在每次内存引用时，将虚拟地址中的页面号与每个 TLB 条目中的虚拟页号进行比较（并行进行）。

    +   如果有匹配的话，使用相应的物理页码。

    +   如果没有匹配，则执行完整的地址转换，并将信息保存在 TLB 中（替换现有条目中的一个）。

    +   TLB 的“命中率”通常为 95%或更高。

+   TLB 的复杂性：

    +   在上下文切换时，必须使 TLB 中的所有条目无效（映射将对下一个进程不同）。当页表基址寄存器被更改时，芯片硬件会自动执行此操作。

    +   如果当前进程的虚拟内存映射发生变化（例如，页面移动），必须使一些 TLB 条目无效。为此有特殊的硬件指令。

## 杂项主题

+   操作系统如何从用户内存中获取信息？例如 I/O 缓冲区、参数块。请注意，用户向操作系统传递的是*虚拟地址*。

    +   在一些系统中，操作系统只是无映射地运行。

        +   在这种情况下，它会读取页面表，并在软件中转换用户地址。

        +   在虚拟地址空间中连续的地址在物理上可能不是连续的。因此，I/O 操作可能需要被拆分为多个块。

    +   大多数较新的系统将内核和用户内存包含在同一虚拟地址空间中（但内核内存在用户模式下不可访问）。这让内核的生活变得更加容易，尽管它并没有解决 I/O 问题。

+   分页的另一个问题是：*内部碎片*。

    +   无法分配部分页面，因此对于小块信息，只有页面的一部分会被使用。

    +   结果：一些页面两端会有浪费的空间。

    +   在今天的系统中并不是一个大问题：

        +   对象（如代码或堆栈）往往比页面大得多。

        +   由于碎片化造成的浪费空间百分比很小。

    +   如果页面大小增长会发生什么？
