![](img/a5823530e230b7c3ee90fda214e7fefe_1.png)

# 课程 P22：第 23 讲 - RCU 🧠

## 概述

在本节课中，我们将学习如何为多核硬件上的共享数据获取良好性能，特别是针对那些**读取远多于写入**的数据。我们将重点探讨 Linux 内核中一种非常成功的技术——**RCU**。我们将了解其工作原理、适用场景以及它如何通过避免读者端的锁和写操作来显著提升性能。

---

## 多核性能与共享数据

上一节我们介绍了多核性能的挑战。现代计算机拥有多个核心并行运行并共享内存，内核本身就是一个并行程序。为了获得高性能，我们需要确保内核的许多工作能在不同核心上尽可能并行执行。

如果系统上有许多进程在运行，并且它们都在进行系统调用，很多时候，不同进程的系统调用看起来是独立的，应该能够互不干扰地并行执行。然而，问题在于内核为了管理资源（如内存、CPU、磁盘缓存等），共享了许多数据结构。这意味着即使两个进程的系统调用互不相关，如果它们都使用了内核中的相同数据结构，我们也需要一种机制来确保它们能安全地并发使用这些数据。

---

## 传统锁的局限性

我们之前学习过一种保证正确性的机制——自旋锁。自旋锁虽然易于推理，但其作用是防止并行执行，从而会降低性能。自旋锁直接减少了并行性，这在追求高性能的场景下并不总是理想的。

因此，我们将聚焦于**读取密集型数据**的情况，即数据大部分时间被读取，相对较少被写入。我们将以一个简单的**单向链表**作为主要示例。

### 示例：受保护的链表

假设我们有一个全局头指针指向一个链表，每个链表元素包含一些数据（例如一个字符串）和一个指向下一个元素的指针。我们假设对这个链表的大多数操作是**读取**（例如扫描链表查找内容），但偶尔也会有**写入**操作（例如修改元素数据、插入或删除元素）。

在 XV6 这样的简单系统中，我们可能会用一个锁来保护整个链表。这意味着不仅写入者需要获取锁，**读取者也需要获取锁**，以防止在读取过程中链表被修改。这种方法的缺陷在于，即使没有写入者，每次读取操作也需要获取锁，这阻止了多个读取者并行执行，从而无法充分利用多核优势。

---

## 读写锁：一种改进方案

为了改进上述情况，一种思路是使用一种新类型的锁，它允许多个读取者，但只允许一个写入者。这就是**读写锁**。

以下是读写锁的接口：
*   读取者调用 `r_lock()` 和 `r_unlock()`。
*   写入者调用 `w_lock()` 和 `w_unlock()`。

其语义是：可以同时有多个读取者持有锁，或者恰好有一个写入者持有锁，但**不能同时有读取者和写入者**。这看起来是读取密集型数据结构的理想解决方案。

### 读写锁的实现与性能问题

然而，如果我们深入研究读写锁的实现细节，尤其是在数据被频繁读取时，会发现一些问题。Linux 内核中读写锁的一个简化实现使用了一个计数器 `n`：
*   `n = 0`：锁未被任何线程持有。
*   `n = -1`：锁被一个写入者持有。
*   `n > 0`：锁被 `n` 个读取者持有。

`r_lock` 函数的核心是一个循环，它使用 **`compare-and-swap`** 原子指令来安全地增加计数器。`compare-and-swap` 指令的语义如下：
```c
// 伪代码：如果 *ptr 的值等于 expected，则将其设置为 new，并返回1；否则返回0。
int compare_and_swap(int *ptr, int expected, int new) {
    if (*ptr == expected) {
        *ptr = new;
        return 1;
    } else {
        return 0;
    }
}
```

![](img/a5823530e230b7c3ee90fda214e7fefe_3.png)

尽管读写锁允许多个读取者，但其性能在多核系统上可能很差。原因在于，每个核心都有自己的缓存。当多个核心同时尝试获取读锁时，它们都需要读取并可能修改共享的锁变量 `n`。这会导致大量的**缓存一致性**通信（例如缓存行失效消息）。具体来说，如果有 N 个核心同时竞争读锁，总的消息开销或时间成本可能达到 **O(N²)** 级别。

**关键问题在于**：读写锁将原本可以是**只读**的、快速缓存访问的操作，转变成了涉及**写入**共享数据的昂贵操作。任何对可能被其他核心缓存的数据的写入，都需要核心间的通信，这在高并发读取时会成为性能瓶颈。

---

## RCU 的核心思想

正是读写锁的性能问题催生了 **RCU**。RCU 的目标是允许读取者完全**无锁**且**无写**地访问数据。它通过让写入者遵循一些更复杂的规则，来换取读取者的极致性能。

我们将针对之前提到的“读者无锁读取时可能遇到的三种危险情况”来阐述 RCU 的解决方案。

### 思想一：通过副本更新（Read-Copy-Update）

**问题**：写入者直接修改链表元素的内容，导致读者可能看到部分更新的数据。

**解决方案**：禁止写入者就地修改数据。相反，写入者必须分配一个**全新的元素副本**，完全初始化这个新副本（包括数据和指针），然后通过一个**原子的“提交写”操作**，将前一个元素的 `next` 指针从指向旧元素改为指向新元素。

由于这个“提交写”是原子的（在常见硬件上，对齐的指针写入是原子的），读者在读取指针时，要么看到旧版本，要么看到完整初始化的新版本，绝不会看到处于中间状态的错误数据。

这个技术适用于可以通过单个原子写操作来“提交”更新的数据结构，如链表和树。

---

### 思想二：使用内存屏障

**问题**：编译器和处理器可能会对内存操作进行重排序。例如，写入者可能在实际初始化新元素内容之前，就执行了提交指针的写操作；或者读者可能在获取指针之前，就尝试读取指针指向的内容。

**解决方案**：**写入者**必须在提交写操作之前插入一个**写内存屏障**，确保所有对新元素的初始化写操作都在提交指针之前完成。
**读取者**必须在获取受保护指针之后、解引用该指针之前插入一个**读内存屏障**，确保获取指针的操作先于后续的读数据操作。

这保证了读者看到的指针所指向的数据是完整的。

---

### 思想三：延迟释放（垃圾回收思想）

**问题**：写入者提交了新元素后，旧元素需要被释放。但可能仍有读者在旧指针被替换前就获取了它，并正在访问旧元素。我们不能立即释放它。

**解决方案**：RCU 引入了一个**宽限期**的概念。规则如下：
1.  **读者规则**：读者在 RCU 临界区（即持有指向 RCU 保护数据的指针时）**不得发生上下文切换**（即不能休眠）。
2.  **写入者规则**：写入者在释放旧数据之前，必须等待一个宽限期，确保**所有可能持有旧数据指针的核心都至少进行了一次上下文切换**。

由于读者在临界区内不会休眠，那么在宽限期（所有核心都发生一次上下文切换）结束后，就可以确保没有任何读者仍持有旧数据的指针。此时，写入者安全地释放旧内存。

写入者可以通过调用 `synchronize_rcu()` 来同步等待宽限期结束，或者使用 `call_rcu()` 异步注册一个回调函数，在宽限期结束后执行释放操作。

---

## RCU 使用示例

以下是使用 RCU 读取和更新链表的简化代码示例：

### 读取者代码
```c
rcu_read_lock(); // 进入RCU读临界区，主要作用是禁止上下文切换
list_for_each_entry_rcu(e, &head, list) {
    // rcu_dereference() 封装了读内存屏障
    data = rcu_dereference(e->data);
    // ... 使用 data ...
}
rcu_read_unlock(); // 退出RCU读临界区
```
读取者的开销极小：`rcu_read_lock/unlock` 几乎不做任何工作（主要是防止上下文切换），`rcu_dereference` 包含一个内存屏障。

### 写入者代码（替换第一个元素）
```c
spin_lock(&list_lock); // 写入者之间仍需用锁互斥
old_e = head;
new_e = kmalloc(sizeof(*new_e)); // 分配新元素
new_e->data = new_data;          // 初始化新元素
new_e->next = old_e->next;
// 写内存屏障 + 提交写
rcu_assign_pointer(head, new_e);
spin_unlock(&list_lock);

synchronize_rcu(); // 等待宽限期结束
kfree(old_e);      // 安全释放旧元素
```
写入者的开销较大：需要锁、分配内存、内存屏障，以及可能耗时的 `synchronize_rcu()` 调用。

---

## RCU 的优缺点与适用场景

### 优点
*   **读者性能极高**：几乎零开销，可真正并行。
*   特别适合**读取占绝对主导**、写入极少的工作负载。

### 缺点与限制
*   **写入者开销大**：写入操作更复杂、更慢。
*   **读者限制**：不能在 RCU 临界区内休眠或长时间持有指针。
*   **数据结构限制**：最适合能通过单次原子写操作更新的数据结构（如链表、树）。
*   **可能读到旧数据**：读者在宽限期前可能继续访问已被逻辑上“替换”的旧数据副本。

### 适用场景
RCU 在 Linux 内核中取得了巨大成功，广泛应用于许多读取密集型的数据结构，例如：
*   目录项缓存
*   文件系统对象缓存
*   网络路由表
*   模块引用计数

其核心魔力在于，它通过一种**专门的垃圾收集机制**（宽限期），完全消除了读者端的锁和写操作。

---

## 其他并发性能技术

RCU 主要解决读取密集型数据的问题。对于**写入密集型数据**，也有其他技术：
*   **数据分片**：将共享数据结构拆分为每个核心的私有部分（如每核心空闲链表、每核心统计计数器）。这样写入大多发生在本地，冲突减少。读取时需要聚合所有部分，因此将开销转移到了读取端。
*   **序列锁**：允许读者与写入者并发，但读者需要检查在读取期间数据是否被修改，如果被修改则重试。

选择哪种技术取决于具体的工作负载特征。

---

## 总结

本节课我们一起学习了 **RCU** 这一用于提升多核系统上读取密集型共享数据性能的关键技术。我们分析了传统锁和读写锁的局限性，深入探讨了 RCU 的三个核心思想：
1.  **读-复制-更新**：通过创建副本来避免就地修改。
2.  **内存屏障**：确保内存操作的顺序一致性。
3.  **延迟释放与宽限期**：安全地回收不再被任何读者使用的旧数据。

RCU 的精妙之处在于，它通过让写入者承担更多责任，换取了读者端的极致性能，是一种非常成功的、以读者为中心的并发控制方案。理解 RCU 有助于我们设计出更能充分利用现代多核硬件能力的高性能系统。