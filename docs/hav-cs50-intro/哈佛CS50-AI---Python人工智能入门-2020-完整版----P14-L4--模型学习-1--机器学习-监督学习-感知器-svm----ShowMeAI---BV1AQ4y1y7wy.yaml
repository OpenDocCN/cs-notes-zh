- en: 哈佛CS50-AI ｜ Python人工智能入门(2020·完整版) - P14：L4- 模型学习 1 (机器学习，监督学习，感知器，svm) - ShowMeAI
    - BV1AQ4y1y7wy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哈佛CS50-AI ｜ Python人工智能入门(2020·完整版) - P14：L4- 模型学习 1 (机器学习，监督学习，感知器，svm) - ShowMeAI
    - BV1AQ4y1y7wy
- en: '![](img/d1fa64ba22d78e5e958d31065456ad72_0.png)'
  id: totrans-1
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1fa64ba22d78e5e958d31065456ad72_0.png)'
- en: '[Music]，all right welcome back everyone to an，introduction to artificial intelligence。with
    Python now so far in this class，we''ve used AI to solve a number of。different
    problems giving me a，instructions for how to search for a。solution or how to satisfy
    certain，constraints in order to find its way。'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[音乐]，欢迎大家回到Python人工智能入门课程，到目前为止，我们已经利用AI解决了许多不同的问题，给出了如何寻找解决方案或如何满足某些约束条件的指示。'
- en: from some input point to some output，point in order to solve some sort of。problem
    today we're going to turn to the，world of learning in particular the idea。of machine
    learning which generally，refers to the idea where we are not。going to give the
    computer explicit，instructions for how to perform a task。
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从某个输入点到某个输出点，以解决某种问题，今天我们将转向学习的世界，特别是机器学习的概念，它通常指的是我们不打算给计算机明确的执行任务的指示。
- en: but rather we are going to give the，computer access to information in the。form
    of data or patterns that it can，learn from and let the computer try and。figure
    out what those patterns are try，and understand that data to be able to。perform
    a task on its own machine，learning comes in a number of different。
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们并不是给计算机提供关于如何执行任务的明确指示，而是让计算机访问以数据或模式的形式存在的信息，让它尝试找出这些模式，理解这些数据，以便能够独立执行任务，机器学习有许多不同的形式。
- en: forms and it's a very wide field so，today we'll explore some of the。foundational
    algorithms and ideas that，are behind a lot of the different areas。within machine
    learning and one of the，most popular is the idea of supervised。machine learning
    or just supervised，learning and supervised learning is a。
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这个领域非常广泛，今天我们将深入探讨一些基础算法和概念，这些概念在机器学习的不同领域中都起着重要作用，而其中一个最受欢迎的想法是监督学习。
- en: particular type of task it refers to the，task where we give the computer access。to
    a data set where that data set，consists of input/output pairs and what。we would
    like the computer to do is we，would like our AI to be able to figure。out some
    function that map's inputs to，outputs so we have a whole bunch of data。
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特定类型的任务是指，我们让计算机访问一个数据集，该数据集由输入/输出对组成，而我们希望计算机能够找出一些将输入映射到输出的函数，因此我们有一整套数据。
- en: that generally consists of some kind of，inputs some evidence some information。the
    computer will have access to and we，would like the computer based on that。input
    information to predict what some，output is going to be and we'll give it。some
    data so that the computer can train，its model on to begin to understand how。
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常由某种输入、证据或信息组成，计算机将能够访问这些信息，我们希望计算机根据这些输入信息预测某个输出将会是什么，我们将提供一些数据，以便计算机能够训练其模型，开始理解。
- en: it is this information works and how it，is that the inputs and outputs relate
    to。each other but ultimately we hope that，our computer will be able to figure
    out。some function that given those inputs is，able to get those outputs there are
    a。couple of different tasks within，supervised learning the one we'll focus。
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息是如何工作的，输入和输出之间是如何关联的，但最终我们希望我们的计算机能够找出一个函数，给定这些输入，能够得到这些输出，在监督学习中有几种不同的任务，我们将重点关注其中之一。
- en: on and start with is known as，classification and classification is the。problem
    where if I give you a whole，bunch of inputs you need to figure out。some way to
    map those inputs into，discrete categories where you can decide。what those categories
    are and it's the，job of the computer to predict what。
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先讨论的是分类，分类问题是，如果我给你一堆输入，你需要找出将这些输入映射到离散类别的方法，而你可以决定这些类别是什么，计算机的工作是预测。
- en: those categories are going to be so that，might be for example I give you。information
    about a banknote like a US，dollar and I'm asking you to predict for，me doesn't
    blow。to the category of authentic banknotes，or does it belong to the category
    of。counterfeit banknotes you need to，categorize the input and we want to。
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类别将如何定义，例如，我给你关于某张钞票的信息，比如一美元钞票，我在询问你预测它是否属于真实钞票的类别，还是属于假钞的类别，你需要对输入进行分类。
- en: train the computer to figure out some，function to be able to do that。calculation
    another example might be the，case of whether something we've talked。about a little
    bit so far in this class，where we would like to predict on a。given day you know
    is it gonna rain on，that day and is it going to be cloudy on。
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 训练计算机来找出一些函数来进行这个计算，另一个例子可能是我们在这门课上稍微提到的情况，我们想预测在某一天，知道那一天是否会下雨，以及是否会多云。
- en: that day and before we've seen how we，could do this if we really give the。computer
    all the exact probabilities for，you know if these are the conditions。what's the
    probability of rain，oftentimes we don't have access to that。information though
    but what we do have，access to is a whole bunch of data so if。
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那一天，之前我们看到如果我们真的给计算机所有的确切概率，比如如果这些是条件，降雨的概率是什么，但通常我们没有访问到那些信息，不过我们确实拥有大量数据，所以如果。
- en: we wanted to be able to predict，something like is it going to rain or is。it
    not going to rain we would give the，computer historical information about。days
    when it was raining and days when，it was not raining and ask the computer。to look
    for patterns in that data so，what might that data look like well we。
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够预测一些事情，比如会不会下雨，我们会给计算机提供关于下雨和不下雨的历史信息，并让计算机寻找这些数据中的模式。那么这些数据可能是什么样的呢？我们。
- en: could structure that data in a table，like this this might be what our table。looks
    like we are for any particular day，going back，we have information about like that
    days。humidity that days air pressure and then，importantly we have a label something
    or。the human has said that on this，particular day it was raining or it was。
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像这样将数据结构化到一个表格中，这可能是我们表格的样子。对于任何特定的日子，我们有关于那天的湿度、空气压力的信息，重要的是我们有一个标签，某个人曾说过在这一天是下雨的或者是。
- en: not raining so you could fill in this，table with a whole bunch of data and。what
    makes this what we would call a，supervised learning exercise is that a。human has
    gone in and labeled each of，these data points said that on this day。when these
    were the values for the，humidity and pressure that day was a。
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 不下雨，所以你可以用很多数据填充这个表格，而这之所以被称为监督学习的练习，是因为有人为每一个数据点标注了标签，说明在湿度和气压为这些值的那天是一个。
- en: rainy day and this day was a not rainy，day and what we would like the computer。to
    be able to do then is to be able to，figure out given these inputs given like。the
    humidity and the pressure can the，computer predict what label should be。associated
    with that day does that day，look more like it's going to be a day。
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下雨的日子和这一天是一个不下雨的日子，我们希望计算机能够根据这些输入，比如湿度和气压，来预测应该与那一天关联的标签。那一天看起来更像是会是一个。
- en: that rains or does it look more like a，day when it's not going to rain put a。little
    bit more mathematically you can，think of this as a function that takes。two inputs
    the inputs being the data，points that our computer will have。access to things
    like humidity and，pressure so we could write a function f。
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着会下雨，或者看起来更像是一个不会下雨的日子。从数学上讲，可以把这看作是一个接受两个输入的函数，这些输入是我们计算机可以获取的数据点，比如湿度和气压，因此我们可以写一个函数
    f。
- en: that takes as input both humidity and，pressure and then the output is going
    to。be what category we would ascribe to，these particular input points what label。we
    would associate with that input so，we've seen a couple of example data。points
    here we're given this value for，humidity and this value for pressure we。
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 它以湿度和气压作为输入，输出将是我们为这些特定输入点所归类的类别，即我们会将什么标签与该输入关联。因此，我们在这里看到了一些示例数据点，给出了这个湿度值和这个气压值。
- en: predict is it going to rain or is it not，going to rain and，information that
    we just gathered from。the world we measured on various，different days what the
    humidity and。pressure were we observed whether or not，we saw rain or no rain on
    that。particular day and this function f is，what we would like to approximate now。
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 预测是会下雨还是不会下雨，我们从世界上刚收集的信息，在不同的日子里测量湿度和气压，观察在特定那天是否下雨，这个函数 f 是我们希望近似的现在。
- en: the computer and we humans don't really，know exactly how this function f works。it's
    probably quite a complex function，so what we're going to do instead is。attempt
    to estimate it we would like to，come up with a hypothesis function H。which is
    going to try to approximate，what F does we want to come up with some。
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机和我们人类并不确切知道这个函数f是如何工作的，它可能是一个相当复杂的函数，因此我们将尝试估计它。我们希望提出一个假设函数H，试图近似f的功能，我们想要提出一些。
- en: function H that will also take the same，inputs and will also produce an output。rain
    or no rain and ideally we'd like，these two functions to agree and as much。as possible
    so the goal then of the，supervised learning classification tasks。is going to be
    to figure out what does，that function H look like how can we。
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 函数H也会接受相同的输入，并产生一个输出：有雨或没有雨，理想情况下，我们希望这两个函数尽可能一致，因此监督学习分类任务的目标是弄清楚函数H是什么样的，我们该如何。
- en: begin to estimate given all of this，information all of this data what。category
    are what label should be，assigned to a particular data point so。where could you
    begin doing this well a，reasonable thing to do especially in。this situation I
    have two numerical，values is I could try to plot this on。
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何开始做这件事呢？在这种情况下，我有两个数值，合理的做法是尝试将其绘制在图上。
- en: like a on a graph that has two axes an x，axis and the y axis and in this case。we're
    just going to be using two，numerical values as input but these same。types of ideas
    scale as you add more and，more inputs as well we'll be plotting。things in two
    dimensions but as we soon，see you could add more inputs and just。
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个有两个轴的图表上，x轴和y轴，在这种情况下，我们将使用两个数值作为输入，但这些相同的想法在增加更多输入时也同样适用，我们将在二维中绘制事物，但如我们所见，可以添加更多输入。
- en: imagine things in multiple dimensions，and while we humans have trouble。conceptualizing
    anything really beyond，three dimensions at least visually a。computer has no problem
    with trying to，imagine things in many many more。dimensions that for a computer
    each，dimension is just some separate number。
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 想象事物在多个维度中，而我们人类在视觉上至少在三维之外的概念化方面存在困难，但计算机在尝试想象许多更多维度时没有问题，对计算机来说，每个维度只是一个独立的数字。
- en: that it is keeping track of so it，wouldn't be unreasonable for a computer。to
    think in ten dimensions or a hundred，dimensions to be able to try to solve a。problem
    but for now we've got two inputs，so we'll graph things along two axes in。x axis
    which will here representing，humidity and y axis which here。
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机在十维或百维中思考并不是不合理的，这样能够尝试解决问题，但现在我们只有两个输入，因此我们将在x轴上绘制事物，这里代表湿度，y轴在这里。
- en: represents pressure and what we might do，is say let's take all of the days that。were
    raining and just try to plot them，on this graph and see where they fall on。this
    graph and you know here might be，all of the rainy days where each rainy。day with
    one of these blue dots here，that corresponds to a particular value。
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 表示压力，我们可能会说，取所有下雨的天数，尝试在这个图表上绘制它们，看看它们在图表上的位置，你知道这里可能是所有的下雨天，每个下雨天用一个蓝点表示，代表一个特定的值。
- en: for humidity and a particular value for，pressure and then I might do the same。thing
    with the days that were not，raining say take all the not rainy days，figure out
    what。their values were for each of these two，inputs and go ahead and plot them
    on。this graph as well and up here plotted，them in reds the blue here stands for
    a。
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 针对湿度和特定压力值，然后我可能会对不下雨的天做同样的事情，比如取所有不下雨的日子，弄清楚这两个输入的值，并继续在这个图表上绘制它们，上面用红色绘制，而这里的蓝色则代表。
- en: rainy day and red here stands for a not，rainy day and this then is the input。that
    my computer has access to all of，this input and what I would like the。computer
    to be able to do is to train a，model such that if I'm ever presented。with a new
    input that doesn't have a，label associated with it something like。
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 下雨天和红色在这里代表的是一个不下雨的日子，这就是我的计算机能够访问的所有输入。我希望计算机能够训练一个模型，使得如果我遇到一个没有标签的新输入时，能够开始估计基于所有这些信息和数据，应该将什么类别或标签分配给特定的数据点。
- en: this white dot here I would like to，predict given those values for each of。the
    two inputs should we classify it as，a blue dot a rainy day or should we。classify
    it as a red dot and not rainy，day and if you're just looking at this。picture graphically
    trying to say all，right this white dot does it look like。
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的白点，我想预测根据这两个输入的值，我们应该将其分类为蓝点（下雨天），还是将其分类为红点（不下雨的日子）。如果你仅仅从图像上看，试图说好吧，这个白点看起来像什么。
- en: it belongs to the blue category or does，it look like it belongs to the red。category
    I think most people would agree，that it probably belongs to the blue。category
    and why is that well it looks，like it's close to other blue dots and。that's not
    a very formal notion but it's，the notion that will formalize them in。
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它属于蓝色类别还是看起来属于红色类别？我想大多数人会同意它可能属于蓝色类别。为什么呢？因为它看起来接近其他蓝点。这不是一个很正式的概念，但我们会在后面进行形式化。
- en: just a moment because it seems to be，close to like this blue dot here like。nothing
    else is closer to it then we，might say that it should be categorized。as blue it
    should fall into that，category of I think that day is going to。be a rainy day
    based on that input might，not be totally accurate but it's a。
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 稍等一下，因为它似乎接近这个蓝点，周围没有其他点比它更近，因此我们可能会说它应该被分类为蓝色。我认为这一天将会是雨天，基于这个输入，可能不是完全准确，但这是一个。
- en: pretty good guess in this type of，algorithm is actually a very popular in。common
    machine learning algorithm known，as nearest neighbor classification it's。an algorithm
    for solving these，classification type problems and in。nearest neighbor classification
    it's，going to perform this algorithm what it。
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种算法中，做出相当不错的猜测实际上是一个非常流行的常见机器学习算法，称为最近邻分类。这是解决这些分类类型问题的算法。在最近邻分类中，它将执行这个算法。
- en: will do is given an input it will choose，the class of the nearest data point
    to。that input by class we just here mean，category like rain or no rain。counterfeit
    or not counterfeit and we，choose the category or the class based。on the nearest
    data point so given all，that data we just looked at is the。
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所做的是给定一个输入，它将选择与该输入最近的数据点的类别。这里的类别我们只指雨天或非雨天、假冒或非假冒，我们根据最近的数据点选择类别或类别。
- en: nearest data point a blue point or is it，a red point and depending on the answer。to
    that question we were able to make，some sort of judgment we were able to。say something
    like we think it's going，to be blue or we think it's going to be。red so likewise
    we could apply this to，other data points that we encounter as。
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的数据点是蓝点还是红点？根据这个问题的答案，我们能够做出某种判断，可以说我们认为它会是蓝色的，或者我们认为它会是红色的。同样，我们可以将此应用于我们遇到的其他数据点。
- en: well if suddenly this data point comes，about well it's nearest data is red so。we
    would go ahead and classify this as a，red point not raining things get a。little
    bit trickier though when you look，here，and you asked the same sort of question。should
    it belong to the category of blue，points the rainy days or should it。
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果突然出现这个数据点，它最近的数据是红色的，所以我们将其分类为红点，不下雨。但当你看看这里，问同样的问题时，事情会变得有点复杂。它应该属于蓝点（下雨天）类别，还是应该。
- en: belong to the category of red points，than not rainy days now nearest-neighbor。classification
    would say the way you，solve this problem is a look at which。point its nearest
    to that point you look，at this nearest point and say it's red。it's a not rainy
    day and therefore，according to nearest neighbor。
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 属于红点类别，而不是不下雨的日子。最近邻分类会说，解决这个问题的方法是看哪个点离那个点最近。你看这个最近的点，发现它是红色的，是个不下雨的日子，因此，根据最近邻。
- en: classification I would say that this，unlabeled point well that should also be。red
    it should also be classified as a，not rainy day but your intuition you。know might
    think that that's a，reasonable judgment to make that it's。the closest thing is
    a not rainy day so，may as well guess that it's not rainy。
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个未标记的点，我会说它也应该是红色的，它也应该被分类为不下雨的日子，但你的直觉可能会认为这是一个合理的判断，认为它最接近的东西是一个不下雨的日子，所以可以猜测它不下雨。
- en: day but it's probably also reasonable to，look at the bigger picture of things。since
    to say yes it is true that the，nearest point to it was a red point but。it's surrounded
    by a whole bunch of，other blue points so looking at the。bigger picture there's
    potentially an，argument to be made that this point。
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这一天，但从更大的角度看事情也是合理的，因为可以说，最近的点确实是一个红点，但它被许多其他蓝点包围，因此从更大的角度来看，可以认为这个点。
- en: should actually be blue and with only，this data we actually don't know for。sure
    we are given some input something，we're trying to predict and we don't。necessarily
    know what the output is，going to be so in this case which one is。correct is difficult
    to say but，oftentimes considering more than just a。
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上应该是蓝色的，而仅凭这些数据我们实际上并不确定，我们给出一些输入，试图预测的内容，而我们不一定知道输出将是什么，因此在这种情况下，哪一个是正确的很难说，但通常考虑的不仅仅是一个。
- en: single neighbor considering multiple，neighbors can sometimes give us a better。result
    and so there's a variant on the，nearest neighbor classification。algorithm that
    is known as the K nearest，neighbor classification algorithm where。K is some parameter
    some number that we，choose for how many neighbors are we。
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑多个邻居有时可以给我们更好的结果，因此存在一种称为K最近邻分类算法的变体，其中K是我们选择的一个参数，即我们希望查看多少个邻居。
- en: going to look at so one nearest neighbor，classification is what we saw before。just
    pick the one nearest neighbor and，use that category but with K nearest。neighbor
    classification where a K might，be three or five or seven to say look at。the three
    or five or seven closest，neighbors closest data points to that。
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要看的一个最近邻分类是我们之前看到的，选择最近的一个邻居并使用该类别，但在K最近邻分类中，K可能是三、五或七，表示查看三个、五个或七个与该点最近的数据点。
- en: point works a little bit differently，this algorithm will given an input。choose
    the most common class out of the，K nearest data points to that input so。if we
    look at the five nearest points，and you know three of them say it's。raining and
    two of them say it's not，raining we'll go with the three instead。
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个点的工作方式略有不同，该算法会在给定输入的情况下，从K个最近的数据点中选择最常见的类别，因此如果我们查看五个最近的点，知道其中三个说下雨，两个说没下雨，我们将选择三个。
- en: of the two because each one effectively，gets one vote towards what they believe。the
    category ought to be and ultimately，you choose the category that has the。most
    votes as a consequence of that so K，nearest neighbor classification fairly。straightforward
    one to understand，intuitively you just，look at the neighbors and figure out。
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是两个，因为每个点实际上都会对他们认为类别应是什么投票，最终你选择票数最多的类别，因此K最近邻分类是一个相对简单易懂的算法，你只需查看邻居并找出。
- en: what the answer might be and it turns，out this can work very very well for。solving
    a whole variety of different，types of classification problems but not。every model
    is going to work under every，situation and so one of the things we'll。take a look
    at today especially in the，context of supervised machine learning。
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 答案可能是什么，事实证明这对于解决各种不同类型的分类问题非常有效，但并不是每个模型在每种情况下都能有效，因此今天我们特别要关注的一个方面是监督机器学习的背景。
- en: is that there are a number of different，approaches to machine learning a number。of
    different algorithms that we can，apply all solving the same type of。problem all
    solving some kind of，classification problem where we want to。take inputs and organize
    it into，different categories and no one。
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的方法来进行机器学习，也有许多不同的算法可以应用，所有这些算法都在解决同一种类型的问题，都是一些分类问题，我们希望将输入数据组织成不同的类别，而没有任何一个算法一定会比其他算法更好。
- en: algorithm is necessarily always going to，be better than some other algorithm
    they。each have their trade-offs and maybe，depending on the data one type of。algorithm
    is going to be better suited，to trying to model that information than。some other
    algorithm and so this is what，a lot of machine learning research ends。
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每种算法都有其权衡，可能根据数据的不同，一种类型的算法会更适合对该信息进行建模，而这正是许多机器学习研究的终点。
- en: up being about that when you're trying，to apply machine learning techniques。you're
    often looking not just as one，particular algorithm but trying multiple。different
    algorithms trying to see what，is going to give you the best results。for trying
    to predict some function that，map's inputs to outputs so what then are。
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当你尝试应用机器学习技术时，往往不仅仅关注一个特定的算法，而是尝试多种不同的算法，看看哪个能够给你最好的结果，以预测将输入映射到输出的某个函数。那么，是什么呢？
- en: the drawbacks of K nearest neighbor，classification well there are a couple。one
    might be that in a naive approach at，least it could be fairly slow to have to。go
    through and measure the distance，between a point and every single one of。these
    points that exists here now there，are ways of trying to get around that。
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: K 最近邻分类的缺点，有几个。一个可能是，在一种天真的方法下，它可能会比较慢，因为必须遍历并测量一个点与这里每一个点之间的距离，现在有一些方法可以尝试解决这个问题。
- en: there are data structures that can help，to make it more quickly to be able to。find
    these neighbors there are also，techniques you can use to try and prune。some of
    this data or remove some of the，data points so that you're only left。with the
    relevant data points just to，make it a little bit easier but。
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有数据结构可以帮助更快速地找到这些邻居，还有一些技术可以用来尝试修剪一些数据或删除一些数据点，以便仅保留相关数据点，从而使其更容易，但。
- en: ultimately what we might like to do is，come up with another way of trying to
    do。this classification and one way of，trying to do the classification was。looking
    at like what are the neighboring，points but another way might be to try。to look
    at all of the data and see if we，can come up with some like decision。
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们可能想要做的是想出另一种方法来进行分类，一种尝试分类的方法是查看邻近的点，但另一种方法可能是尝试查看所有数据，看看我们能否想出一些决策。
- en: boundary some boundary that will，separate the rainy days from the not。rainy
    days in the case of two dimensions，we can do that by drawing a line for。example
    so what we might want to try to，do is just find some line find some。separator
    that divides the rainy days，the blue points over here from the not。
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 边界将雨天与非雨天分开，在二维的情况下，我们可以通过绘制一条线来做到这一点。例如，我们可能想尝试找到某条线，找到某个分隔符，将雨天（这里的蓝点）与非雨天分开。
- en: rainy days the red points over there，we're now trying a different approach in。contrast
    with the nearest neighbor，approach which just looked at local data。around the
    input data point that we，cared about now what we're doing is。trying to use a technique
    known as，linear regression to find some sort of。
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 雨天的红点在那边，我们现在正在尝试一种不同的方法。与仅查看输入数据点周围的局部数据的最近邻方法相对，现在我们所做的是尝试使用一种称为线性回归的技术来寻找某种。
- en: line that will separate the two halves，from each other now sometimes that are。actually
    possible to come up with some，line that perfectly separates all the。rainy days
    from the not rainy days，realistically though this is probably。cleaner than many
    data sets will，actually be oftentimes data is Messier。
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将两部分分开的线现在有时实际上可能会得出一条完美分隔所有雨天和非雨天的线，但实际上这可能比许多数据集要干净得多，通常数据会更混乱。
- en: there are outliers there's random noise，that happens inside of a particular。system
    and what we'd like to do is still，be able to figure out what a line might。look
    like so in practice the data will，not always be linearly separable。we're linearly
    separable refers to some，data set where I could like draw a line。
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 存在离群值和特定系统中发生的随机噪声，我们希望仍然能够弄清楚一条线可能是什么样子。因此，实际上数据并不总是线性可分的，线性可分指的是我可以绘制一条线的一些数据集。
- en: just to separate the two halves of it，perfectly instead you might have a。situation
    like this where there are some，rainy points that are on this side of。the line
    and some not rainy points that，are on that side of the line and there。may not
    be a line that perfectly，separates what path of the inputs from。
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完美地分开这两个部分，而是可能会出现这样的情况：某些雨天点在这条线的一侧，而某些非雨天点在那条线的另一侧，并且可能没有一条线能够完美地分开输入的路径。
- en: the other half that perfectly separates，all the rainy days from the not rainy。days
    but we can still say that this line，does a pretty good job and we'll try to。formalize
    a little bit later what we，mean when we say something like this。line does a pretty
    good job of trying to，make that prediction but for now let's。
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 另一半完美地区分了所有雨天和非雨天，但我们仍然可以说这条线做得相当不错，我们稍后会试图正式化一下，当我们说这样的线在尝试进行预测时做得相当不错的意思。但现在让我们。
- en: just say we're looking for a line that，does as good of a job as we can at。trying
    to separate one category of，things from another category of things。so let's now
    try to formalize this a，little bit more mathematically we want。to come up with
    some sort of function，some way we can define this line and our。
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅说我们正在寻找一条线，尽可能有效地将一类事物与另一类事物分开。那么现在我们试着在数学上更正式地表达这一点，我们想要想出某种函数，某种定义这条线的方法。
- en: inputs are things like humidity and，pressure in this case so our inputs we。might
    call x1 is going to be a represent，humidity and x2 is going to represent。pressure
    these are our inputs that we，are going to provide to our machine。learning algorithm
    and given those，inputs we would like for our model to be。
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 输入是像湿度和压力这样的东西，因此我们的输入可能称为x1，代表湿度，x2则代表压力。这些是我们将提供给机器学习算法的输入，基于这些输入，我们希望我们的模型能够。
- en: able to predict some sort of output and，we are going to predict that using our。hypothesis
    function which we called H，our hypothesis function is going to take。as input x1
    and x2 humidity and pressure，in this case and you can imagine if we。didn't just
    have two inputs we had three，or four or five inputs or more we could。
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 能够预测某种输出，我们将使用我们的假设函数来进行预测，我们称之为H，假设函数将以x1和x2（湿度和压力）作为输入。在这种情况下，你可以想象如果我们不仅有两个输入，而是有三个、四个、五个或更多输入，我们可以。
- en: have this hypothesis function take all，of those as input and we'll see examples。of
    that a little bit later as well and，now the question is what does this。hypothesis
    function do well it really，point，on one side of the boundary or is it on。the other
    side of the boundary and how，do we formalize that boundary well the。
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让这个假设函数将所有这些作为输入，我们稍后也会看到一些例子。现在问题是，这个假设函数做什么呢？它实际上是在边界的一侧还是在另一侧？我们如何正式化这个边界呢？
- en: boundary is generally going to be a，linear combination of these input。variables
    at least in this particular，case then what we're trying to do when。we say linear
    combination is take each，of these inputs and multiply them by。some number that
    we're gonna have to，figure out we'll generally call that。
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 边界通常将是这些输入变量的线性组合，至少在这个特定的案例中。那么我们所说的线性组合就是取每个输入并将其乘以一个我们需要弄明白的数字，我们通常称之为。
- en: number awaked for how important should，these variables be in trying to。determine
    the answer so we'll wait each，of these variables with some weight and。we might
    add like a constant to it just，to try and make the function a little。bit different
    and the result we just，need to compare like is it greater than。
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数字表示这些变量在试图确定答案时应该有多重要，因此我们将对这些变量加权，我们可能会再加上一个常数，以试图使这个函数有些不同，结果我们只需比较，看看它是大于。
- en: zero or is it less than zero to say it，doesn't belong on one side of the line。or
    the other side of the line and so，what that mathematical expression might。look
    like is this we would take each of，my variables X 1 and X 2 multiply them。by some
    weight I don't yet know what，that weight is but it's gonna be some。
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 零还是小于零，以说它不属于一侧的线或另一侧的线。那么，这个数学表达式可能看起来像这样：我们将取每个变量X1和X2，将它们乘以一些权重，我现在还不知道那个权重是什么，但它将是一些。
- en: number weight 1 and weigh - and maybe we，just want to add some other way to
    it。because the function might require us to，shift the entire value up or down
    by a。certain amount and then we just compare，if we do all this map is a greater
    than。or equal to 0 if so we might categorize，that data point as a rainy day and。
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 权重1，也许我们只想加上一些其他权重，因为函数可能要求我们将整个值上移或下移某个量，然后我们只需比较，如果我们做所有这些映射，是否大于或等于0，如果是，我们可能将这个数据点分类为雨天。
- en: otherwise we might say no rain so the，key here then is that this expression
    is。how we are going to calculate whether，it's a rainy day or not we're going to。do
    a bunch of math where we take each of，the variables multiply them by a weight。maybe
    add an extra weight to it see if，the result is greater than or equal to 0。
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 否则我们可能会说没有雨，因此关键在于这个表达式是我们将如何计算是否是雨天，我们将进行一系列数学运算，将每个变量乘以一个权重，也许再加一个额外的权重，看看结果是否大于或等于0。
- en: and using that result of that expression，we're able to determine whether it's。raining
    or not raining this expression，here it's in this case going to refer to。just some
    line if you were to plot，diagraph eclis it would just be some。line and what the
    line actually looks，like depends upon these weights x1 and。
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 并且利用这个表达式的结果，我们能够确定是否下雨，这个表达式在这里的情况将仅指代某条线，如果你绘制图表，它将只是一些线，而这条线的实际样子取决于这些权重x1和。
- en: x2 are the inputs but these weights are，really would determine the shape of
    that。line the slope of that line and what，that line actually looks like so we
    then。would like to figure out what these，weights should be we can choose whatever。weights
    we want but we want to choose，weights in such a way that if you pass。
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: x2是输入，但这些权重实际上决定了那条线的形状、斜率以及那条线的实际样子，因此我们想要弄清楚这些权重应该是什么，我们可以选择任何权重，但我们希望以这样的方式选择权重：如果你传入。
- en: in a rainy days humidity and pressure，then you end up with a result that is。greater
    than or equal to 0 and we would，like it such that if we passed into our。hypothesis
    function not rainy days in，then the output that we get should be。not raining so
    before we get there let's，try and formalize this a little bit more。
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在雨天的湿度和压力下，你最终得到的结果是大于或等于0的，我们希望这样，如果我们输入到我们的假设函数中不是雨天，那么我们得到的输出应该是不下雨，因此在到达那里之前，让我们尝试把这更正式化一些。
- en: mathematically just to get a sense for，how it is that you'll often see this
    if。you ever go further into supervised，machine learning and explore this idea。one
    thing is that generally for these，categories will sometimes just use the。names
    of the category it's like rain and，not rain often mathematically if we're。
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这样你就可以理解，如果你进一步深入监督学习并探索这个概念，你会经常看到这个。一件事是，通常对于这些类别，有时只会使用类别的名称，比如“下雨”和“不下雨”，通常在数学上如果我们。
- en: trying to do comparisons between these，things it's easier just to deal in the。world
    of numbers so we could just say 1，& 0 1 for raining 0 for not raining so。we do
    all this math and if the result is，greater than or equal to 0 we'll go。ahead and
    say our hypothesis function，outputs one meaning raining and。
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些事物之间进行比较时，处理数字世界更容易，所以我们可以说1和0，1代表下雨，0代表不下雨，因此我们做所有这些数学运算，如果结果大于或等于0，我们将继续说我们的假设函数输出1，意味着下雨。
- en: otherwise that outputs zero meaning not，raining and oftentimes this type of。expression
    will instead express using，vector mathematics and all the vector is。if you're
    not familiar with the term is，it refers to a sequence of numerical。values you
    could represent that in，Python using like a list of numerical。
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，输出为零，意味着不下雨，通常这类表达会用向量数学来表示，而向量如果你不熟悉这个术语，是指数值序列，你可以在Python中用数值列表表示。
- en: values or a tupple with numerical values，and here we have a couple of sequences。of
    numerical values one of our vectors，one of our sequences of numerical values。are
    all of these individual weights w0，w1 and w2 so we could construct what。we'll
    call a weight vector and we'll see，why this is useful in a moment called W。
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 值或带有数值的元组，在这里我们有几个数值序列，我们的一个向量，数值序列之一是所有这些单独的权重w0、w1和w2，因此我们可以构造一个我们称之为权重向量的东西，我们稍后将看到这有什么用，称为W。
- en: generally represented using a boldface W，that is just a sequence of these three。weights
    weight 0 weight 1 and weight 2，and to be able to calculate based on。those weights
    whether we think a day is，raining or not raining we're going to。multiply each
    of those weights by one of，our input variables that W to this。
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通常用加粗的W表示，这只是这三个权重的序列：权重0、权重1和权重2，为了能够基于这些权重计算我们认为一天是下雨还是不下雨，我们将把每个权重与我们的输入变量之一相乘。
- en: weight is going to be multiplied by，input variable X 2 W 1 is going to be。multiplied
    by input variable X 1 and W 0，well it's not being multiplied by。anything but to
    make sure the vectors is，the same length and we'll see why that's。useful in just
    a second we'll just go，ahead and say W 0 is being multiplied by。
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 权重将会乘以输入变量X2，W1将会乘以输入变量X1，而W0，嗯，它并没有被任何东西乘以，但为了确保向量长度一致，我们稍后会看到这为什么有用，我们只是说W0被乘以。
- en: 1 because you can multiply by something，by 1 and you end up getting the exact。same
    number so in addition to the weight，vector W will also have an input vector。that
    we'll call X that has three values，one again because we're just multiplying。W
    zero by one eventually and then X 1，and X 2 so here then we've represented。
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你可以乘以某个数，乘以1后最终得到的就是确切的相同数字，所以除了权重之外，向量W还会有一个输入向量，我们称之为X，它有三个值，再一次，因为我们只是在将W零乘以1，最终然后是X1和X2，所以这里我们已经表示出来。
- en: two distinct vectors that，Durov weights that we need to somehow。learn the goal
    of our machine learning，algorithm is to learn what this weight。vector is supposed
    to be we could choose，any arbitrary set of numbers and it。would produce a function
    that tries to，predict rain or not rain but it probably。
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 两个不同的向量，即我们需要以某种方式学习的权重，机器学习算法的目标是学习这个权重向量应该是什么，我们可以选择任何任意的数字集，它将产生一个尝试预测是否下雨的函数，但它可能不会很有效。
- en: wouldn't be very good what we want to do，is come up with a good choice of these。weights
    so that we're able to do the，accurate predictions and then this input。vector represents
    a particular input to，the function a data point for which we。would like to estimate
    is that day a，rainy day or is that day a not rainy day。
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是很好，我们想要做的是提出这些权重的良好选择，以便我们能够进行准确的预测，然后这个输入向量表示某个特定输入到函数中，即我们希望估计的一个数据点，看看那天是雨天还是非雨天。
- en: and so that's going to vary just，depending on what input is provided to。our
    function what it is that we are，trying to estimate and then to do the。calculation
    we want to calculate this，expression here and it turns out that。expression is
    what we would call the dot，product of these two vectors the dot。
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 而且这将根据提供给我们函数的输入而有所不同，我们正在尝试估计什么，然后为了进行计算，我们想要计算这个表达式，结果表明这个表达式就是我们所说的这两个向量的点积。
- en: product of two vectors just means taking，each of the terms and the vectors and。multiplying
    them together w0 x 1 w1，multiply it by X 1 w2 multiply it by X 2。and that's why
    these vectors need to be，the same length and then we just add all。of the results
    together so the dot，product of dot product of W and X our。
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的乘积仅意味着将向量中的每一项相乘，W0乘以X1，W1乘以X1，W2乘以X2，这就是为什么这些向量需要相同长度的原因，然后我们将所有结果相加，所以W和X的点积。
- en: weight vector and our input vector，that's just going to be W 0 times 1 or。just
    W 0 plus W 1 times X 1 multiplying，these two terms together plus W 2 times。X 2
    multiplying those terms together so，we have our weight vector which we need。to
    figure out we need our machine，learning algorithm to figure out what。
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 权重向量和我们的输入向量，只会是W0乘以1或者说是W0加上W1乘以X1，将这两个项相乘，再加上W2乘以X2，将这些项相乘，所以我们有我们的权重向量，我们需要搞清楚我们需要我们的机器学习算法来弄明白什么。
- en: the weights should be we have the input，vector representing the data point that。we're
    trying to predict a category for，predict a label for and we're able to do。that
    calculation by taking this dot，product which you'll often see。represented in vector
    form but if you，haven't seen vectors before you can。
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 权重应该是，我们有代表我们尝试预测的类别的数据点的输入向量，预测标签，我们能够通过计算这个点积来做到这一点，这在向量形式中经常被表示，但如果你之前没有见过向量，你可以。
- en: think of it as identical to just this，mathematical expression just doing the。multiplication
    adding the results，together and then seeing whether the。result is greater than
    or equal to 0 or，not this expression here is identical to。the expression that
    we're calculating to，see whether or not that answer is。
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 可以把它想象成与这个数学表达式完全相同，只是进行乘法运算，将结果相加，然后查看结果是否大于或等于0，这里的表达式与我们计算的表达式是完全相同的，以查看那个答案是否成立。
- en: greater than or equal to 0 in this case，and so for that reason you'll often
    see。the hypothesis function written as，something like this a simpler，representation
    where the hypothesis。takes as input some input vector X some，humidity and pressure
    for some day。we want to predict an output like rain，or no rain or 1 or 0 if we
    choose to。
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你通常会看到假设函数写成像这样一个更简单的表示，其中假设以某些输入向量X（某天的湿度和压力）作为输入。我们想要预测一个输出，比如下雨或不下雨，或者选择1或0。
- en: represent things numerically and the way，we do that is by taking the dot product。of
    the weight and our input if it's，greater than or equal to zero we'll go。ahead
    and say the output is 1 otherwise，the output is going to be 0 and this。hypothesis
    we say is parameterize by the，weights depending on what weights we。
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 数字表示事物的方式是通过计算权重和输入的点积。如果结果大于或等于零，我们将说输出为1；否则，输出为0。这个假设被认为是由权重参数化的，具体取决于我们选择的权重。
- en: choose we'll end up getting a different，hypothesis if we choose the weights。randomly
    we're probably not going to get，a very good hypothesis function we'll。get a 1
    or a 0 but it's probably not，accurately going to reflect whether we。think a day
    is going to be rainy or not，rainy but if we choose the weights right。
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们随机选择权重，最终得到的假设可能会有所不同，可能不会得到一个非常好的假设函数。我们会得到1或0，但这可能不会准确反映我们认为某一天是否会下雨，但如果我们正确选择权重。
- en: we can often do a pretty good job of，trying to estimate whether we think the。output
    of the function should be a 1 or，a 0 and so the question then is how to。figure
    out what these weights should be，how to be able to tune those parameters。and there
    are a number of ways you can，do that one of the most common is known。
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常可以很好地估计函数的输出应该是1还是0。那么问题是如何确定这些权重应该是什么，如何调整这些参数。有很多方法可以做到这一点，其中一种最常见的方法称为感知机学习规则，我们稍后会详细介绍。
- en: as the perceptron learning rule and，we'll see more of this later。but the idea
    of the perceptron learning，rule and we're not going to get too deep。into the mathematics
    we'll mostly just，introduce it more conceptually is to say。that given some data
    point that we would，like to learn from some data point that。
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 感知机学习规则的思想是，对于我们希望从中学习的数据点来说，不会深入数学，我们主要是以概念性介绍，假设给定一些数据点。
- en: has an input X and an output Y where Y，is like 1 for rain or 0 for not rain。then
    we're going to update the weights，and we'll look at the formula in just a。moment
    but the big picture idea is that，we can start with random weights but。then learn
    from the data like take the，data points one at a time and for each。
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个输入X和一个输出Y，其中Y为1表示下雨，0表示不下雨。然后我们将更新权重，稍后我们将看看公式，但大体思路是，我们可以从随机权重开始，然后像从数据中学习一样，逐个数据点处理。
- en: one of the data points figure out all，right what parameters do we need to。change
    inside of the weights in order to，better match that input point and so。that is
    the value of having access to a，lot of data in the supervised machine。learning
    algorithm is it you take each，of the data points and maybe look at the。
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据点中找出好吧，我们需要在权重中更改哪些参数，以更好地匹配该输入点。因此，拥有大量数据在监督学习算法中的价值在于，你逐个处理每个数据点，也许会查看。
- en: multiple times and constantly try and，figure out whether you need to shift。your
    weights in order to better create，some weight vector that is able to。correctly
    or more accurately try to，estimate what the output should be。whether we think
    it's going to be，raining or whether we think it's not。
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会多次尝试并不断确定是否需要调整权重，以便更好地创建一个能够正确或更准确地估计输出的权重向量。无论我们认为要下雨还是不下雨。
- en: going to be raining so what does that，weight update look like without going。into
    too much of the mathematics we're，going to update each of the weights to。be the
    result of the original weight，plus some additional expression and to。understand
    this expression，why well why is what the actual output。
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要下雨了，那么在不深入数学的情况下，权重更新看起来像什么呢？我们将更新每个权重，使其成为原始权重加上一些附加表达式，而要理解这个表达式，为什么呢？因为实际输出大于或等于0。
- en: is and hypothesis of X the input that's，going to be what we thought the input。was
    and so I can replace this by saying，like what the actual value was minus。what
    our estimate was and based on the，difference between the actual value and。what
    our estimate was we might want to，change our hypothesis change the way。
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 是输入 X 的假设，这将是我们认为的输入，所以我可以用实际值减去我们的估计来替代，并根据实际值和估计值之间的差异，我们可能想要改变我们的假设，改变我们。
- en: that we do that estimation if the actual，value in the estimate were the same。thing
    meaning we were correctly able to，predict what category this data point，belonged
    to。well then actual value minus estimate，that's just going to be zero。which means
    this whole term on the right，hand side goes to be zero and the weight。
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这种估计的方式，如果实际值和估计值是相同的，那么意味着我们能够正确预测这个数据点属于哪个类别。那么实际值减去估计值，这将是零，这意味着右边的整个项将变为零，权重。
- en: doesn't change wait I where I is like，wait one or wait 2 or wait zero wait I。just
    stays at wait I and none of the，weights change if we were able to。correctly predict
    what category the，input belong to but if our hypothesis。didn't correctly predict
    what category，the input belong to well then maybe then。
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 不会改变权重，我在这里的权重是指，权重保持不变，如果我们能够正确预测输入属于哪个类别，但如果我们的假设没有正确预测输入属于哪个类别，那么也许。
- en: we need to make some changes adjust the，weights so that we're better able to。predict
    this kind of data point in the，future and what is the way we might do。that well
    if the actual value was bigger，than the estimate then and for now we'll。go ahead
    and assume that these X's are，positive values then if the actual value。
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做一些调整，以便更好地预测未来这种数据点，而我们可能的方式是，如果实际值大于估计值，那么现在我们就假设这些 X 是正值。
- en: is bigger than the estimate well that，means we need to increase the weight in。order
    to make it such that the output is，bigger and therefore we're more likely。to get
    to the right actual value and so，if the actual value is bigger than the。estimate
    then actual value minus，estimate that'll be a positive number。
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果实际值大于估计值，那就意味着我们需要增加权重，以使输出更大，因此我们更有可能达到正确的实际值，所以如果实际值大于估计值，那么实际值减去估计值将是一个正数。
- en: and so you imagine we're just adding，some positive number to the weight just。to
    increase it ever so slightly and，likewise the inverse case is true that。if the
    actual value was less than the，estimate the actual value was zero but。we estimated
    one meaning of it actually，was not raining but we predicted it was。
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以想象，我们只是给权重增加一个正数，以稍微增加它，同样反向的情况也是如此，如果实际值小于估计值，实际值是零，但我们估计为一，意味着实际并没有下雨，但我们预测为下雨。
- en: going to be raining well then we want to，decrease the value of the weight because。then
    in that case we want to try and，lower the total value of computing that。dot product
    in order to make it less，likely that we would predict that it。would actually be
    raining so no need to，get too deep into the mathematics of。
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果预判为下雨，那么我们想要减少权重的值，因为在这种情况下，我们想尽量降低计算该点积的总值，以使我们预测实际会下雨的可能性更小，所以不需要深入到数学。
- en: that but the general idea is that every，time we encounter some data point we
    can。adjust these weights accordingly to try，and make the weights better line up
    with。the actual data that we have access，and you can repeat this process with。data
    point after data point until，eventually hopefully your algorithm。
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 总的思路是，每次遇到数据点时，我们可以相应地调整这些权重，以便更好地与我们所获得的实际数据对齐，你可以重复这个过程，逐个数据点，直到最终希望你的算法。
- en: converges to some set of weights that do，a pretty good job of trying to figure。out
    whether a day is going to be rainy，or not raining，and just as a final point about
    this。particular equation this value alpha，here is generally what we'll call the。learning
    rate it's just some parameter，some number we choose for how quickly。
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛到一些权重，这些权重相当好地尝试去判断一天是否会下雨，或者不会下雨，最后一点关于这个特定方程的值 alpha，这通常被称为**学习率**，它只是我们选择的一个参数，用来决定变化的速度。
- en: we're actually going to be updating，these weight values so that if alpha is。bigger
    then we're gonna update these，weight values by a lot and if alpha is。smaller then
    we'll update the weight，values by less and you can choose a。value of alpha depending
    on the problem，different values might suit the。
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上要更新这些权重值，因此如果 alpha 较大，我们将大幅更新这些权重值；如果 alpha 较小，我们将较少地更新权重值，你可以根据问题选择一个
    alpha 的值，不同的值可能更适合。
- en: situation better or worse than others so，after all of that after we've done
    this。training process of take all this data，and using this learning rule look
    at all。the pieces of data and use each piece of，data as an indication to us have
    do the。weight stay the same do we increase the，weights do we decrease the weights
    and。
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 情况，与其他情况相比是更好还是更差，所以在经历了这些之后，在我们完成了这个训练过程，利用所有这些数据并使用这个学习规则，查看所有的数据，并用每一条数据作为我们是否应该保持权重不变、增加权重或减少权重的指示。
- en: if so by how much what you end up with，is effectively a threshold function and。we
    can look at what the threshold，function looks like like this on the。x-axis here
    we have the output of that，function taking the weights taking the。dot product
    of it with the input and on，the y-axis we have what the output is。
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是的话，那究竟是多少呢？你最终得到的实际上是一个阈值函数，我们可以看看阈值函数的样子。在 x 轴上，我们有这个函数的输出，它取权重并与输入进行点积；在
    y 轴上，我们有输出的结果。
- en: going to be zero which in this case，represented like not raining and one。which
    in this case represented raining，and the way that our hypothesis function。works
    is it calculates this value and if，it's greater than zero or greater than。some
    threshold value then we declare，that it's a rainy day and otherwise we。
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个结果是零，这在这里表示不下雨，而另一个结果是1，这在这里表示下雨。我们的假设函数的工作方式是计算这个值，如果它大于零或大于某个阈值值，我们就声明今天是下雨天；否则我们就声明今天不下雨。
- en: declare that it's a not rainy day and，this then graphically is what that。function
    looks like that initially when，the value of this dot product is small。it's not
    raining it's not raining it's，not raining but as soon as it crosses。that threshold
    we suddenly say okay now，it's raining now it's raining not now。
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从图形上看，这个函数的样子是这样的：最初，当这个点积的值较小时，它是不下雨的；但一旦它超过了那个阈值，我们突然说，好吧，现在是下雨了，现在是下雨，不是的。
- en: it's raining and the way to interpret，this kind of representation is that。anything
    on this side of the line that，would be the category of data points。where we say
    yes it's raining anything，that falls on this side of the line are。the data points
    where we would say it's，not raining and again we want to choose。
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 它是下雨的，解读这种表示的方法是，这条线这一侧的任何东西都会被视为数据点的类别，我们会说“是的，下雨了”；而落在这条线另一侧的数据点则是我们会说“没下雨”。我们希望在两者之间进行选择。
- en: some value for the weights that results，in a function that does a pretty good。job
    of trying to do this estimation but，one tricky thing with this type of hard。threshold
    is that it only leaves two，possible outcomes，right we plug in some data as input
    and。the output we get is raining or not，raining and there's no room for anywhere。
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于权重的一些值，结果是一个相当不错的函数，试图进行这种估计。但这种硬阈值有一个棘手的地方，就是它只留下两种可能的结果。没错，我们输入一些数据，输出的结果就是下雨或不下雨，根本没有其他可能。
- en: in between and maybe that's what you，want maybe all you want is given some。data
    point you would like to be able to，classify it into one or two or more of。these
    various different categories but，it might also be the case that you care。about
    knowing how strong that prediction，is for example so if we go back to this。
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这就是你想要的，或许你只想根据一些数据点，能够将其分类为这几个不同的类别之一或多个，但也可能你关心的是知道这个预测的强度，例如，如果我们回到这个。
- en: instance here where we have a rainy days，on this side of the line not rainy
    days。on that side of the line and you might，imagine that let's look now at these
    two。white data points this data point here，that we would like to predict a label
    or。a category form and this data point over，here that we would also like to predict。
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个例子，我们在这条线的这一侧有下雨的日子，而在那一侧则是非下雨的日子。你可能想象，现在来看看这两个白色的数据点。这个数据点是我们希望预测标签或类别的；而这个数据点我们也希望进行预测。
- en: a label or a category for it seems，likely that you could pretty confidently。say
    that this data point that should be，a rainy day seems close to the other。rainy
    days if we're going by the nearest，neighbor strategy and it's on this side。of
    the line if we're going by the，strategy of just saying you know which。
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一个标签或类别似乎很可能你可以相当自信地说，这个数据点应该是一个雨天，似乎靠近其他雨天，如果我们依据最近邻策略，它在这条线的这一侧，如果我们根据仅仅是说你知道哪个。
- en: side of the line does it fall on by，figuring out what those weights should。be
    and if we're using the line strategy，of just which side of the line does it。fall
    on which side of this decision，boundary what we'd also say that this。point here
    is also a rainy day because，it follows on the side of the line that。
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这条线的哪一侧，它应该落在哪一侧，通过弄清楚这些权重应该是什么。如果我们使用线性策略，仅仅判断它落在哪一侧，哪个是这个决策边界的侧面，我们还可以说，这个点也是一个雨天，因为它在这条线的一侧。
- en: corresponds to rainy days but it's，likely that even in this case we would。know
    that we don't feel nearly as，confident about this data point on the。left as compared
    to this data point on，the right therefore this one on the。right we can feel very
    confident that，yes it's a rainy day and this one you。
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这与雨天相对应，但即使在这种情况下，我们也可能知道，我们对左侧的这个数据点的信心远没有右侧的这个数据点高，因此我们对右侧的这个数据点可以非常有信心，“是的，这是一个雨天”，而这个你。
- en: know it's pretty close to the line if，we're judging just by distance and so。you
    might be less sure but our threshold，function doesn't allow for a notion of。less
    sure or more sure about something，it's what we would call a hard threshold。it's
    once you've crossed this line then，immediately we say yes this is going to。
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仅通过距离来判断，它距离线非常近，因此你可能不太确定，但我们的阈值函数不允许对于某事物有“更不确定”或“更确定”的概念，这就是我们所称的硬阈值。一旦你跨越了这条线，我们就立刻说“是的，这将会下雨”。
- en: be a rainy day and anywhere before it，we're gonna say it's not a rainy day and。that
    may not be helpful in a number of，cases one this is not a particularly。easy function
    to deal with if you guess，you get deeper into the world and。machine learning and
    are trying to do，things like taking derivatives of these。
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个雨天，在线的前面我们将说它不是一个雨天，这在许多情况下可能没有帮助。首先，这不是一个特别容易处理的函数，如果你深入了解机器学习，并试图做一些像求导这样的事情。
- en: curves this type of function makes，things challenging but the other。challenge
    is that we don't really have，any notion of gradation between things。we don't have
    a notion of yes this is a，very strong，only strong belief that it's going to be。raining
    as opposed to you know it's，probably more likely than not that it's。
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的函数使事情变得复杂，但另一个挑战是，我们对事物之间的渐变没有真正的概念。我们没有“是的，这是一个非常强烈的，只有强烈的信念它会下雨”，与“可能比不下雨要更可能”相对。
- en: going to be raining but maybe not，totally sure about that either so what。we
    can do by taking advantage of a，technique known as logistic regression。is instead
    of using this hard threshold，type of function we can use instead a。logistic function
    something we might，call a soft threshold and that's going。
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会下雨，但也许对此并不完全确定。因此，我们可以利用一种称为逻辑回归的技术，取而代之的是使用这种硬阈值类型的函数，我们可以使用一个逻辑函数，我们可以称之为软阈值，这样就可以了。
- en: to transform this into looking something，a little more like this something that。more
    nicely curves and as a result the，possible output values are no longer，just zero
    and 1：
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个转换成更像这样的东西，使其更平滑，因此可能的输出值不再仅仅是零和一：
- en: 04 not raining one for，raining but you can actually get any，real numbered value
    between zero and one。that if you're way over on this side，then you get a value
    of zero okay it's。not gonna be raining and we're pretty，sure about that if you're
    over on this。side you get a value of one like yes，we're very sure that it's going
    to be。
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 04 不下雨的情况，虽然下雨，但你实际上可以得到任何在零和一之间的真实数值。如果你在这边，那么你得到的值是零，好的，它不会下雨，我们对此非常确定。如果你在这边，你得到的值是一个，像是“是的，我们非常确定会下雨”。
- en: raining but in between you could get，some real numbered value where a value，like
    0。7 might mean you know we think，it's gonna rain it's more probable that。it's
    gonna rain than not based on the，data but we're not as confident as some。of the
    other data points might be so one，of the advantages of the soft threshold。
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下雨，但在两者之间，你可以得到一些真实的数值，其中一个值，比如0.7，可能意味着我们认为会下雨，基于数据它下雨的可能性比不下雨要高，但我们对某些其他数据点可能没有那么自信。因此，软阈值的一个优势。
- en: is that it allows us to have an output，that could be some real number that。potentially
    reflects some sort of，probability the likelihood that we think。that this particular
    data point belongs，to that particular category and there。are some other nice mathematical，properties
    of that as well so that then。
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许我们有一个输出，可能是某个实数，反映某种概率，即我们认为这个特定数据点属于那个特定类别的可能性。此外，还有一些其他不错的数学属性。
- en: is two different approaches to trying to，solve this type of classification。problem
    one is this nearest neighbor，type of approach where you just take a。data point
    and look at the data points，that are nearby to try and estimate what。category
    we think it belongs to and the，other approach is the approach of saying。
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种不同的方法来解决这种分类问题，一种是最近邻的方法，你只需取一个数据点，查看附近的数据点，以估计它属于哪个类别，另一种方法则是通过。
- en: alright let's just try and use linear，regression and figure out what these。weights
    should be adjust the weights in，order to figure out what line or what。decision
    boundary is going to best，separate these two categories it turns。out that another
    popular approach a very，popular approach if you just have a data。
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，让我们尝试使用线性回归，调整权重以确定最能分隔这两类的决策边界。结果表明，另一种非常流行的方法是，当你有一个穿过数据集的对角线。
- en: set and you want to start trying to do，some learning on it is what we call the。support
    vector machine we're not going，to go too much into the mathematics of。the support
    vector machine but we'll at，least explore it graphically to see what。it is that
    it looks like and the idea or，the motivation behind the support vector。
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 设置并开始尝试进行一些学习，这就是我们所称的支持向量机。我们不会过多讨论支持向量机的数学，但至少会从图形上探讨它的样子以及支持向量机背后的动机。
- en: machine is the idea that there are，actually a lot of different，that we could
    draw a lot of different。decision boundaries that we could draw，to separate two
    groups so if for example。I had the red data points over here and，the blue data
    points over here one。possible line I could draw is a line，like this that this
    line here would。
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，我在这里有红数据点，而蓝数据点在这里，我可以画出这样的一条线，这条线将红点与蓝点分开。
- en: separate the red points from the blue，points and it does so perfectly all the。red
    points are on one side of the line，all the blue points are on the other。side of
    the line but this should，probably make you a little bit nervous。if you come up
    with a model and the，model comes up with the line that looks。
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 它能够完美地将红点与蓝点分开，所有红点都在直线的一侧，所有蓝点都在另一侧。但如果你得出了一个看起来像这样的模型，可能会让你有些紧张。
- en: like this and the reason why I am is，that you worry about how well it's going。to
    generalize to other data points that，are not necessarily in the data set that。we
    have access to for example if there，was a point that fell like right here。for
    example on the right side of the，line well then based on that we might。
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我担心的是，它在其他不一定在我们拥有数据集中的数据点上的泛化能力。例如，如果有一个点正好位于直线的右侧。
- en: want to guess that it is in fact a red，point but it falls on the side of the。line
    where instead we would estimate，that it's a blue point instead and so。based on
    that this line is probably not，a great choice just because it is so。close to these
    various data points we，might instead prefer like a diagonal。
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我想猜测这实际上是一个红点，但它落在了线的一侧，而我们估计它是一个蓝点。因此，这条线可能不是一个很好的选择，因为它与这些数据点太接近。
- en: line that just goes diagonally through，the data set like we've seen before but。there
    - there's a lot of diagonal lines，that we could draw as well for example I。could
    draw this diagonal line here which，also successfully separates all the red。points
    from all of the blue points from，the perspective of something like just。
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这条线也成功地将所有红点从所有蓝点中分开。从某种角度来看，实际上有很多不同的决策边界可以画出，以分隔两组数据。
- en: trying to figure out some setting of，weights that allows us to predict the。correct
    output this line will predict，the correct output for this particular。set of data
    every single time because，the red points are on one side of the。blue points are
    on the other but yet，again you should probably be a little。
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一些权重设置，让我们能够预测正确的输出，这条线将每次都为这组数据预测正确的输出，因为红点在一侧，蓝点在另一侧，但你应该再稍微谨慎一点。
- en: nervous because this line is so close to，these red points even though we're
    able。to correctly predict on the input data，if there was a point that fell you
    know。somewhere in this general area our，algorithm this model would say that yeah。we
    think it's a blue point when in，actuality it might belong to the red。
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会感到紧张，因为这条线与这些红点如此接近，即使我们能够正确预测输入数据。如果有一个点落在这个一般区域，我们的算法模型会说是的，我们认为它是蓝点，而实际上它可能属于红色。
- en: category instead just because it looks，like it's close to the other red point。what
    we really want to be able to say，given this data how can you generalize。this as
    best as possible is to come up，with a line like this that seems like。the intuitive
    line to draw and the，reason why it's intuitive is because it。
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 分类仅仅因为它看起来接近其他红点。我们真正想说的是，给定这些数据，如何尽可能好地概括它，就是想出这样一条看似直观的线，而之所以直观，是因为它。
- en: seems to be as far apart as possible，from the red data and the，so that if we
    generalize a little bit。and assume that maybe we have some，points that are different
    from the input。but still slightly further away we can，still say that something
    on this side。probably read something on that side，probably blue and we can make
    those。
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来尽可能远离红色数据，因此，如果我们稍微概括一下，假设我们有一些与输入不同的点，但仍然稍微远离，我们仍然可以说这一侧的东西可能是红色的，而那一侧的东西可能是蓝色的，我们可以做出这些。
- en: judgments that way and that is what，support vector machines are designed to。do
    they're designed to try and find what，we call the maximum margin separator。where
    the maximum margin separator is，just some boundary that maximizes the。![](img/d1fa64ba22d78e5e958d31065456ad72_2.png)
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这样进行判断，这正是支持向量机设计的目的。它们旨在寻找我们所称的最大边际分隔器，最大边际分隔器仅仅是最大化的某种边界。![图像](img/d1fa64ba22d78e5e958d31065456ad72_2.png)
- en: distance between the groups of points，rather than come up with some boundary，other。where
    in the case before we wouldn't，have cared as long as we're categorizing。the input
    well that seems all we need to，do the support the support vector。machine will
    try and find this maximum，margin separator some way of trying to。
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在点组之间的距离，而不是想出其他某种边界。在之前的情况下，我们不会在意，只要我们能很好地对输入进行分类，这似乎就是我们需要做的一切，支持向量机会尝试找到这个最大边际分隔器，试图找出。
- en: maximize that particular distance and it，does so by finding what we call the。support
    vectors which are the vectors，that are closest to the line and trying。to maximize
    the distance between the，line and those particular points and it。works that way
    in two dimensions it also，works in higher dimensions where we're。
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化特定的距离，它通过找到我们称之为支持向量的向量来实现，这些向量与线最近，并试图最大化线与这些特定点之间的距离。在二维中是这样，在更高维度中也是如此。
- en: not looking for some line that separates，the two data points but instead looking。for
    what we generally call a hyperplane，some decision boundary effectively that。separates
    one set of data from the other，set of data and this ability of support。vector
    machines to work in higher，dimensions actually has a number of。
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并不是在寻找某条将两个数据点分开的线，而是在寻找我们通常称之为超平面的东西，即有效地将一组数据与另一组数据分开的决策边界，而支持向量机在更高维度中工作的能力实际上有很多。
- en: other applications as well but one is，that it helpfully deals with cases where。data
    may not be linearly separable so we，talked about linear separability before。this
    idea that you can take data and，just draw a line or some linear。combination of
    the inputs that allows us，to perfectly separate the two sets from。
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他应用，但其中之一是它很好地处理数据可能不是线性可分的情况，因此我们之前讨论了线性可分性。这个想法是，你可以取数据，画一条线或某种输入的线性组合，这使我们能够完美地将两组分开。
- en: each other there are some data sets that，are not linearly separable and some
    word。even to you would not be able to find a，good line at all，that would try to
    do that kind of。separation something like this for，example or if you imagine here
    are the。red points and the blue points around it，if you try to find a line that
    divides。
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 彼此之间有一些数据集是不可线性分开的，有些情况下你甚至无法找到一条好的线来进行这种分离，比如像这样，或者如果你想象这里有红点和周围的蓝点，如果你试图找到一条线将其划分开来。
- en: the red points from the blue points it's，actually going to be difficult it's
    not。impossible to do that any line you，choose well if you draw a line here then。you've
    ignored all of these blue points，that should actually be blue and not red。anywhere
    else you draw a line there's，going to be a lot of error a lot of。
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 将红点与蓝点区分开来实际上是困难的，并不是不可能。如果你选择在这里画一条线，那么你就忽略了这些本该是蓝色而不是红色的点。无论你在哪里画线，都会有很多错误。
- en: mistakes a lot of what will soon call，loss to that line that you。a lot of points
    that you're going to，categorize incorrectly what we really。want is to be able
    to find better，decision boundary that may not be just a。straight line through
    this，two-dimensional space and what support。
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 误差很多，这将很快称为损失，你将有很多点被错误分类。我们真正想要的是能够找到更好的决策边界，它可能不仅仅是通过这个二维空间的一条直线。
- en: vector machines can do is they can begin，to operate in higher dimensions and
    be。able to find some other decision，boundary like the circle in this case。that
    actually is able to separate one of，these sets of data from the other set of。data
    a lot better so oftentimes in，datasets where the data is not linearly。
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 向量机所能做的是，它们可以开始在更高维度中操作，并能够找到一些其他的决策边界，比如在这种情况下的圆，实际上能够更好地区分这些数据集。
- en: separable support vector machines by，working in higher dimensions can。actually
    figure out a way to solve that，kind of problem effectively so that then。three
    different approaches to trying to，solve these sorts of problems we see。them support
    vector machines and we've，seen trying to use linear regression and。
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 可分离的支持向量机通过在更高维度中工作，实际上可以找到有效解决这类问题的方法。因此，我们可以看到三种不同的方法来尝试解决这些问题，我们看到支持向量机，并且我们尝试使用线性回归。
- en: the perceptron learning rule to be able，to figure out how to categorize inputs。and
    outputs we see in the nearest，neighbor approach，no one necessarily better than
    any other。again it's going to depend on the data，set the information you have
    access to。it's going to depend on what the，function looks like that you're。
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器学习规则旨在找出如何对输入和输出进行分类，我们在最近邻方法中看到，没有一种方法一定比其他方法更好。这又要取决于你所访问的数据集和信息，以及你要处理的函数的形状。
- en: ultimately trying to predict and this is，where a lot of research and。experimentation
    can be involved in，trying to figure out how it is to best。perform that kind of
    estimation but，classification is only one of the tasks。that you might encounter
    in supervised，machine learning because in。
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的目标是进行预测，这也是很多研究和实验涉及的地方，试图找出如何最佳执行这种估计，但分类只是你可能在监督学习中遇到的任务之一。
- en: classification what we're trying to，predict is some discrete category we're。trying
    to predict red or blue rain or。
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 分类我们要预测的是某个离散类别，我们试图预测红色或蓝色的雨。
