- en: Lecture 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二次讲座
- en: 原文：[https://cs50.harvard.edu/ai/notes/2/](https://cs50.harvard.edu/ai/notes/2/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://cs50.harvard.edu/ai/notes/2/](https://cs50.harvard.edu/ai/notes/2/)
- en: Uncertainty
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不确定性
- en: Last lecture, we discussed how AI can represent and derive new knowledge. However,
    often, in reality, the AI has only partial knowledge of the world, leaving space
    for uncertainty. Still, we would like our AI to make the best possible decision
    in these situations. For example, when predicting weather, the AI has information
    about the weather today, but there is no way to predict with 100% accuracy the
    weather tomorrow. Still, we can do better than chance, and today’s lecture is
    about how we can create AI that makes optimal decisions given limited information
    and uncertainty.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 上次讲座，我们讨论了AI如何表示和推导新的知识。然而，在现实中，AI通常只有对世界的部分了解，这留下了不确定性的空间。尽管如此，我们希望我们的AI在这些情况下做出最佳可能的决策。例如，在预测天气时，AI有关于今天天气的信息，但无法100%准确地预测明天的天气。尽管如此，我们可以比随机性做得更好，今天的讲座是关于我们如何创建在有限信息和不确定性下做出最优决策的AI。
- en: Probability
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率
- en: Uncertainty can be represented as a number of events and the likelihood, or
    probability, of each of them happening.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性可以用一系列事件及其发生的可能性或概率来表示。
- en: '**Possible Worlds**'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**可能的世界**'
- en: 'Every possible situation can be thought of as a world, represented by the lowercase
    Greek letter omega ω. For example, rolling a die can result in six possible worlds:
    a world where the die yields a 1, a world where the die yields a 2, and so on.
    To represent the probability of a certain world, we write P(*ω*).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 每个可能的情况都可以被视为一个世界，用小写希腊字母omega ω表示。例如，掷骰子可以产生六个可能的世界：一个世界是骰子显示1，一个世界是骰子显示2，以此类推。为了表示某个世界的概率，我们写P(*ω*)。
- en: '**Axioms in Probability**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**概率公理**'
- en: '0 < P(*ω*) < 1: every value representing probability must range between 0 and
    1.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0 < P(*ω*) < 1：每个代表概率的值必须在0和1之间。
- en: Zero is an impossible event, like rolling a standard die and getting a 7.
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零是一个不可能发生的事件，比如掷一个标准骰子得到7。
- en: One is an event that is certain to happen, like rolling a standard die and getting
    a value less than 10.
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个是一定会发生的事件，比如掷一个标准骰子得到小于10的数值。
- en: In general, the higher the value, the more likely the event is to happen.
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常情况下，数值越高，事件发生的可能性就越大。
- en: The probabilities of every possible event, when summed together, are equal to
    1.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有可能事件的概率之和等于1。
- en: '![Summing Probabilities](../Images/9e8aae5f3b3ce3d92df7dfd9290cf079.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![概率求和](../Images/9e8aae5f3b3ce3d92df7dfd9290cf079.png)'
- en: The probability of rolling a number *R* with a standard die can be represented
    as P(*R*). In our case, P(*R*) = 1/6, because there are six possible worlds (rolling
    any number from 1 through 6) and each is equally likely to happen. Now, consider
    the event of rolling two dice. Now, there are 36 possible events, which are, again,
    equally as likely.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 抛掷一个标准骰子得到数字 *R* 的概率可以表示为 P(*R*)。在我们的例子中，P(*R*) = 1/6，因为有六个可能的世界（从1到6的任意数字），每个世界发生的可能性是相等的。现在，考虑抛掷两个骰子的事件。现在，有36个可能的事件，它们再次是同等可能发生的。
- en: '![36 Events](../Images/7acb0bf3fad4d177724794bcad78abcf.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![36个事件](../Images/7acb0bf3fad4d177724794bcad78abcf.png)'
- en: However, what happens if we try to predict the sum of the two dice? In this
    case, we have only 11 possible values (the sum has to range from 2 to 12), and
    they do not occur equally as often.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们尝试预测两个骰子的和会发生什么？在这种情况下，我们只有11个可能值（和必须从2到12），它们并不以相同的频率发生。
- en: '![Sum of Two Dice](../Images/0239d1fb8e6d4f8ad96b46b33e9ae6e8.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![两个骰子的和](../Images/0239d1fb8e6d4f8ad96b46b33e9ae6e8.png)'
- en: To get the probability of an event, we divide the number of worlds in which
    it occurs by the number of total possible worlds. For example, there are 36 possible
    worlds when rolling two dice. Only in one of these worlds, when both dice yield
    a 6, do we get the sum of 12\. Thus, P(*12*) = 1/36, or, in words, the probability
    of rolling two dice and getting two numbers whose sum is 12 is 1/36\. What is
    P(*7*)? We count and see that the sum 7 occurs in 6 worlds. Thus, P(*7*) = 6/36
    = 1/6.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要得到一个事件的概率，我们将其发生的世界数除以所有可能世界数。例如，当抛掷两个骰子时，有36个可能的世界。只有在这36个世界中，当两个骰子都显示6时，我们才能得到和为12。因此，P(*12*)
    = 1/36，或者说，用文字表达，抛掷两个骰子得到两个数之和为12的概率是1/36。P(*7*)是多少？我们数一下，发现和为7的情况发生在6个世界中。因此，P(*7*)
    = 6/36 = 1/6。
- en: '**Unconditional Probability**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**无条件概率**'
- en: Unconditional probability is the degree of belief in a proposition in the absence
    of any other evidence. All the questions that we have asked so far were questions
    of unconditional probability, because the result of rolling a die is not dependent
    on previous events.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 无条件概率是在没有任何其他证据的情况下对命题的信念程度。我们之前提出的所有问题都是无条件概率问题，因为掷骰子的结果不依赖于先前的事件。
- en: Conditional Probability
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条件概率
- en: Conditional probability is the degree of belief in a proposition given some
    evidence that has already been revealed. As discussed in the introduction, AI
    can use partial information to make educated guesses about the future. To use
    this information, which affects the probability that the event occurs in the future,
    we rely on conditional probability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率是在已有某些证据被揭示的情况下，对命题的信念程度。正如引言中讨论的，人工智能可以使用部分信息对未来做出有根据的猜测。为了使用这些信息，这些信息会影响未来事件发生的概率，我们依赖于条件概率。
- en: 'Conditional probability is expressed using the following notation: P(*a | b*),
    meaning “the probability of event *a* occurring given that we know event *b* to
    have occurred,” or, more succinctly, “the probability of *a* given *b*.” Now we
    can ask questions like what is the probability of rain today given that it rained
    yesterday P(*rain today | rain yesterday*), or what is the probability of the
    patient having the disease given their test results P(*disease | test results*).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率使用以下符号表示：P(*a | b*)，意味着“在已知事件 *b* 已经发生的情况下，事件 *a* 发生的概率，”或者更简洁地说，“给定 *b*
    的 *a* 的概率。”现在我们可以提出像今天下雨的概率是多少，给定昨天已经下雨 P(*rain today | rain yesterday*)，或者患者有疾病的概率是多少，给定他们的检测结果
    P(*disease | test results*)。
- en: 'Mathematically, to compute the conditional probability of *a* given *b*, we
    use the following formula:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，为了计算给定 *b* 的 *a* 的条件概率，我们使用以下公式：
- en: '![Conditional Probability Formula](../Images/3ed75a84fd781e595d28e8290b332c65.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![条件概率公式](../Images/3ed75a84fd781e595d28e8290b332c65.png)'
- en: 'To put it in words, the probability that *a* given *b* is true is equal to
    the probability of *a* and *b* being true, divided by the probability of *b*.
    An intuitive way of reasoning about this is the thought “we are interested in
    the events where both *a* and *b* are true (the numerator), but only from the
    worlds where we know *b* to be true (the denominator).” Dividing by *b* restricts
    the possible worlds to the ones where *b* is true. The following are algebraically
    equivalent forms to the formula above:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 用语言来说，给定 *b* 的 *a* 的概率是真实的，等于 *a* 和 *b* 同时为真的概率，除以 *b* 的概率。对此进行直观推理的一种方式是“我们感兴趣的只是
    *a* 和 *b* 同时为真的事件（分子），但只从我们知道 *b* 为真的世界中（分母）。”除以 *b* 限制了可能的世界，使其只包含 *b* 为真的世界。以下是与上述公式代数上等价的形式：
- en: '![Equivalent Formulas](../Images/c8f319de3f5b737991e1870e387f0f1d.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![等效公式](../Images/c8f319de3f5b737991e1870e387f0f1d.png)'
- en: 'For example, consider P(*sum 12 | roll six on one die*), or the probability
    of rolling two dice and getting a sum of twelve, given that we have already rolled
    one die and got a six. To calculate this, we first restrict our worlds to the
    ones where the value of the first die is six:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑 P(*sum 12 | roll six on one die*)，或者在我们已经掷出一个六的情况下，掷两个骰子得到总和为十二的概率。为了计算这个概率，我们首先将我们的世界限制在第一个骰子的值为六的情况：
- en: '![Restricting the Worlds](../Images/c6db2185d70a90243e95999a4e211c65.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![限制世界](../Images/c6db2185d70a90243e95999a4e211c65.png)'
- en: Now we ask how many times does the event *a* (the sum being 12) occur in the
    worlds that we restricted the question to (dividing by P(*b*), or the probability
    of the first die yielding 6).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们询问事件 *a*（总和为12）在我们限制问题的世界中发生的次数是多少（除以 P(*b*)，即第一个骰子掷出6的概率）。
- en: '![Conditioned Probability](../Images/b8ad79a4f9df28af93781db43fe37a08.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![条件概率](../Images/b8ad79a4f9df28af93781db43fe37a08.png)'
- en: Random Variables
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机变量
- en: A random variable is a variable in probability theory with a domain of possible
    values that it can take on. For example, to represent possible outcomes when rolling
    a die, we can define a random variable *Roll*, that can take on the values {*1,
    2, 3, 4, 5, 6*}. To represent the status of a flight, we can define a variable
    *Flight* that takes on the values {*on time, delayed, canceled*}.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量是概率论中的一个变量，它有一个可能的值域。例如，为了表示掷骰子的可能结果，我们可以定义一个随机变量 *Roll*，它可以取值 {*1, 2, 3,
    4, 5, 6*}。为了表示航班的状况，我们可以定义一个变量 *Flight*，它可以取值 {*on time, delayed, canceled*}。
- en: Often, we are interested in the probability with which each value occurs. We
    represent this using a probability distribution. For example,
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们感兴趣的是每个值出现的概率。我们使用概率分布来表示这一点。例如，
- en: P(*Flight = on time*) = 0.6
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P(*Flight = on time*) = 0.6
- en: P(*Flight = delayed*) = 0.3
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P(*Flight = delayed*) = 0.3
- en: P(*Flight = canceled*) = 0.1
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P(*Flight = canceled*) = 0.1
- en: To interpret the probability distribution with words, this means that there
    is a 60% chance that the flight is on time, 30% chance that it is delayed, and
    10% chance that it is canceled. Note that, as shown previously, the sum the probabilities
    of all possible outcomes is 1.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 用文字来解释概率分布，这意味着有60%的几率航班准点，30%的几率延误，10%的几率取消。注意，如前所述，所有可能结果的概率之和为1。
- en: A probability distribution can be represented more succinctly as a vector. For
    example, **P**(*Flight*) = <*0.6, 0.3, 0.1*>. For this notation to be interpretable,
    the values have a set order (in our case, *on time, delayed, canceled*).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布可以用向量更简洁地表示。例如，**P**(*Flight*) = <*0.6, 0.3, 0.1*>. 为了使这种表示法可解释，值必须有一个固定的顺序（在我们的例子中，*准点，延误，取消*）。
- en: '**Independence**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**独立性**'
- en: Independence is the knowledge that the occurrence of one event does not affect
    the probability of the other event. For example, when rolling two dice, the result
    of each die is independent from the other. Rolling a 4 with the first die does
    not influence the value of the second die that we roll. This is opposed to dependent
    events, like clouds in the morning and rain in the afternoon. If it is cloudy
    in the morning, it is more likely that it will rain in the afternoon, so these
    events are dependent.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性是知道一个事件的发生不会影响另一个事件发生的概率。例如，当掷两个骰子时，每个骰子的结果是相互独立的。掷出第一个骰子的4点不会影响我们掷出的第二个骰子的值。这与像早晨有云和下午下雨这样的相关事件相反。如果早晨有云，下午下雨的可能性更大，所以这些事件是相关的。
- en: 'Independence can be defined mathematically: events *a* and *b* are independent
    if and only if the probability of *a* and *b* is equal to the probability of *a*
    times the probability of *b*: P(*a ∧ b*) = P(*a*)P(*b*).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性可以用数学定义：事件*a*和*b*是独立的，当且仅当*a*和*b*的概率等于*a*的概率乘以*b*的概率：P(*a ∧ b*) = P(*a*)P(*b*).
- en: Bayes’ Rule
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: Bayes’ rule is commonly used in probability theory to compute conditional probability.
    In words, Bayes’ rule says that the probability of *b* given *a* is equal to the
    probability of *a* given *b*, times the probability of *b*, divided by the probability
    of *a*.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理在概率论中常用以计算条件概率。用文字来说，贝叶斯定理表明，给定*a*的*b*的概率等于给定*b*的*a*的概率，乘以*b*的概率，除以*a*的概率。
- en: '![Bayes'' Rule](../Images/43f7f72a2ec8f7e902766aa8a8af95dd.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](../Images/43f7f72a2ec8f7e902766aa8a8af95dd.png)'
- en: 'For example, we would like to compute the probability of it raining in the
    afternoon if there are clouds in the morning, or P(*rain | clouds*). We start
    with the following information:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们想要计算如果早晨有云，下午下雨的概率，或P(*雨 | 云*). 我们从以下信息开始：
- en: 80% of rainy afternoons start with cloudy mornings, or P(*clouds | rain*).
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 80%的雨天下午始于多云的早晨，或P(*云 | 雨*).
- en: 40% of days have cloudy mornings, or P(*clouds*).
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 40%的天数早晨有云，或P(*云*).
- en: 10% of days have rainy afternoons, or P(*rain*).
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10%的天数下午有雨，或P(*雨*).
- en: Applying Bayes’ rule, we compute (0.1)(0.8)/(0.4) = 0.2\. That is, the probability
    that it rains in the afternoon given that it was cloudy in the morning is 20%.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 应用贝叶斯定理，我们计算(0.1)(0.8)/(0.4) = 0.2\. 这意味着，如果早晨有云，下午下雨的概率是20%。
- en: Knowing P(*a | b*), in addition to P(*a*) and P(*b*), allows us to calculate
    P(*b | a*). This is helpful, because knowing the conditional probability of a
    visible effect given an unknown cause, P(*visible effect | unknown cause*), allows
    us to calculate the probability of the unknown cause given the visible effect,
    P(*unknown cause | visible effect*). For example, we can learn P(*medical test
    results | disease*) through medical trials, where we test people with the disease
    and see how often the test picks up on that. Knowing this, we can calculate P(*disease
    | medical test results*), which is valuable diagnostic information.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 知道P(*a | b*)，除了P(*a*)和P(*b*)，我们可以计算P(*b | a*)。这很有帮助，因为知道在未知原因给定的情况下可见效果的条件下概率，P(*visible
    effect | unknown cause*)，允许我们计算给定可见效果的未知原因的概率，P(*unknown cause | visible effect*)。例如，我们可以通过医学试验学习P(*medical
    test results | disease*)，在试验中测试患有疾病的人，看看测试有多频繁地检测到这一点。了解这一点后，我们可以计算P(*disease
    | medical test results*)，这是有价值的诊断信息。
- en: Joint Probability
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联合概率
- en: Joint probability is the likelihood of multiple events all occurring.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 联合概率是多个事件同时发生的可能性。
- en: Let us consider the following example, concerning the probabilities of clouds
    in the morning and rain in the afternoon.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下例子，关于早晨有云和下午下雨的概率。
- en: '| C = *cloud* | C = *¬cloud* |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| C = *云* | C = *¬云* |'
- en: '| --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0.4 | 0.6 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 0.4 | 0.6 |'
- en: '| R = *rain* | R = *¬rain* |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| R = *雨* | R = *¬雨* |'
- en: '| --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0.1 | 0.9 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 0.1 | 0.9 |'
- en: 'Looking at these data, we can’t say whether clouds in the morning are related
    to the likelihood of rain in the afternoon. To be able to do so, we need to look
    at the joint probabilities of all the possible outcomes of the two variables.
    We can represent this in a table as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 观察这些数据，我们无法说早晨的云与下午下雨的可能性有关。要能够做到这一点，我们需要查看两个变量所有可能结果的联合概率。我们可以用以下表格表示：
- en: '|   | R = *rain* | R = *¬rain* |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|   | R = *雨* | R = *¬雨* |'
- en: '| --- | --- | --- |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| C = *cloud* | 0.08 | 0.32 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| C = *云* | 0.08 | 0.32 |'
- en: '| C = *¬cloud* | 0.02 | 0.58 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| C = *¬云* | 0.02 | 0.58 |'
- en: Now we are able to know information about the co-occurrence of the events. For
    example, we know that the probability of a certain day having clouds in the morning
    and rain in the afternoon is 0.08\. The probability of no clouds in the morning
    and no rain in the afternoon is 0.58.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够了解事件共现的信息。例如，我们知道某一天早晨有云和下午下雨的概率是 0.08。早晨无云和下午无雨的概率是 0.58。
- en: 'Using joint probabilities, we can deduce conditional probability. For example,
    if we are interested in the probability distribution of clouds in the morning
    given rain in the afternoon. P(*C | rain*) = P(*C, rain*)/P(*rain*) (a side note:
    in probability, commas and ∧ are used interchangeably). Thus, P(*C, rain*) = P(*C
    ∧ rain*)). In words, we divide the joint probability of rain and clouds by the
    probability of rain.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用联合概率，我们可以推导出条件概率。例如，如果我们对下午下雨时早晨有云的概率分布感兴趣。P(*C | 雨*) = P(*C, 雨*)/P(*雨*)（顺便提一下：在概率论中，逗号和
    ∧ 可以互换使用）。因此，P(*C, 雨*) = P(*C ∧ 雨*)。换句话说，我们将雨和云的联合概率除以雨的概率。
- en: In the last equation, it is possible to view P(*rain*) as some constant by which
    P(*C, rain*) is multiplied. Thus, we can rewrite P(*C, rain*)/P(*rain*) = αP(*C,
    rain*), or α<0.08, 0.02>. Factoring out α leaves us with the proportions of the
    probabilities of the possible values of C given that there is rain in the afternoon.
    Namely, if there is rain in the afternoon, the proportion of the probabilities
    of clouds in the morning and no clouds in the morning is 0.08:0.02\. Note that
    0.08 and 0.02 don’t sum up to 1; however, since this is the probability distribution
    for the random variable C, we know that they should sum up to 1\. Therefore, we
    need to normalize the values by computing α such that α0.08 + α0.02 = 1\. Finally,
    we can say that P(*C | rain*) = <0.8, 0.2>.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个方程中，我们可以将 P(*雨*) 视为一个常数，它乘以 P(*C, 雨*)。因此，我们可以重写 P(*C, 雨*)/P(*雨*) = αP(*C,
    雨*)，或 α<0.08, 0.02>。提取 α 后，我们得到在下午下雨的条件下 C 的可能值的概率比例。也就是说，如果下午下雨，早晨有云和早晨无云的概率比例是
    0.08:0.02。请注意，0.08 和 0.02 的和并不等于 1；然而，由于这是随机变量 C 的概率分布，我们知道它们的和应该等于 1。因此，我们需要通过计算
    α 来归一化这些值，使得 α0.08 + α0.02 = 1。最后，我们可以说 P(*C | 雨*) = <0.8, 0.2>。
- en: Probability Rules
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率规则
- en: '**Negation**: P(*¬a*) = 1 - P(*a*). This stems from the fact that the sum of
    the probabilities of all the possible worlds is 1, and the complementary literals
    *a* and *¬a* include all the possible worlds.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**否定**: P(*¬a*) = 1 - P(*a*). 这源于所有可能世界的概率之和为1，互补命题 *a* 和 *¬a* 包括所有可能世界。'
- en: '**Inclusion-Exclusion**: P(*a ∨ b*) = P(*a*) + P(*b*) - P(*a ∧ b*). This can
    interpreted in the following way: the worlds in which *a* or *b* are true are
    equal to all the worlds where *a* is true, plus the worlds where *b* is true.
    However, in this case, some worlds are counted twice (the worlds where both *a*
    and *b* are true)). To get rid of this overlap, we subtract once the worlds where
    both *a* and *b* are true (since they were counted twice).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包含-排除**: P(*a ∨ b*) = P(*a*) + P(*b*) - P(*a ∧ b*). 这可以这样解释：*a* 或 *b* 为真的世界等于所有
    *a* 为真的世界，加上所有 *b* 为真的世界。然而，在这种情况下，一些世界被计算了两次（即 *a* 和 *b* 都为真的世界）。为了消除这种重叠，我们减去一次
    *a* 和 *b* 都为真的世界（因为它们被计算了两次）。'
- en: Here is an example from outside lecture that can elucidate this. Suppose I eat
    ice cream 80% of days and cookies 70% of days. If we’re calculating the probability
    that today I eat ice cream or cookies P(*ice cream ∨ cookies*) without subtracting
    P(*ice cream ∧ cookies*), we erroneously end up with ~~0.7 + 0.8 = 1.5~~. This
    contradicts the axiom that probability ranges between 0 and 1\. To correct for
    counting twice the days when I ate both ice cream and cookies, we need to subtract
    P(*ice cream ∧ cookies*) once.
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里有一个来自课堂外部的例子可以阐明这一点。假设我80%的日子里吃冰淇淋，70%的日子里吃饼干。如果我们计算今天我吃冰淇淋或饼干的概率 P(*ice cream
    ∨ cookies*) 而不减去 P(*ice cream ∧ cookies*)，我们会错误地得到 0.7 + 0.8 = 1.5。这与概率范围在 0 到
    1 之间的公理相矛盾。为了纠正重复计算我同时吃冰淇淋和饼干的日子，我们需要减去一次 P(*ice cream ∧ cookies*)。
- en: '**Marginalization**: P(*a*) = P(*a, b*) + P(*a, ¬b*). The idea here is that
    *b* and *¬b* are disjoint probabilities. That is, the probability of *b* and *¬b*
    occurring at the same time is 0\. We also know *b* and *¬b* sum up to 1\. Thus,
    when *a* happens, *b* can either happen or not. When we take the probability of
    both *a* and *b* happening in addition to the probability of *a* and *¬b*, we
    end up with simply the probability of *a*.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边缘化**: P(*a*) = P(*a, b*) + P(*a, ¬b*). 这里面的想法是 *b* 和 *¬b* 是互斥的概率。也就是说，*b*
    和 *¬b* 同时发生的概率是 0。我们还知道 *b* 和 *¬b* 的总和为 1。因此，当 *a* 发生时，*b* 要么发生，要么不发生。当我们考虑 *a*
    和 *b* 同时发生的概率，以及 *a* 和 *¬b* 同时发生的概率，我们最终得到的就是 *a* 的概率。'
- en: 'Marginalization can be expressed for random variables the following way:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘化可以用以下方式表示随机变量：
- en: '![Marginalization](../Images/f16133fa0d9aad9784df103985812661.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![边缘化](../Images/f16133fa0d9aad9784df103985812661.png)'
- en: The left side of the equation means “The probability of random variable X having
    the value xᵢ.” For example, for the variable C we mentioned earlier, the two possible
    values are *clouds in the morning* and *no clouds in the morning*. The right part
    of the equation is the idea of marginalization. P(*X = xᵢ*) is equal to the sum
    of all the joint probabilities of xᵢ and every single value of the random variable
    Y. For example, P(*C = cloud*) = P(*C = cloud, R = rain*) + P(*C = cloud, R =
    ¬rain*) = 0.08 + 0.32 = 0.4.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式的左边表示“随机变量 X 取值 xᵢ 的概率。”例如，对于前面提到的变量 C，可能的两个值是“早上有云”和“早上无云”。方程式的右边是边缘化的概念。P(*X
    = xᵢ*) 等于 xᵢ 和随机变量 Y 的每个值的联合概率之和。例如，P(*C = cloud*) = P(*C = cloud, R = rain*)
    + P(*C = cloud, R = ¬rain*) = 0.08 + 0.32 = 0.4。
- en: '**Conditioning**: P(*a*) = P(*a | b*)P(*b*) + P(*a | ¬b*)P(*¬b*). This is a
    similar idea to marginalization. The probability of event *a* occurring is equal
    to the probability of *a* given *b* times the probability of *b*, plus the probability
    of *a* given *¬b* time the probability of *¬b*.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件化**: P(*a*) = P(*a | b*)P(*b*) + P(*a | ¬b*)P(*¬b*). 这与边缘化有类似的想法。事件 *a*
    发生的概率等于 *a* 在 *b* 条件下的概率乘以 *b* 的概率，加上 *a* 在 *¬b* 条件下的概率乘以 *¬b* 的概率。'
- en: '![Conditioning](../Images/eff11ee634038b28e8728fea53276b00.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![条件化](../Images/eff11ee634038b28e8728fea53276b00.png)'
- en: In this formula, the random variable X takes the value xᵢ with probability that
    is equal to the sum of the probabilities of xᵢ given each value of the random
    variable Y multiplied by the probability of variable Y taking that value. This
    makes sense if we remember that P(*a | b*) = P(*a, b*)/P(*b*). If we multiply
    this expression by P(*b*), we end up with P(*a, b*), and from here we do the same
    as we did with marginalization.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，随机变量 X 以 xᵢ 的值出现，其概率等于 xᵢ 在每个随机变量 Y 的值下的概率之和乘以变量 Y 取该值的概率。如果我们记住 P(*a
    | b*) = P(*a, b*)/P(*b*)，这个公式是有意义的。如果我们乘以 P(*b*)，我们最终得到 P(*a, b*)，然后我们就可以像边缘化一样做了。
- en: Bayesian Networks
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贝叶斯网络
- en: 'A Bayesian network is a data structure that represents the dependencies among
    random variables. Bayesian networks have the following properties:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯网络是一种表示随机变量之间依赖关系的数据结构。贝叶斯网络具有以下特性：
- en: They are directed graphs.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是有向图。
- en: Each node on the graph represent a random variable.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表上的每个节点代表一个随机变量。
- en: An arrow from X to Y represents that X is a parent of Y. That is, the probability
    distribution of Y depends on the value of X.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 X 到 Y 的箭头表示 X 是 Y 的父节点。也就是说，Y 的概率分布取决于 X 的值。
- en: Each node X has probability distribution P(*X | Parents(X)*).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个节点 X 都有概率分布 P(*X | Parents(X)*)。
- en: Let’s consider an example of a Bayesian network that involves variables that
    affect whether we get to our appointment on time.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个涉及影响我们是否准时到达约会的时间的贝叶斯网络的例子。
- en: '![Bayesian Network](../Images/6f5cda1e10d03dac442fc6b714c0d513.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯网络](../Images/6f5cda1e10d03dac442fc6b714c0d513.png)'
- en: 'Let’s describe this Bayesian network from the top down:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从上到下描述这个贝叶斯网络：
- en: 'Rain is the root node in this network. This means that its probability distribution
    is not reliant on any prior event. In our example, Rain is a random variable that
    can take the values {*none, light, heavy*} with the following probability distribution:'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雨是网络中的根节点。这意味着它的概率分布不依赖于任何先前事件。在我们的例子中，Rain是一个可以取值 {*none, light, heavy*} 的随机变量，其概率分布如下：
- en: '| *none* | *light* | *heavy* |'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *none* | *light* | *heavy* |'
- en: '| --- | --- | --- |'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0.7 | 0.2 | 0.1 |'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0.7 | 0.2 | 0.1 |'
- en: Maintenance, in our example, encodes whether there is train track maintenance,
    taking the values {*yes, no*}. Rain is a parent node of Maintenance, which means
    that the probability distribution of Maintenance is affected by Rain.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们的例子中，Maintenance 编码是否存在火车轨道维护，取值有 {*yes, no*}。Rain 是 Maintenance 的父节点，这意味着
    Maintenance 的概率分布受 Rain 影响。
- en: '| R | *yes* | *no* |'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| R | *yes* | *no* |'
- en: '| --- | --- | --- |'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| *none* | 0.4 | 0.6 |'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *none* | 0.4 | 0.6 |'
- en: '| *light* | 0.2 | 0.8 |'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *light* | 0.2 | 0.8 |'
- en: '| *heavy* | 0.1 | 0.9 |'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *heavy* | 0.1 | 0.9 |'
- en: Train is the variable that encodes whether the train is on time or delayed,
    taking the values {*on time, delayed*}. Note that Train has arrows pointing to
    it from both Maintenance and Rain. This means that both are parents of Train,
    and their values affect the probability distribution of Train.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Train 是一个变量，表示火车是否准时或延误，取值有 {*on time, delayed*}。请注意，Train 从 Maintenance 和 Rain
    两处都有箭头指向它。这意味着它们都是 Train 的父节点，它们的值会影响 Train 的概率分布。
- en: '| R | M | *on time* | *delayed* |'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| R | M | *on time* | *delayed* |'
- en: '| --- | --- | --- | --- |'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| *none* | yes | 0.8 | 0.2 |'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *none* | yes | 0.8 | 0.2 |'
- en: '| *none* | no | 0.9 | 0.1 |'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *none* | no | 0.9 | 0.1 |'
- en: '| *light* | yes | 0.6 | 0.4 |'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *light* | yes | 0.6 | 0.4 |'
- en: '| *light* | no | 0.7 | 0.3 |'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *light* | no | 0.7 | 0.3 |'
- en: '| *heavy* | yes | 0.4 | 0.6 |'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *heavy* | yes | 0.4 | 0.6 |'
- en: '| *heavy* | no | 0.5 | 0.5 |'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *heavy* | no | 0.5 | 0.5 |'
- en: 'Appointment is a random variable that represents whether we attend our appointment,
    taking the values {*attend, miss*}. Note that its only parent is Train. This point
    about Bayesian network is noteworthy: parents include only direct relations. It
    is true that maintenance affects whether the train is on time, and whether the
    train is on time affects whether we attend the appointment. However, in the end,
    what directly affects our chances of attending the appointment is whether the
    train came on time, and this is what is represented in the Bayesian network. For
    example, if the train came on time, it could be heavy rain and track maintenance,
    but that has no effect over whether we made it to our appointment.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约会是一个随机变量，表示我们是否参加约会，取值有 {*attend, miss*}。请注意，它的唯一父节点是Train。关于贝叶斯网络的一个值得注意的点：父节点只包括直接关系。确实，维护会影响火车是否准时，火车是否准时会影响我们是否参加约会。然而，最终直接影响我们参加约会机会的是火车是否准时到达，这正是贝叶斯网络所表示的。例如，如果火车准时到达，可能是大雨和轨道维护，但这对我们是否到达约会没有影响。
- en: '| T | *attend* | *miss* |'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| T | *attend* | *miss* |'
- en: '| --- | --- | --- |'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| *on time* | 0.9 | 0.1 |'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *on time* | 0.9 | 0.1 |'
- en: '| *delayed* | 0.6 | 0.4 |'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *delayed* | 0.6 | 0.4 |'
- en: 'For example, if we want to find the probability of missing the meeting when
    the train was delayed on a day with no maintenance and light rain, or P(*light,
    no, delayed, miss*), we will compute the following: P(*light*)P(*no | light*)P(*delayed
    | light, no*)P(*miss | delayed*). The value of each of the individual probabilities
    can be found in the probability distributions above, and then these values are
    multiplied to produce P(*no, light, delayed, miss*).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想找到在无维护和轻雨天气下火车延误时错过会议的概率，或者 P(*light, no, delayed, miss*)，我们将计算以下内容：P(*light*)P(*no
    | light*)P(*delayed | light, no*)P(*miss | delayed*)。每个单独概率的值可以在上面的概率分布中找到，然后这些值相乘以产生
    P(*no, light, delayed, miss*)。
- en: '**Inference**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理**'
- en: At the last lecture, we looked at inference through entailment. This means that
    we could definitively conclude new information based on the information that we
    already had. We can also infer new information based on probabilities. While this
    does not allow us to know new information for certain, it allows us to figure
    out the probability distributions for some values. Inference has multiple properties.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一堂课中，我们探讨了通过蕴涵进行推理。这意味着我们可以根据我们已有的信息确定性地得出新的信息。我们也可以根据概率推断新的信息。虽然这并不允许我们确定地知道新的信息，但它允许我们找出某些值的概率分布。推理具有多个属性。
- en: 'Query **X**: the variable for which we want to compute the probability distribution.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询**X**：我们想要计算概率分布的变量。
- en: 'Evidence variables **E**: one or more variables that have been observed for
    event **e**. For example, we might have observed that there is light rain, and
    this observation helps us compute the probability that the train is delayed.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证据变量**E**：对于事件**e**已经观察到的变量。例如，我们可能观察到有轻微降雨，这个观察结果有助于我们计算火车延误的概率。
- en: 'Hidden variables **Y**: variables that aren’t the query and also haven’t been
    observed. For example, standing at the train station, we can observe whether there
    is rain, but we can’t know if there is maintenance on the track further down the
    road. Thus, Maintenance would be a hidden variable in this situation.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏变量**Y**：不是查询且尚未观察到的变量。例如，站在火车站，我们可以观察到是否有雨，但我们无法知道道路上是否有轨道维护。因此，在这种情况下，Maintenance将是一个隐藏变量。
- en: 'The goal: calculate **P**(*X | e*). For example, compute the probability distribution
    of the Train variable (the query) based on the evidence **e** that we know there
    is light rain.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标：计算**P**(X | e)。例如，根据我们知道有轻微降雨的证据**e**，计算Train变量（查询）的概率分布。
- en: Let’s take an example. We want to compute the probability distribution of the
    Appointment variable given the evidence that there is light rain and no track
    maintenance. That is, we know that there is light rain and no track maintenance,
    and we want to figure out what are the probabilities that we attend the appointment
    and that we miss the appointment, **P**(*Appointment | light, no*). from the [joint
    probability](#joint-probability) section, we know that we can express the possible
    values of the Appointment random variable as a proportion, rewriting **P**(*Appointment
    | light, no*) as αP(*Appointment, light, no*). How can we calculate the probability
    distribution of Appointment if its parent is only the Train variable, and not
    Rain or Maintenance? Here, we will use marginalization. The value of **P**(*Appointment,
    light, no*) is equal to α[**P**(*Appointment, light, no, delayed*) + **P**(*Appointment,
    light, no, on time*)].
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个例子。我们想要计算在已知有轻微降雨且没有轨道维护的证据下，预约变量（Appointment）的概率分布。也就是说，我们知道有轻微降雨且没有轨道维护，我们想要找出我们参加预约和错过预约的概率，即**P**(Appointment
    | light, no)。从[联合概率](#joint-probability)部分，我们知道我们可以将预约随机变量的可能值表示为比例，将**P**(Appointment
    | light, no)重写为 α**P**(Appointment, light, no*)。如果其父变量只有Train变量，而不是Rain或Maintenance，我们该如何计算预约变量的概率分布？在这里，我们将使用边缘化。**P**(Appointment,
    light, no)的值等于 α[**P**(Appointment, light, no, delayed*) + **P**(Appointment,
    light, no, on time*)]。
- en: '**Inference by Enumeration**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**枚举推理**'
- en: Inference by enumeration is a process of finding the probability distribution
    of variable X given observed evidence e and some hidden variables Y.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 枚举推理是一个在给定观察到的证据e和一些隐藏变量Y的情况下寻找变量X的概率分布的过程。
- en: '![Inference by Enumeration](../Images/fae66d8c519d7a9a9ee418baea0ad29b.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![枚举推理](../Images/fae66d8c519d7a9a9ee418baea0ad29b.png)'
- en: In this equation, X stand for the query variable, e for the observed evidence,
    y for all the values of the hidden variables, and α normalizes the result such
    that we end up with probabilities that add up to 1\. To explain the equation in
    words, it is saying that the probability distribution of X given e is equal to
    a normalized probability distribution of X and e. To get to this distribution,
    we sum the normalized probability of X, e, and y, where y takes each time a different
    value of the hidden variables Y.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，X代表查询变量，e代表观察到的证据，y代表所有隐藏变量的值，α将结果归一化，使得我们最终得到的概率加起来等于1。用文字解释这个方程，它表示的是，给定e的X的概率分布等于X和e的归一化概率分布。为了得到这个分布，我们求和X、e和y的归一化概率，其中y每次取隐藏变量Y的不同值。
- en: Multiple libraries exist in Python to ease the process of probabilistic inference.
    We will take a look at the library *pomegranate* to see how the above data can
    be represented in code.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Python中存在多个库来简化概率推理的过程。我们将查看*pomegranate*库，看看如何用代码表示上述数据。
- en: First, we create the nodes and provide a probability distribution for each one.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建节点并为每个节点提供一个概率分布。
- en: '[PRE0]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Second, we create the model by adding all the nodes and then describing which
    node is the parent of which other node by adding edges between them (recall that
    a Bayesian network is a directed graph, consisting of nodes with arrows between
    them).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们通过添加节点并描述它们之间通过添加边连接的节点（回想一下，贝叶斯网络是一个有向图，由带有箭头的节点组成）来创建模型。
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, to ask how probable a certain event is, we run the model with the values
    we are interested in. In this example, we want to ask what is the probability
    that there is no rain, no track maintenance, the train is on time, and we attend
    the meeting.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要询问某个事件的概率，我们使用感兴趣的值运行模型。在这个例子中，我们想知道没有雨、没有轨道维护、火车准时到达，并且我们参加会议的概率。
- en: '[PRE2]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Otherwise, we could use the program to provide probability distributions for
    all variables given some observed evidence. In the following case, we know that
    the train was delayed. Given this information, we compute and print the probability
    distributions of the variables Rain, Maintenance, and Appointment.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，我们可以使用程序为所有变量提供给定一些观察证据的概率分布。在以下情况下，我们知道火车延误了。根据这个信息，我们计算并打印变量Rain、Maintenance和Appointment的概率分布。
- en: '[PRE3]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The code above used inference by enumeration. However, this way of computing
    probability is inefficient, especially when there are many variables in the model.
    A different way to go about this would be abandoning **exact inference** in favor
    of **approximate inference**. Doing this, we lose some precision in the generated
    probabilities, but often this imprecision is negligible. Instead, we gain a scalable
    method of calculating probabilities.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码使用了枚举推理。然而，这种计算概率的方法效率低下，尤其是在模型中有许多变量时。另一种方法可能是放弃**精确推理**而采用**近似推理**。这样做，我们在生成的概率中会失去一些精度，但通常这种不精确是可以忽略不计的。相反，我们获得了一种可扩展的概率计算方法。
- en: Sampling
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 抽样
- en: Sampling is one technique of approximate inference. In sampling, each variable
    is sampled for a value according to its probability distribution. We will start
    with an example from outside lecture, and then cover the example from lecture.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样是近似推理的一种技术。在抽样中，每个变量根据其概率分布抽取一个值。我们将从一个课外例子开始，然后介绍课内的例子。
- en: 'To generate a distribution using sampling with a die, we can roll the die multiple
    times and record what value we got each time. Suppose we rolled the die 600 times.
    We count how many times we got 1, which is supposed to be roughly 100, and then
    repeat for the rest of the values, 2-6\. Then, we divide each count by the total
    number of rolls. This will generate an approximate distribution of the values
    of rolling a die: on one hand, it is unlikely that we get the result that each
    value has a probability of 1/6 of occurring (which is the exact probability),
    but we will get a value that’s close to it.'
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要使用骰子进行抽样生成分布，我们可以多次掷骰子并记录每次得到的结果。假设我们掷了600次骰子。我们计算得到1的次数，预计大约是100次，然后对其他值2-6重复此操作。然后，我们将每个计数除以总掷骰子次数。这将生成掷骰子值的近似分布：一方面，我们不太可能得到每个值都有1/6的概率出现的结果（这是精确概率），但我们会得到一个接近这个值的结果。
- en: 'Here is an example from lecture: if we start with sampling the Rain variable,
    the value *none* will be generated with probability of 0.7, the value *light*
    will be generated with probability of 0.2, and the value *heavy* will be generated
    with probability of 0.1\. Suppose that the sampled value we get is *none*. When
    we get to the Maintenance variable, we sample it, too, but only from the probability
    distribution where Rain is equal to *none*, because this is an already sampled
    result. We will continue to do so through all the nodes. Now we have one sample,
    and repeating this process multiple times generates a distribution. Now, if we
    want to answer a question, such as what is P(*Train = on time*), we can count
    the number of samples where the variable Train has the value *on time*, and divide
    the result by the total number of samples. This way, we have just generated an
    approximate probability for P(*Train = on time*).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个来自讲座的例子：如果我们从采样 Rain 变量开始，将生成概率为 0.7 的 *无* 值，概率为 0.2 的 *轻微* 值，以及概率为 0.1
    的 *严重* 值。假设我们得到的采样值是 *无*。当我们到达 Maintenance 变量时，我们也对其进行采样，但只从 Rain 等于 *无* 的概率分布中进行采样，因为这是一个已经采样的结果。我们将继续这样做，直到所有节点。现在我们有一个样本，重复这个过程多次生成一个分布。现在，如果我们想回答一个问题，比如
    P(*Train = on time*) 是什么，我们可以计算变量 Train 有 *准时* 值的样本数量，然后将结果除以样本总数。这样，我们就为 P(*Train
    = on time*) 生成了一个近似概率。
- en: We can also answer questions that involve conditional probability, such as P(*Rain
    = light | Train = on time*). In this case, we ignore all samples where the value
    of Train is not *on time*, and then proceed as before. We count how many samples
    have the variable Rain = *light* among those samples that have Train = *on time*,
    and then divide by the total number of samples where Train = *on time*.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以回答涉及条件概率的问题，例如 P(*Rain = light | Train = on time*)。在这种情况下，我们忽略所有 Train
    值不是 *准时* 的样本，然后像以前一样进行。我们计算在 Train = *准时* 的样本中，变量 Rain = *轻微* 的样本数量，然后除以 Train
    = *准时* 的样本总数。
- en: 'In code, a sampling function can look like `generate_sample`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，一个采样函数可以看起来像 `generate_sample`：
- en: '[PRE4]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, to compute P(*Appointment | Train = delayed*), which is the probability
    distribution of the Appointment variable given that the train is delayed, we do
    the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了计算 P(*Appointment | Train = delayed*)，即火车延误时 Appointment 变量的概率分布，我们做以下操作：
- en: '[PRE5]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Likelihood Weighting**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**似然加权**'
- en: 'In the sampling example above, we discarded the samples that did not match
    the evidence that we had. This is inefficient. One way to get around this is with
    likelihood weighting, using the following steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的采样例子中，我们丢弃了不符合我们已有证据的样本。这是低效的。一种绕过这个问题的方法是通过似然加权，使用以下步骤：
- en: Start by fixing the values for evidence variables.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先固定证据变量的值。
- en: Sample the non-evidence variables using conditional probabilities in the Bayesian
    network.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用贝叶斯网络中的条件概率采样非证据变量。
- en: 'Weight each sample by its **likelihood**: the probability of all the evidence
    occurring.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将每个样本按其 **似然** 加权：所有证据发生的概率。
- en: For example, if we have the observation that the train was on time, we will
    start sampling as before. We sample a value of Rain given its probability distribution,
    then Maintenance, but when we get to Train - we always give it the observed value,
    in our case, *on time*. Then we proceed and sample Appointment based on its probability
    distribution given Train = *on time*. Now that this sample exists, we weight it
    by the conditional probability of the observed variable given its sampled parents.
    That is, if we sampled Rain and got *light*, and then we sampled Maintenance and
    got *yes*, then we will weight this sample by P(*Train = on time | light, yes*).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们观察到火车准时到达，我们就会像以前一样开始采样。我们根据其概率分布采样 Rain 的值，然后是 Maintenance，但当到达 Train
    时，我们总是给出观察到的值，在我们的例子中，是 *准时*。然后我们继续根据 Train = *准时* 给定的概率分布采样 Appointment。现在这个样本存在了，我们根据观察变量给定的条件概率来加权。也就是说，如果我们采样了
    Rain 并得到 *轻微*，然后采样 Maintenance 并得到 *是*，那么我们将对这个样本进行加权，权重为 P(*Train = on time |
    light, yes*)。
- en: Markov Models
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 马尔可夫模型
- en: So far, we have looked at questions of probability given some information that
    we observed. In this kind of paradigm, the dimension of time is not represented
    in any way. However, many tasks do rely on the dimension of time, such as prediction.
    To represent the variable of time we will create a new variable, X, and change
    it based on the event of interest, such that Xₜ is the current event, Xₜ₊₁ is
    the next event, and so on. To be able to predict events in the future, we will
    use Markov Models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑了一些基于我们观察到的某些信息的概率问题。在这种范式下，时间维度没有以任何方式表示。然而，许多任务确实依赖于时间维度，例如预测。为了表示时间变量，我们将创建一个新的变量X，并根据感兴趣的事件对其进行更改，使得Xₜ是当前事件，Xₜ₊₁是下一个事件，依此类推。为了能够预测未来的事件，我们将使用马尔可夫模型。
- en: '**The Markov Assumption**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**马尔可夫假设**'
- en: The Markov assumption is an assumption that the current state depends on only
    a finite fixed number of previous states. This is important to us. Think of the
    task of predicting weather. In theory, we could use all the data from the past
    year to predict tomorrow’s weather. However, it is infeasible, both because of
    the computational power this would require and because there is probably no information
    about the conditional probability of tomorrow’s weather based on the weather 365
    days ago. Using the Markov assumption, we restrict our previous states (e.g. how
    many previous days we are going to consider when predicting tomorrow’s weather),
    thereby making the task manageable. This means that we might get a more rough
    approximation of the probabilities of interest, but this is often good enough
    for our needs. Moreover, we can use a Markov model based on the information of
    the one last event (e.g. predicting tomorrow’s weather based on today’s weather).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫假设是一个假设，即当前状态只依赖于有限数量的先前状态。这对我们来说很重要。想想预测天气的任务。在理论上，我们可以使用过去一年的所有数据来预测明天的天气。然而，这是不可行的，因为这需要巨大的计算能力，而且可能没有关于基于365天前的天气明天天气的条件概率的信息。使用马尔可夫假设，我们限制我们的先前状态（例如，在预测明天的天气时考虑多少天前的天气），从而使任务变得可管理。这意味着我们可能得到对感兴趣概率的更粗糙的近似，但这通常足以满足我们的需求。此外，我们可以使用基于最后一个事件的信息的马尔可夫模型（例如，根据今天的天气预测明天的天气）。
- en: '**Markov Chain**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**马尔可夫链**'
- en: A Markov chain is a sequence of random variables where the distribution of each
    variable follows the Markov assumption. That is, each event in the chain occurs
    based on the probability of the event before it.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链是一系列随机变量，其中每个变量的分布遵循马尔可夫假设。也就是说，链中的每个事件都是基于之前事件发生的概率。
- en: To start constructing a Markov chain, we need a **transition model** that will
    specify the the probability distributions of the next event based on the possible
    values of the current event.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建马尔可夫链，我们需要一个**转移模型**，该模型将指定基于当前事件可能值的下一个事件的概率分布。
- en: '![Transition Model](../Images/02c1ff11b8f76b491b14bcf0634aae7f.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![过渡模型](../Images/02c1ff11b8f76b491b14bcf0634aae7f.png)'
- en: 'In this example, the probability of tomorrow being sunny based on today being
    sunny is 0.8\. This is reasonable, because it is more likely than not that a sunny
    day will follow a sunny day. However, if it is rainy today, the probability of
    rain tomorrow is 0.7, since rainy days are more likely to follow each other. Using
    this transition model, it is possible to sample a Markov chain. Start with a day
    being either rainy or sunny, and then sample the next day based on the probability
    of it being sunny or rainy given the weather today. Then, condition the probability
    of the day after tomorrow based on tomorrow, and so on, resulting in a Markov
    chain:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，如果今天是晴天，那么明天也是晴天的概率是0.8。这是合理的，因为晴天之后接着是晴天的可能性更大。然而，如果今天是雨天，那么明天下雨的概率是0.7，因为雨天更有可能连续出现。使用这个转移模型，可以采样一个马尔可夫链。从一个雨天或晴天开始，然后根据今天天气是晴天还是雨天来采样下一天。然后，根据明天的情况来调整后天概率，依此类推，从而形成一个马尔可夫链：
- en: '![Markov Chain](../Images/33e9dec509c66164093b95d786019dd2.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![马尔可夫链](../Images/33e9dec509c66164093b95d786019dd2.png)'
- en: 'Given this Markov chain, we can now answer questions such as “what is the probability
    of having four rainy days in a row?” Here is an example of how a Markov chain
    can be implemented in code:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这个马尔可夫链，我们现在可以回答诸如“连续四天降雨的概率是多少？”等问题。以下是一个如何在代码中实现马尔可夫链的示例：
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Hidden Markov Models
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型
- en: 'A hidden Markov model is a type of a Markov model for a system with hidden
    states that generate some observed event. This means that sometimes, the AI has
    some measurement of the world but no access to the precise state of the world.
    In these cases, the state of the world is called the **hidden state** and whatever
    data the AI has access to are the **observations**. Here are a few examples for
    this:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型是一种针对具有隐藏状态的系统的马尔可夫模型，这些状态生成某些观测事件。这意味着有时，AI 对世界有一些测量，但没有访问世界精确状态的途径。在这些情况下，世界的状态被称为**隐藏状态**，而AI可以访问的任何数据都是**观测**。以下是一些例子：
- en: For a robot exploring uncharted territory, the hidden state is its position,
    and the observation is the data recorded by the robot’s sensors.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于探索未知领域的机器人，隐藏状态是它的位置，而观测是机器人传感器记录的数据。
- en: In speech recognition, the hidden state is the words that were spoken, and the
    observation is the audio waveforms.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在语音识别中，隐藏状态是所说的单词，而观测是音频波形。
- en: When measuring user engagement on websites, the hidden state is how engaged
    the user is, and the observation is the website or app analytics.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在测量网站上的用户参与度时，隐藏状态是用户的参与程度，而观测是网站或应用的统计分析。
- en: 'For our discussion, we will use the following example. Our AI wants to infer
    the weather (the hidden state), but it only has access to an indoor camera that
    records how many people brought umbrellas with them. Here is our **sensor model**
    (also called **emission model**) that represents these probabilities:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的讨论，我们将使用以下例子。我们的AI想要推断天气（隐藏状态），但它只能访问一个室内摄像头，该摄像头记录了有多少人带着伞。以下是我们的**传感器模型**（也称为**发射模型**），它表示这些概率：
- en: '![Sensor Model](../Images/807a4fc8eb5bb432577d55934b18fe77.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![传感器模型](../Images/807a4fc8eb5bb432577d55934b18fe77.png)'
- en: In this model, if it is sunny, it is most probable that people will not bring
    umbrellas to the building. If it is rainy, then it is very likely that people
    bring umbrellas to the building. By using the observation of whether people brought
    an umbrella or not, we can predict with reasonable likelihood what the weather
    is outside.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，如果天气晴朗，人们最不可能带伞进建筑物。如果下雨，那么人们很可能带伞进建筑物。通过观察人们是否带伞，我们可以以合理的可能性预测外面的天气。
- en: '**Sensor Markov Assumption**'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**传感器马尔可夫假设**'
- en: The assumption that the evidence variable depends only on the corresponding
    state. For example, for our models, we assume that whether people bring umbrellas
    to the office depends only on the weather. This is not necessarily reflective
    of the complete truth, because, for example, more conscientious, rain-averse people
    might take an umbrella with them everywhere even when it is sunny, and if we knew
    everyone’s personalities it would add more data to the model. However, the sensor
    Markov assumption ignores these data, assuming that only the hidden state affects
    the observation.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 假设证据变量只依赖于对应的状态。例如，对于我们的模型，我们假设人们是否带伞去办公室只取决于天气。这并不一定反映完整的真相，因为例如，更负责任、怕雨的人即使在晴天也可能随身携带伞，如果我们知道每个人的性格，这将向模型添加更多数据。然而，传感器马尔可夫假设忽略了这些数据，假设只有隐藏状态影响观测。
- en: A hidden Markov model can be represented in a Markov chain with two layers.
    The top layer, variable X, stands for the hidden state. The bottom layer, variable
    E, stands for the evidence, the observations that we have.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏马尔可夫模型可以用具有两层马尔可夫链来表示。顶层变量X代表隐藏状态。底层变量E代表证据，即我们拥有的观测。
- en: '![Hidden Markov Chain](../Images/85559a1ad1374bfd81aa2f164ac0eb6e.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![隐藏马尔可夫链](../Images/85559a1ad1374bfd81aa2f164ac0eb6e.png)'
- en: 'Based on hidden Markov models, multiple tasks can be achieved:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 基于隐藏马尔可夫模型，可以实现多个任务：
- en: 'Filtering: given observations from start until now, calculate the probability
    distribution for the current state. For example, given information on when people
    bring umbrellas form the start of time until today, we generate a probability
    distribution for whether it is raining today or not.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤：给定从开始到现在的观测，计算当前状态的概率分布。例如，给定从时间开始到今天人们带伞的信息，我们生成今天是否下雨的概率分布。
- en: 'Prediction: given observations from start until now, calculate the probability
    distribution for a future state.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测：给定从开始到现在的观测，计算未来状态的概率分布。
- en: 'Smoothing: given observations from start until now, calculate the probability
    distribution for a past state. For example, calculating the probability of rain
    yesterday given that people brought umbrellas today.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑化：给定从开始到现在的观察结果，计算过去状态的概率分布。例如，计算给定今天人们带伞的情况下，昨天下雨的概率。
- en: 'Most likely explanation: given observations from start until now, calculate
    most likely sequence of events.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最可能的解释：给定从开始到现在的观察结果，计算最可能的事件序列。
- en: 'The most likely explanation task can be used in processes such as voice recognition,
    where, based on multiple waveforms, the AI infers the most likely sequence of
    words or syllables that brought to these waveforms. Next is a Python implementation
    of a hidden Markov model that we will use for a most likely explanation task:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最可能的解释任务可以用于语音识别等过程，其中，基于多个波形，AI推断出最可能导致这些波形的单词或音节的序列。下面是一个用于最可能解释任务的隐马尔可夫模型的Python实现：
- en: '[PRE7]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note that our model has both the sensor model and the transition model. We
    need both for the hidden Markov model. In the following code snippet, we see a
    sequence of observations of whether people brought umbrellas to the building or
    not, and based on this sequence we will run the model, which will generate and
    print the most likely explanation (i.e. the weather sequence that most likely
    brought to this pattern of observations):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的模型既有传感器模型也有转换模型。对于隐马尔可夫模型，我们需要这两个模型。在下面的代码片段中，我们看到一系列观察结果，即人们是否带伞进入大楼，基于这个序列，我们将运行模型，该模型将生成并打印最可能的解释（即最可能导致这种观察模式的天气序列）：
- en: '[PRE8]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this case, the output of the program will be rain, rain, sun, rain, rain,
    rain, rain, sun, sun. This output represents what is the most likely pattern of
    weather given our observations of people bringing or not bringing umbrellas to
    the building.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，程序的输出将是雨，雨，晴，雨，雨，雨，雨，晴，晴。这个输出代表了根据我们对人们是否带伞进入大楼的观察，最可能的天气模式。
