- en: 9.5\. NUMERICAL LINEAR ALGEBRA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9.5\. 数值线性代数
- en: 原文：[https://introcs.cs.princeton.edu/java/95linear](https://introcs.cs.princeton.edu/java/95linear)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://introcs.cs.princeton.edu/java/95linear](https://introcs.cs.princeton.edu/java/95linear)
- en: This section under major construction.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本节正在大力施工中。
- en: '[Java numerics](http://math.nist.gov/javanumerics/) provides a focal point
    for information on numerical computing in Java.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Java数值计算](http://math.nist.gov/javanumerics/)提供了关于Java中数值计算的信息的焦点。'
- en: '**Linear algebra.** Computer science applications: wavelets, transformations
    in computer graphics, computer vision, Google''s PageRank algorithm, linear programming,
    linear regression, Markov chains. Other applications: linear and nonlinear optimization,
    control theory, combinatorial optimization, numerical solutions to ODEs, analysis
    of electrical networks, portfolio optimization, qunatum mechanics. Desire to solve
    such problems has driven the development of computing technology. BLAS.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性代数。** 计算机科学应用：小波、计算机图形学中的变换、计算机视觉、谷歌的PageRank算法、线性规划、线性回归、马尔可夫链。其他应用：线性和非线性优化、控制理论、组合优化、常微分方程的数值解、电气网络分析、投资组合优化、量子力学。解决这些问题的愿望推动了计算技术的发展。BLAS。'
- en: '**Matrix.** In numerical linear algebra, a *matrix* is a rectangular table
    of real or complex numbers. Given a matrix A, we use the notation A[ij] to represent
    the entry in the ith row and the jth column. We can implement a matrix in Java
    by using a two dimensional array. We access A[ij] using `A[i][j]`. We begin indexing
    at 0 to conform to Java indexing conventions.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵。** 在数值线性代数中，*矩阵*是一个实数或复数的矩形表。给定矩阵A，我们使用符号A[ij]表示第i行和第j列的条目。我们可以通过使用二维数组在Java中实现矩阵。我们使用`A[i][j]`访问A[ij]。我们从0开始索引以符合Java索引约定。'
- en: '**Matrix multiplication.** The product of two N-by-N matrices A and B is an
    N-by-N matrix C defined by'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵乘法。** 两个N×N矩阵A和B的乘积是一个N×N矩阵C，定义为'
- en: '![Matrix multiplication](../Images/04dca913e0c86830217d47b25c278f1b.png)'
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![矩阵乘法](../Images/04dca913e0c86830217d47b25c278f1b.png)'
- en: The following code fragment computes C = AB.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段计算C = AB。
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Row major order vs. column major order.** Can have a huge impact on caching
    and performance. Better to iterate over a row than a column in Java. We can rearrange
    the matrix multiplication triple loop in any of 3! = 6 ways to achieve the same
    answer. Each possibility has different memory access patterns may perform very
    differently (2-3 times) depending on machine architecture since (caching, paging,
    etc.). Program [MatrixMultiplication.java](MatrixMultiplication.java.html) performs
    matrix multiplication in each of the 6 orderings, and outputs the amount of time
    it takes. Some architectures have built in gaxpy methods, etc. High performance
    matrix libraries are very carefully tuned to the machine architecture on which
    they are to be run to take full advantage of such effects.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**行主序 vs. 列主序。** 可以对缓存和性能产生巨大影响。在Java中最好迭代一行而不是一列。我们可以以3！= 6种方式重新排列矩阵乘法三重循环以获得相同的答案。每种可能性具有不同的内存访问模式，可能在机器架构（缓存、分页等）上表现非常不同（2-3倍）。程序[MatrixMultiplication.java](MatrixMultiplication.java.html)在6个顺序中执行矩阵乘法，并输出所需的时间。一些架构具有内置的gaxpy方法等。高性能矩阵库非常精心地调整到将要运行的机器架构，以充分利用这些效果。'
- en: '*Micro-optimizations.* Appropriate to consider here since matrix multiplication
    is the bottleneck computation in many applications. We can explicitly cache certain
    rows and columns to make the computation faster. We cache row i of A and column
    j of B. Since Java arrays are row-ordered, we copy the entries in column j of
    B into a 1D array to facilitate future acceses. Why faster? Better memory access
    patterns. Avoids bounds checking. Number of assignment statements now proportional
    to N^2 instead of N^3.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*微优化。* 在许多应用中，矩阵乘法是瓶颈计算，因此在这里考虑是合适的。我们可以明确地缓存某些行和列以加快计算速度。我们缓存A的第i行和B的第j列。由于Java数组是按行排序的，我们将B的第j列的条目复制到一维数组中以便未来访问。为什么更快？更好的内存访问模式。避免边界检查。现在赋值语句的数量与N^2成正比，而不是N^3。'
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Could also improve performance (perhaps by up to a factor of 2) by using 1D
    array of size N² instead of a Java array of arrays. Here's a good [overview](http://www.ii.uib.no/~geirg/NIK2002.pdf)
    of using matrices in Java.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过使用大小为N²的一维数组而不是Java数组的数组来提高性能（可能高达2倍）。这里有一个关于在Java中使用矩阵的[概述](http://www.ii.uib.no/~geirg/NIK2002.pdf)。
- en: '**Systems of linear equations.** One of the most fundamental and important
    problems in linear algebra is finding a solution x to the equation Ax = b. Difference
    equations, interpolation, digital signal processing, least squares, forecasting,
    Leontief model of economic equilibrium, Hooke''s law of elasticity, [traffic analysis](http://aix1.uottawa.ca/~jkhoury/networks.htm),
    [temperature equilibrium of heat in a plate](http://aix1.uottawa.ca/~jkhoury/temp.htm),
    linear and nonlinear optimization.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性方程组。** 线性代数中最基本和重要的���题之一是找到方程Ax = b的解x。差分方程、插值、数字信号处理、最小二乘、预测、经济均衡的Leontief模型、胡克弹性定律、[交通分析](http://aix1.uottawa.ca/~jkhoury/networks.htm)、[板材中的热平衡](http://aix1.uottawa.ca/~jkhoury/temp.htm)、线性和非线性优化。'
- en: '**Kirchoff''s voltage law.** Loop current analysis of [electric circuits](http://aix1.uottawa.ca/~jkhoury/networks.htm).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**基尔霍夫电压定律。** [电路](http://aix1.uottawa.ca/~jkhoury/networks.htm)的环流分析。'
- en: '**Row operations.** Consider the following system of three linear equations
    in three unknowns.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**行操作。** 考虑以下三个未知数的线性方程组。'
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can apply a number of identities to transform the system of equations into
    an equivalent system of equations that is potentially easier to solve. We will
    use transformation of the following two forms.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以应用一些恒等式将方程组转化为一个可能更容易解决的等价方程组。我们将使用以下两种形式的转换。
- en: '*Row interchange.* Interchange any two rows. For example, we can interchange
    the first and second rows above to yield the equivalent system.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*行互换。* 交换任意两行。例如，我们可以交换上面的第一行和第二行以得到等价系统。'
- en: '[PRE3]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Swapping rows i and j in a 2D array is an especially efficient operation in
    Java. We only need to swap the references to the ith and jth rows.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在Java中，交换二维数组中的第i行和第j行是一种特别高效的操作。我们只需要交换第i行和第j行的引用。
- en: '[PRE4]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Linear combination.* Add or subtract a multiple of one row to another row.
    For example, we can subtract three times the second equation from the third to
    obtain yet another equivalent system.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*线性组合。* 将一个行的多倍加或减去另一个行。例如，我们可以从第三个方程中减去第二个方程的三倍，以获得另一个等价系统。'
- en: '[PRE5]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This transformation involves multiplication by a real number, so we may end
    up with real-valued coefficients even if we begin with integer coefficients.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种转换涉及乘以一个实数，因此即使我们从整数系数开始，最终可能得到实数系数。
- en: '**Back-substitution.** The last system of equations above is particularly amenable
    to solution. From the last equation (12 x[2] = 24) we can immediately derive x[2]
    = 2\. Substituting x[2] = 2 into the second equation yields x[1] + 2 = 4\. Now
    we can derive x[1] = 2\. Finally, we can substitute x[1] and x[2] back into the
    first equation. This yields 2x[0] + 4(2) - 2(2) = 2, which implies x[0] = -1.
    This back-substitution procedure is straightforward to express in Java.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**回代法。** 上述最后一个方程组特别适合求解。从最后一个方程（12 x[2] = 24）中，我们可以立即推导出 x[2] = 2。将 x[2] =
    2代入第二个方程中得到 x[1] + 2 = 4。现在我们可以推导出 x[1] = 2。最后，我们可以将 x[1] 和 x[2] 代入第一个方程中。这导致
    2x[0] + 4(2) - 2(2) = 2，这意味着 x[0] = -1。这种回代过程在Java中表达起来很简单。'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Gaussian elimination.** Gaussian elimination is one of the oldest and most
    widely used algorithms for solving linear systems of equations. The algorithm
    was explicitly described by Liu Hui in 263 while presenting solutions to the famous
    Chinese text Jiuzhang suanshu (The Nine Chapters on the Mathematical Art), but
    was probably discovered much earlier. The name Gaussian elimination arose after
    Gauss used it to predict the location of celestial objects using his newly discovered
    method of least squares. Apply row operations to transform original system of
    equations into an upper triangular system. Then use back-substitution.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯消元法。** 高斯消元法是解线性方程组的最古老和最广泛使用的算法之一。该算法由刘徽在263年明确描述，当时他在解释著名的中国文本《九章算术》时提出了解决方案，但实际上可能早在此之前就已被发现。高斯消元法这个名称是在高斯使用它来预测天体位置时产生的，他使用了自己新发现的最小二乘法。对原始方程组应用行操作，将其转换为上三角形式。然后使用回代法。'
- en: '![Gaussian elimination schematic](../Images/9fecd45b65d87b5c2240fe2f69215b3b.png)'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![高斯消元法示意图](../Images/9fecd45b65d87b5c2240fe2f69215b3b.png)'
- en: The following *fantasy* code is a straightforward implementation of Gaussian
    elimination.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下*虚构*代码是高斯消元法的一个简单实现。
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Unfortunately, if one of the pivot elements `A[i][i]` is zero, the code divides
    by zero and fails spectacularly. There are some important applications where we
    are guaranteed never to encounter a zero pivot and get stuck (e.g., if matrix
    is strictly diagonally dominant or symmetric positive definite), but in general,
    we must ensure that zero pivots never occur by interchanging the row containing
    the zero pivot with another row beneath it. If no such row exists, then the system
    either has no solution or it has infinitely many. (See Exercises XYZ and XYZ.)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，如果其中一个主元素`A[i][i]`为零，代码会除以零并失败。有一些重要的应用场景，我们保证永远不会遇到零主元素并陷入困境（例如，如果矩阵严格对角占优或对称正定），但一般情况下，我们必须通过将包含零主元素的行与其下方的另一行交换来确保零主元素永远不会出现。如果没有这样的行存在，则系统要么没有解，要么有无穷多个解。（参见练习XYZ和XYZ。）
- en: '*Partial pivoting.* One common pivot strategy is to select the row that has
    the largest (in absolute value) pivot element, and do this interchange before
    each pivot, regardless of whether we encounter a potential zero pivot. Program
    [GaussianElimination.java](GaussianElimination.java.html) implements Gaussian
    elimination with partial pivoting. This selection rule is known as *partial pivoting*.
    It is widely used because, in addition to fixing the zero pivot problem, it dramatiaclly
    improves the numerical stability of the algorithm. To see its effects, consider
    the following system of equations, where a = 10^(-17).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*部分主元素选取。* 一种常见的主元素选取策略是选择具有最大（绝对值）主元素的行，并在每次主元素选取之前进行交换，无论我们是否遇到潜在的零主元素。程序[GaussianElimination.java](GaussianElimination.java.html)实现了带有部分主元素选取的高斯消元法。这种选择规则被称为*部分主元素选取*。它被广泛使用，因为除了解决零主元素问题外，它还显著提高了算法的数值稳定性。要看到其效果，请考虑以下方程组，其中a
    = 10^(-17)。'
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If we don''t pivot on the largest coefficient, then Gaussian elimination produces
    the solution (x[0], x[1] = (0.0, 1.0), whereas Gaussian elimination with partial
    pivoting yields (1.0, 1.0). The exact answer is (99999999999999997/99999999999999998,
    50000000000000000/49999999999999999). The solution with partial pivoting yields
    16 decimal digits of accuracy while the one without partial pivoting has 0 digits
    of accuracy for x[0]. Although this example was contrived to demonstrate and magnify
    the effect, such situation do arise in practice. This example is a situation where
    the problem instance is well-conditioned, but the algorithm (without partial pivoting)
    is unstable. In this example, the potential problem is resolved by using partial
    pivoting. (See Exercise XYZ for an example where partial pivoting fails even though
    the intance is not ill-conditioned.) Numerical analysts use Gaussian elimination
    with partial pivoting with high confidence even though it is not provably stable.
    When the problem instance itself is ill-conditioned, no floating point algorithm
    will be able to rescue it. To detect such cases, we compute the *condition number*,
    which measures how ill-conditioned a matrix is. # bits in solution ~ # bits in
    data - lg kappa(A)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不在最大系数上选主元，那么高斯消元会产生解（x[0]，x[1] = (0.0, 1.0)，而带部分主元的高斯消元会产生 (1.0, 1.0)。精确答案是
    (99999999999999997/99999999999999998, 50000000000000000/49999999999999999)。带部分主元的解提供了
    16 位小数的精度，而不带部分主元的解对于 x[0] 的精度为 0 位。尽管这个例子是为了演示和放大效果而构造的，但在实践中确实会出现这种情况。这个例子是一个问题实��很好的情况，但算法（不带部分主元）是不稳定的。在这个例子中，通过使用部分主元解决了潜在的问题。
    （参见练习 XYZ，一个例子展示了即使实例不是病态的情况下部分主元也会失败。）数值分析师对带部分主元的高斯消元有很高的信心，尽管它不能被证明是稳定的。当问题实例本身是病态的时候，没有浮点算法能够拯救它。为了检测这种情况，我们计算*条件数*，它衡量矩阵的病态程度。解中的位数约等于数据中的位数
    - lg kappa(A)。
- en: '*Complete pivoting.* Choose pivot element to be the one with largest absolute
    value among entries that still need to be row-reduced. Swap both rows and columns
    (instead of just rows). More bookkeeping and time searching for the pivot, but
    better stability. However, scientists rarely use complete pivoting in practice
    because partial pivoting almost always succeeds.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*完全主元.* 选择主元素为仍需行约化的条目中绝对值最大的条目。交换行和列（而不仅仅是行）。更多的簿记和搜索主元的时间，但更好的稳定性。然而，科学家们在实践中很少使用完全主元，因为部分主元几乎总是成功的。'
- en: 'Gaussian elimination can also be used to compute the rank since row operations
    do not change the rank. Rank of an m-by-n matrix: if you get stuck when pivoting
    in column j, continue to column j+1\. Rank = # nonzero rows upon termination.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯消元法也可用于计算秩，因为行操作不会改变秩。m×n 矩阵的秩：如果在列 j 中选主元时卡住了，就继续到列 j+1。秩 = 终止时非零行数。
- en: '[interesting matrices](http://math.nist.gov/MatrixMarket/) for testing.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[有趣的矩阵](http://math.nist.gov/MatrixMarket/) 用于测试。'
- en: '*Iterative methods.* Roundoff error can accumulate in Gaussian elimination.
    Iterative methods (Gauss-Seidel, Jacobi iteration, successive over relaxation)
    can also be used to refine solutions to linear systems of equations obtained via
    Gaussian elimination. Also can solve from scratch - a big advantage if A is sparse.
    Gauss Seidel: x[0] = b, x[k+1] = (I - A)x[k] + b. If all diagonal of entries of
    A are 1 (can assume by rescaling) and all eigenvalues of (I - A) are less than
    1 in magnitude, then Gauss-Seidel iterates converge to true solution.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*迭代方法.* 高斯消元中会积累舍入误差。迭代方法（高斯-赛德尔，雅各比迭代，逐次超松弛）也可用于改进通过高斯消元获得的线性方程组的解。也可以从头开始解决
    - 如果 A 是稀疏的话，这是一个很大的优势。高斯-赛德尔：x[0] = b, x[k+1] = (I - A)x[k] + b。如果 A 的对角线上的元素都是
    1（可以通过重新缩放假设），且（I - A）的所有特征值的绝对值都小于 1，那么高斯-赛德尔迭代会收敛到真解。'
- en: '**Matrix ADT.** Now, we describe an ADT for matrices.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵 ADT.** 现在，我们描述一个矩阵的 ADT。'
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The program [Matrix.java](Matrix.java.html) implements the following operations:
    add, multiply, transpose, identity matrix, trace, and random matrix. More ops:
    inverse, rank, determinant, eigenvalues, eigenvectors, norm, solve, condition
    number, singular values.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 程序 [Matrix.java](Matrix.java.html) 实现了以下操作：加法，乘法，转置，单位矩阵，迹，随机矩阵。更多操作：逆，秩，行列式，特征值，特征向量，范数，解，条件数，奇异值。
- en: '**Java libraries for numerical linear algebra**. Building efficient and robust
    algorithm for linear algebraic problems is a challenging task. Fortunately, such
    algorithms have been refined over the past few decades, and mature libraries are
    available and easy to access. [JAMA: A Java Matrix Package]( http://math.nist.gov/javanumerics/jama/)
    is such a library for matrix operations including solving Ax = b, computing eigenvalues,
    computing the singular value decomposition, etc. The algorithms are the same as
    the ones in EISPACK, LINPACK, and MATLAB. This software has been released into
    the public domain by The MathWorks and the National Institute of Standards and
    Technology (NIST). Here is the [Javadoc documentation](http://math.nist.gov/javanumerics/jama/doc/).
    Program [JamaTest.java](JamaTest.java.html) illustrates how to interface with
    this library. It solves a system of 3 linear equations in 3 unknowns using the
    JAMA package.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**用于数值线性代数的 Java 库**。构建高效和稳健的线性代数问题算法是一项具有挑战性的任务。幸运的是，这些算法在过去几十年中得到了改进，成熟的库易于访问。[JAMA：Java
    矩阵包](http://math.nist.gov/javanumerics/jama/) 是一个包括解 Ax = b，计算特征值，计算奇异值分解等矩阵操作的库。这些算法与
    EISPACK、LINPACK 和 MATLAB 中的算法相同。这个软件已经被 MathWorks 和国家标准技术研究所（NIST）释放到公共领域。这里是[Javadoc
    文档](http://math.nist.gov/javanumerics/jama/doc/)。程序 [JamaTest.java](JamaTest.java.html)
    演示了如何与这个库进行交互。它使用 JAMA 包解决了一个包含 3 个未知数的线性方程组。'
- en: '**Eigenvalues and eigenvectors.** Given a square matrix A, the eigenvalue problem
    is to find solutions to Ax = λx. A scalar λ that satisfies this equation is called
    an *eigenvalue* and the corresponding vector x is called an *eigenvector*. Solutions
    to the eigenvalue problem play an important role of the computational infrastructure
    in many scientific and engineering disciplines. In 1940, Tacoma Narrows Bridge
    collapsed four months after it was built because frequency of wind was too close
    to natural frequency of bridge, and this caused overwhelming oscillations. Natural
    frequency of the bridge is the smallest eigenvalue in linear system that models
    the bridge. Eigenvalues also used to analyze modes of vibrations of a string,
    solutions to differential equations, Leslie matrix model of population dynamics,
    test for cracks or deformities in a solid, probe land for oil, damp noise in car
    passenger compartment, design concert halls for optimum sound quality, compute
    axes of inertia of a rigid body.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征值和特征向量。** 给定一个方阵A，特征值问题是找到满足Ax = λx的解。满足这个方程的标量λ被称为*特征值*，对应的向量x被称为*特征向量*。特征值问题的解在许多科学和工程学科的计算基础设施中扮演着重要角色。1940年，塔科马纳罗斯大桥在建成四个月后倒塌，因为风的频率太接近桥梁的固有频率，导致了压倒性的振荡。桥梁的固有频率是模拟桥梁的线性系统中最小的特征值。特征值也用于分析弦的振动模式，微分方程的解，莱斯利矩阵模型的人口动态，检测固体中的裂缝或变形，勘探土地寻找石油，减少汽车乘客舱内的噪音，设计音质最佳的音乐厅，计算刚体的惯性轴。'
- en: '*Spectral decomposition.* If A is symmetric, then the eigenvalue decomposition
    is A = VΛV^T where Λ is the diagonal matrix of eigenvalues and V is the orthogonal
    matrix of eigenvectors. Program [Eigenvalues.java](Eigenvalues.java.html) generates
    a random symmetric positive definite matrix and computes its spectral decomposition
    using the Jama library `EigenvalueDecomposition`.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*谱分解。* 如果A是对称的，那么特征值分解是A = VΛV^T，其中Λ是特征值的对角矩阵，V是特征向量的正交矩阵。程序[Eigenvalues.java](Eigenvalues.java.html)生成一个随机的对称正定矩阵，并使用Jama库`EigenvalueDecomposition`计算其谱分解。'
- en: '*Power method.* In many science and engineering applications, the principal
    eigenvalue (largest in absolute value) and associated eigenvector reveal the dominant
    mode of behavior. For example, Google uses it to rank the most important web pages,
    a structural engineer uses it to measure the maximum load of a bridge, a sound
    engineer uses it to measure the lowest resonating frequency in a concert hall.
    The *power method* is a simple scheme to isolate the largest eigenvalue and the
    associated eigenvector.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*幂法。* 在许多科学和工程应用中，主特征值（绝对值最大的）和相关的特征向量揭示了主导行为模式。例如，谷歌使用它来排名最重要的网页，结构工程师使用它来测量桥梁的最大荷载，声学工程师使用它来测量音乐厅中最低的共振频率。*幂法*是一种简单的方案来分离最大特征值和相关的特征向量。'
- en: x = Ax
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x = Ax
- en: x = x / |x|
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x = x / |x|
- en: λ = x^TAx / x^Tx
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: λ = x^TAx / x^Tx
- en: Here |x| means the L1 norm (for probability distributions) or L2 norm. Under
    general technical conditions, λ converges to the principal eigenvalue and x converges
    to the principal eigenvector.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的|x|表示L1范数（用于概率分布）或L2范数。在一般的技术条件下，λ收敛到主特征值，x收敛到主特征向量。
- en: '*Markov chain stationary distribution.* A Markov chain is.... Like a randomized
    NFA. Compute the fraction of time that the Markov chain spends in each state.
    Stationary distribution satisfies π A = π. The vector π is the (normalized) eigenvector
    corresponding to the eigenvalue 1. Under certain technical conditions (ergodic),
    the stationary distribution is unique and it is the principle eigenvector of A^T.
    All components of this eigenvector are guaranteed to be nonnegative.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*马尔可夫链稳态分布。* 马尔可夫链是...像一个随机的NFA。计算马尔可夫链在每个状态中花费的时间比例。稳态分布满足π A = π。向量π是对应于特征值1的（归一化的）特征向量。在某些技术条件（遍历性）下，稳态分布是唯一的，它是A^T的主特征向量。这个特征向量的所有分量都保证是非负的。'
- en: '*Google''s PageRank algorithm.* Use eigenvalues to rank importance of web pages
    or rank football teams according to strength of schedule. [good discussion](http://www.math.utsc.utoronto.ca/b24/KendallWei.pdf).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*Google的PageRank算法。* 使用特征值来排名网页的重要性或者根据赛程强度排名足球队伍。[好的讨论](http://www.math.utsc.utoronto.ca/b24/KendallWei.pdf)。'
- en: Jack Dongarra has an online guide [Templates for the Solution of Algebraic Eigenvalue
    Problems](http://www.cs.utk.edu/~dongarra/etemplates/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Jack Dongarra有一个在线指南[代数特征值问题的解模板](http://www.cs.utk.edu/~dongarra/etemplates/)。
- en: '**Singular values.** The *singular value decomposition* is a fundamental concept
    in science and engineering, and one of the most central problems in numerical
    linear algebra. Given an M-by-N matrix A, the singular value decomposition is
    A = UΣV^T, where U is an M-by-N matrix with orthogonal columns, Σ is an N-by-N
    diagonal matrix, and V is an N-by-N orthogonal matrix. It is also known as principal
    component analysis (PCA) in statistics and the Karhunen-Loeve or Hotelling expansion
    in pattern recognition. The SVD is well-defined for any M-by-N matrix (even if
    the matrix does not have full row or column rank) and is essentially unique (assuming
    the singular values are in descending order). It is efficiently computable in
    time O( min { MN^2, M^2N } ). It has many astonishing and beautiful properties,
    which we will only begin to explore. The SVD has many applications: multiple linear
    regression, factor analysis, computer graphics, [face recognition](http://vismod.media.mit.edu/vismod/demos/facerec/basic.html),
    noise reduction, information retrieval, robotics, gene expression analysis, computational
    tomography, geophysical inversion (seismology), image compression, image deblurring,
    face recognition, using optics linear sensitivity matrices to analyze spacecraft
    dynamics, visualization of chemical databases, and latent semantic indexing (LSI).
    Also widely used in [biology](http://cmgm.stanford.edu/biochem218/Projects%20Spring%202003/McGrath.pdf)
    to deconvolute a titration involving a mixture of three pH indicators, in protein
    dynamics to analyze the movement of myoglobin, analysis of microarray data, reverse
    engineering gene networks.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**奇异值。** *奇异值分解*是科学和工程中的一个基本概念，也是数值线性代数中最核心的问题之一。给定一个M×N矩阵A，奇异值分解是A = UΣV^T，其中U是具有正交列的M×N矩阵，Σ是一个N×N对角矩阵，V是一个N×N正交矩阵。在统计学中也被称为主成分分析（PCA），在模式识别中被称为Karhunen-Loeve或Hotelling展开。奇异值分解对于任何M×N矩阵都是明确定义的（即使矩阵没有完整的行或列秩），并且基本上是唯一的（假设奇异值按降序排列）。它的计算效率为O(
    min { MN^2, M^2N } )。它具有许多惊人和美丽的性质，我们只会开始探索其中的一部分。奇异值分解有许多应用：多元线性回归、因子分析、计算机图形学、[人脸识别](http://vismod.media.mit.edu/vismod/demos/facerec/basic.html)、降噪、信息检索、机器人技术、基因表达分析、计算断层摄影、地球物理反演（地震学）、图像压缩、图像去模糊、人脸识别、利用光学线性灵敏度矩��分析航天器动态、化学数据库的可视化以及潜在语义索引（LSI）。在[生物学](http://cmgm.stanford.edu/biochem218/Projects%20Spring%202003/McGrath.pdf)中也被广泛应用于解卷积涉及三种pH指示剂混合的滴定，蛋白质动力学分析肌红蛋白的运动，微阵列数据分析，逆向工程基因网络。'
- en: Program [SVD.java](SVD.java.html) computes the singular values of a random 8-by-5
    matrix. It also prints out the condition number, numerical rank, and 2-norm.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 程序[SVD.java](SVD.java.html)计算一个随机8×5矩阵的奇异值。它还输出条件数、数值秩和2-范数。
- en: '**Image processing.** Lossy compressions. A popular technique for compressing
    images is other data is via the SVD or Karhunen-Loeve decomposition. We can treat
    an M-by-N image of pixels, as three M-by-N arrays red, green, and blue intensities,
    each intensity is between 0 and 255\. Using the SVD, we can compute the "best"
    rank r approximation to each of the three matrices. This can be stored using only
    r(M + N + 1) values instead of MN. As r gets larger, the quality of the image
    improves, but at the expense of more storage.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**图像处理。** 有损压缩。压缩图像和其他数据的一种流行技术是通过SVD或Karhunen-Loeve分解。我们可以将一个M×N像素图像视为三个M×N数组，分别表示红色、绿色和蓝色强度，每个强度在0到255之间。使用SVD，我们可以计算每个三个矩阵的“最佳”秩r近似。这可以仅使用r(M
    + N + 1)个值来存储，而不是MN。随着r的增大，图像的质量会提高，但会增加存储成本。'
- en: One of the SVDs most important properties is that the *truncated SVD* A[r] =
    U[r]S[r]V[r] is the best rank r approximation to A, where U[r] denotes the first
    r columns of U, V[r] denotes the first r columns of V, and S[r] denotes the first
    r rows and columns of S. Here "best" means L_2 norm - A[r] minimizes sum of the
    squares of the differences between A and A[r].
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: SVD的最重要特性之一是*截断SVD* A[r] = U[r]S[r]V[r] 是矩阵A的最佳秩r近似，其中U[r]表示U的前r列，V[r]表示V的前r列，S[r]表示S的前r行和列。这里的“最佳”是指L_2范数
    - A[r]使得A和A[r]之间的差的平方和最小化。
- en: Program [KarhunenLoeve.java](KarhunenLoeve.java.html) reads in a picture and
    an integer r, compute the best rank r approximation of each of its red, green,
    and blue matrices, and display the resulting compressed picture. The key subroutine
    computes the best rank r approximation to matrix A. The method `getMatrix(i1,
    i2, j1, j2)` returns the submatrix of A bounded by the specified row and column
    indices.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 程序[KarhunenLoeve.java](KarhunenLoeve.java.html)读入一张图片和一个整数r，计算其红色、绿色和蓝色矩阵的最佳秩r近似，并显示结果压缩后的图片。关键子程序计算矩阵A的最佳秩r近似。方法`getMatrix(i1,
    i2, j1, j2)`返回由指定行和列索引限定的A的子矩阵。
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The images below give the results of the KL-transform on the famous Mandrill
    test image for ranks 2, 5, 10, 25, 50, and 298. The last one is the original image.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像展示了对著名的Mandrill测试图像进行KL变换的结果，秩分别为2、5、10、25、50和298。最后一个是原始图像。
- en: '| ![Karhunen-Loeve transform](../Images/903784043c79a2c418d40c2d80ffb70d.png)
    | ![Karhunen-Loeve transform](../Images/2ca0ffcb1f264ca66b2c439e8acf00f8.png)
    | ![Karhunen-Loeve transform](../Images/8600f4e539e90a5df033b11686621418.png)
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| ![Karhunen-Loeve transform](../Images/903784043c79a2c418d40c2d80ffb70d.png)
    | ![Karhunen-Loeve transform](../Images/2ca0ffcb1f264ca66b2c439e8acf00f8.png)
    | ![Karhunen-Loeve transform](../Images/8600f4e539e90a5df033b11686621418.png)
    |'
- en: '| ![Karhunen-Loeve transform](../Images/944ef9284758af992e8f36d4118aab3a.png)
    | ![Karhunen-Loeve transform](../Images/61db57ea890b27265b9546e1d049a081.png)
    | ![Karhunen-Loeve transform](../Images/019e768915961025923e85d7f0cdc0e3.png)
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| ![Karhunen-Loeve transform](../Images/944ef9284758af992e8f36d4118aab3a.png)
    | ![Karhunen-Loeve transform](../Images/61db57ea890b27265b9546e1d049a081.png)
    | ![Karhunen-Loeve transform](../Images/019e768915961025923e85d7f0cdc0e3.png)
    |'
- en: '**Latent semantic indexing.** LSI used by Google to classify web pages, linguists
    to classify documents, etc. Create matrix where rows index terms in a document
    and column index documents. The matrix entry (i, j) is some function of how many
    times the term i appears in document j. The matrix AA^T measure the document similarities.
    Eigenvectors correspond to linguistic concepts, e.g., sports might subsume the
    terms football, hockey, and baseball. LSI techniques can identify hidden correlations
    between documents, even if the documents don''t share any terms in common. For
    example, the terms car and automobile get pulled together, since both occur frequently
    with the terms tire, radiator and cylinder.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**潜在语义索引。** 谷歌用于分类网页，语言学家用于分类文档等的 LSI。创建矩阵，其中行索引文档中的术语，列索引文档。矩阵条目 (i, j) 是术语
    i 在文档 j 中出现的次数的某种函数。矩阵 AA^T 衡量文档之间的相似性。特征向量对应于语言概念，例如，体育可能包含足球、曲棍球和棒球等术语。LSI 技术可以识别文档之间的隐藏相关性，即使这些文档没有共同的术语。例如，术语汽车和汽车被拉在一起，因为两者都经常与轮胎、散热器和汽缸等术语一起出现。'
- en: '**Hubs and authorities.** Kleinberg''s method for finding relevant web pages.
    A[ij] = 1 if there is a link from i to j, and 0 otherwise. The matrix A^TA counts
    how many links i and j have in common; the matrix AA^T counts how many common
    pages link to i and j. A *hub* is a page that points to multiple authoritative
    pages; an *authority* is a page that is pointed to by multiple hubs. The principal
    component of A^TA (or equivalently the first column of U in the SVD A = USV^T)
    gives the "principle hubs"; the principle component of AA^T (or equivalently the
    first column of V) gives the "principle authorities."'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**中心节点和权威节点。** Kleinberg 的方法用于查找相关的网页。如果从 i 到 j 有链接，则 A[ij] = 1，否则为 0。矩阵 A^TA
    统计 i 和 j 共同拥有多少链接；矩阵 AA^T 统计多少共同页面链接到 i 和 j。*中心节点*是指指向多个权威页面的页面；*权威节点*是指被多个中心节点指向的页面。矩阵
    A^TA 的主要成分（或者等价地，SVD A = USV^T 中 U 的第一列）给出了“主要中心节点”；矩阵 AA^T 的主要成分（或者等价地，V 的第一列）给出了“主要权威节点”。'
- en: '**Gene expression data analysis.** Subject genes to a battery of experiments
    and try to cluster genes with similar responses together. Group genes by transcription
    response, grouping assays by expression profile.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**基因表达数据分析。** 将基因置于一系列实验中，并尝试将具有相似响应的基因聚类在一起。通过转录响应对基因进行分组，通过表达谱对实验进行分组。'
- en: '**Sparse matrices.** An N-by-N matrix is *sparse* if the number of nonzeros
    is proportional to N. Sparse matrices of dimension 100,000 arise in optimization
    and solutions to partial differential equations. The search engine Google computes
    with a monstrous sparse matrix of size N = 4 billion. The 2D array representation
    is rendered useless in these contexts. For example, to compute a matrix-vector
    product would require quadratic space and time. The power method for computing
    the principal eigenvector requires a fast matrix-vector multiply. We will describe
    how to do the same computation in linear time. The main idea is to explicitly
    store only the s nonzeros of the matrix A, while retaining enough auxiliary information
    to compute with A. We will describe one popular [sparse matrix storage scheme](http://www.cs.utk.edu/~dongarra/etemplates/node372.html#sec:data-structures)
    known as *compressed row storage*. We store all s nonzero entries consecutively
    in a one dimensional array `val[]` so that `val[j]` stores the jth nonzero (in
    the order from left to right, and top to bottom). We also maintain two extra auxiliary
    arrays to provide access to the individual matrix entries. Specifically we maintain
    one integer array `col[]` of size s such that `col[j]` is the column in which
    the jth nonzero appears. Finally, maintain an integer array `row` of size N+1
    such that `row[i]` is the index of the first nonzero from row i in the array `val`.
    By convention `row[N] = s`.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**稀疏矩阵。** 如果非零元素的数量与 N 成比例，则 N×N 矩阵是*稀疏*的。在优化和解决偏微分方程的情况下，维度为 100,000 的稀疏矩阵会出现。搜索引擎谷歌使用大小为
    N = 40 亿的庞大稀疏矩阵进行计算。在这些情况下，2D 数组表示变得无用。例如，要计算矩阵-向量乘积将需要二次空间和时间。计算主特征向量的幂法需要快速的矩阵-向量乘法。我们将描述如何在线性时间内执行相同的计算。主要思想是仅显式存储矩阵
    A 的 s 个非零元素，同时保留足够的辅助信息以便与 A 进行计算。我们将描述一种被称为*压缩行存储*的流行[稀疏矩阵存储方案](http://www.cs.utk.edu/~dongarra/etemplates/node372.html#sec:data-structures)。我们将所有
    s 个非零条目连续存储在一个一维数组 `val[]` 中，以便 `val[j]` 存储第 j 个非零元素（按从左到右、从上到下的顺序）。我们还维护两个额外的辅助数组，以提供对各个矩阵条目的访问。具体来说，我们维护一个大小为
    s 的整数数组 `col[]`，使得 `col[j]` 是第 j 个非零元素出现的列。最后，维护一个大小为 N+1 的整数数组 `row`，使得 `row[i]`
    是数组 `val` 中第 i 行的第一个非零元素的索引。按照惯例，`row[N] = s`。'
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Since each `double` consumes 8 bytes and each `int` consumes 4 bytes, the overall
    storage for CRS is roughly 12s + 4N. This compares favorably with the 8N² bytes
    required with the 2D array representation. Now, if A is represented using CRS,
    then the matrix-vector product y = Ax is efficiently computed using the following
    compact code fragment. The number of floating point operations is now proportional
    to (s + N) instead of N².
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个`double`占用 8 字节，每个`int`占用 4 字节，CRS 的整体存储大约为 12s + 4N。与 2D 数组表示需要的 8N² 字节相比，这是有利的。现在，如果
    A 使用 CRS 表示，那么矩阵-向量乘积 y = Ax 可以使用以下紧凑的代码片段高效计算。现在，浮点运算的数量与 (s + N) 成正比，而不是 N²。
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Computing y = A^Tx is a little trickier since the naive approach involves traversing
    the columns of A, which is not convenient using CRS format. Switching the order
    of summation yields:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 y = A^Tx 稍微棘手，因为朴素方法涉及遍历 A 的列，这在 CRS 格式下不方便。改变求和顺序得到：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Conjugate gradient method.** A Krylov-subspace method when A is symmetric
    positive definite. [Probably omit or leave as an exercise.]'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**共轭梯度法。** 当 A 对称正定时的 Krylov 子空间方法。[可能省略或留作练习。]'
- en: Q & A
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 问答
- en: Q. Is there ever a reason to explicitly compute the inverse of a matrix?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 问：有没有理由明确计算矩阵的逆？
- en: A. Yes, if it's asked for on an exam. In practice, it's almost never necessary.
    To solve Ax = b, you should use Gaussian elimination instead of forming A^(-1)b.
    If you need to solve Ax = b for many different values of b, then use something
    called the LU decomposition. It's twice as fast and has better numerical accuracy
    and stability properties.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: A. 是的，如果在考试中要求。在实践中，几乎从不需要。要解Ax = b，应该使用高斯消元而不是形成A^(-1)b。如果需要为许多不同的b值解Ax = b，则使用称为LU分解的东西。它是两倍快，具有更好的数值精度和稳定性属性。
- en: Exercises
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 练习
- en: Add a method `frobenius()` to `Matrix` that returns the Frobenius norm of the
    matrix. The *Frobenius norm* is the square root of sum of the squares of all the
    entries.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Matrix`中添加一个名为`frobenius()`的方法，返回矩阵的Frobenius范数。*Frobenius范数*是所有条目的平方和的平方根。
- en: Add a method `normInfinity` that returns the *infinity norm* of the matrix.
    The infinity norm (a.k.a., row sum norm) is the maximum sum obtained by adding
    the absolute values of the elements in each row.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名为`normInfinity`的方法，返回矩阵的*无穷范数*。无穷范数（又称行和范数）是通过将每行中元素的绝对值相加得到的最大和。
- en: Add a method `trace` that returns the *trace* of the matrix. The trace is the
    sum of the diagonal entries.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名为`trace`的方法，返回矩阵的*迹*。迹是对角线条目的总和。
- en: Add a method `isSymmetric` that returns `true` if the matrix is *symmetric*
    and `false` otherwise. The matrix A is symmetric if it is square and A[ij] = A[ji]
    for all i and j.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名为`isSymmetric`的方法，如果矩阵是*对称*的，则返回`true`，否则返回`false`。矩阵A是对称的，如果它是方阵且对于所有i和j，A[ij]
    = A[ji]。
- en: Add a method `isTridiagonal` that returns `true` if the matrix is *tridiagonal*,
    and `false` otherwise.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名为`isTridiagonal`的方法，如果矩阵是*三对角*的，则返回`true`，否则返回`false`。
- en: Given an N-by-N array `a[][]`, write a code fragment to transpose `a` in-place.
    That is, use at most a few extra variables of storage.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定一个N×N数组`a[][]`，编写一个代码片段来原地转置`a`。也就是说，最多使用少量额外的存储变量。
- en: Add a method `plusEquals` that takes a Matrix B as input and over-writes the
    invoking matrix with the sum of itself and B.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个名为`plusEquals`的方法，以矩阵B作为输入，并用自身和B的和覆盖调用矩阵。
- en: Suppose you run Gaussian elimination without exchanging rows. Show that it will
    fail on
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你进行高斯消元而不交换行。展示它将在哪里失败
- en: '[PRE14]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Alternative pivot strategy: choose the row in column j such that |A_ij| / max_k
    | A_ik| is as large as possible.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 替代的主元策略：选择列j中的行，使得|A_ij| / max_k | A_ik|尽可能大。
- en: Solve the following system Ax = b by hand using partial pivoting. Creates numbers
    as big as 2^5\. Generalizes to 2^N for N-by-N system.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过部分主元消去法手工解以下系统Ax = b。创建的数字最大为2^5。对于N×N系统，泛化为2^N。
- en: '[PRE15]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Intermediate expression swell.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 中间表达式膨胀。
- en: Consider an N-by-N matrix A of the following form for N = 100,
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑一个N×N矩阵A，形式如下，对于N = 100，
- en: '[PRE16]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: and a vector b = [1, 0, 0, ..., 0, 0]. The matrix A is nonsingular and Ax =
    b has the unique solution x = [1/2, 0, 0, ..., 0, 9/20]. Solve Ax = b using Gaussian
    elimination with partial pivoting (either our code or the Jama library). Examine
    the residual error and observe that the solution vector has no significant digits
    of accuracy in many coordinates. The matrix A is well-conditioned, so it is not
    a result of the problem being ill-conditioned as in XYZ. Instead, it is because
    partial pivoting is unstable, and this input highlights this defect. Name your
    program [PartialPivotStability.java](PartialPivotStability.java.html).
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 和一个向量b = [1, 0, 0, ..., 0, 0]。矩阵A是非奇异的，Ax = b有唯一解x = [1/2, 0, 0, ..., 0, 9/20]。使用带部分主元消去的高斯消元解Ax
    = b（使用我们的代码或Jama库）。检查残差误差，并观察解向量在许多坐标上没有有效数字。矩阵A是良好条件的，因此这不是问题不良条件的结果，如XYZ中所述。相反，这是因为部分主元消去是不稳定的，这个输入突显了这个缺陷。将你的程序命名为[PartialPivotStability.java](PartialPivotStability.java.html)。
- en: Solve the following upper triangular linear system of equations by hand using
    back-substitution.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过手工使用回代法解以下上三角线性方程组。
- en: '[PRE17]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Answer:* -1 2 2.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*答案:* -1 2 2。'
- en: Solve the following linear system of equations by hand using Gaussian elimination
    and back-substitution.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过手工使用高斯消元和回代解以下线性方程组。
- en: '[PRE18]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*Answer:* -1 2 2\. You should obtain the upper triangular system in the previous
    exercise along the way.'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*答案:* -1 2 2。你应该在解上一个练习中获得上三角系统。'
- en: Solve the following linear system of equations.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解以下线性方程组。
- en: '[PRE19]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '*Answer:* 2 3 5 7 -1 4.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*答案:* 2 3 5 7 -1 4。'
- en: '**Area of a triangle and ccw.** Formulas for the area of a triangle have been
    known for 2000 years. Grade school formula (1/2 base * height) and Heron''s formula
    require analyzing trigonometric functions or taking square roots. In the 17th
    century Descartes and Fermat used linear algebra to gain new insight into geometric
    problems. For example, the following determinant gives twice the signed area of
    the triangle with vertices a, b, and c.'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**三角形的面积和ccw。** 三角形面积的公式已知已有2000年。小学公式（1/2底*高）和海伦公式需要分析三角函数或取平方根。在17世纪，笛卡尔和费马使用线性代数来深入了解几何问题。例如，以下行列式给出了以a、b和c为顶点的三角形的带符号面积的两倍。'
- en: '[PRE20]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The sign of the determinant specifies whether or not c is to the left or, to
    the right of, or on the line directed from a to b. This ccw test is a useful primitive
    for convex hull and other computational geometry algorithms. Generalizes naturally
    to higher dimensions for tetrahedron and other simplices.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 行列式的符号指定了c是在a到b的线上的左侧、右侧还是在线上。这个ccw测试对于凸包和其他计算几何算法非常有用。自然地推广到更高维度的四面体和其他单纯形。
- en: '**In-circle test.** Determine if the point d lies inside or outside the circle
    defined by the three points a, b, and c in the plane. Application: primitive operation
    in Delaunay triangulation algorithms. Assuming that a, b, c are labeled in counterclockwise
    order around the circle, the following determinant is positive if d is inside
    the circle, negative if d is outside the circle, and zero if all four points are
    cocircular. This generalizes naturally to higher dimensions, e.g., point inside
    a sphere defined by 4 points.'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Given the equation of a plane ax + by + cz = 1 that contains the three points
    (10, 5, 2), (3, 8, 9), and (3, 6, -1).
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the eigenvalues and eigenvectors of the following matrix.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*Answer:* λ[1] = 2, λ[2] = 4.'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Suppose you are presented with the problem of computing c^TA^(-1)d. Explain
    how to do it without explicitly computing A^(-1). *Solution.* Solve Ax = d for
    x using Gaussian elimination. Now the desired answer is c^Tx. Whenever you see
    an inverse in a formula, always think of it as solving an equation rather than
    computing an inverse.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creative Exercises
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Complex matrices.** Create an abstract data type to represent complex matrices.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Lights out.** Implement a solver for the games [Lights Out](http://www.braingle.com/games/disco/index.php?play=1).
    Solve a linear system of equations (over Z_2) to determine which lights to turn
    on (if such a solution exists).'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Feasibility detection.** Can''t find a non zero pivot and the current right
    hand side is nonzero.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Certificate of infeasibility.** If there is no solution to Ax = b, then Gaussian
    elimination will fail. If so, then there exists a vector c such that c^TA = 0
    and c^Tb ≠ 0. Modify Gaussian elimination so that it produces such a vector when
    Ax = b has no solutions.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tridiagonal matrices.** Implement a data type `TridiagonalMatrix` that implements
    a tridiagonal matrix using three 1-D arrays. Design an algorithm that solves Ax
    = b when A is a square tridiagonal matrix. Your algorithm should run in linear
    time.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Strassen''s algorithm.** N^(2.81) divide-and-conquer algorithm for matrix
    multiplication. Compare vs. Gaussian elimination.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Special matrices.** Create classes `DiagonalMatrix`, `TridiagonalMatrix`
    using inheritance and override the methods for solving a linear system of equations
    and matrix multiplication....'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Markov chains.** Markov chains are a simple mathematical tool for modeling
    behavioral patterns. Widely used in many scientific areas including queuing theory,
    statistics, modeling population processes, and gene prediction. Glass and Hall
    (1949) distinguished 7 states in their social mobility study:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Professional, high administrative
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Managerial
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Inspectional, supervisory, non-manual high grade
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-manual low grade
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Skilled manual
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Semi-skilled manual
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Unskilled manual
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The table below presents the data from their study. Entry (i, j) is the probability
    of transitioning from state i to j.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Write a program [MarkovChain.java](MarkovChain.java.html) to compute some interesting
    quantity.
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Hilbert matrix.** Write a program [Hilbert.java](Hilbert.java.html) that
    reads in a command line parameter N, creates an N-by-N *Hilbert matrix* H, numerically
    computes its inverse H^(-1). The i-j entry of a Hilbert matrix is 1/(i+j-1). All
    Hilbert matrices are invertible. Below is the 4-by-4 Hilbert matrix and its inverse'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: What happens when you try to invert a 100-by-100 Hilbert matrix?
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Answer*: Jama matrix inverter reports that the matrix is not invertible. The
    Hilbert matrix is ill-conditioned, and most linear algebra packages have difficulty
    inverting this matrix for sufficiently large N. Note that although it inverts
    smaller matrices without reporting an error, there is substantial error in the
    results.'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Markov chain stationary distribution.** If Markov chain M is *irreducible*
    (possible to get from any state to any other state after finitely many transitions)
    and aperiodic, then it it called *ergodic*. The stationary distribution is the
    (unique) eigenvector of M corresponding to eigenvalue = 1.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Detailed balance.** A special case of an ergodic Markov chain is one that
    satisfies *detailed balance*: there exists π[i] such that π[i] p[ij] = π[j] p[ji]
    for all i and j != i. Show that if detailed balance is satisfied, then π P = π.
    *Hint*: sum over j.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Random walk on a ring.** Suppose you have a circle of N nodes and you start
    at node 1. At each step, you flip a fair coin and go clockwise or counterclockwise
    accordingly. Calculate the probability that each vertex (other than 1) is the
    last one visited. *Solution*: all have equal likelihood of being last!'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Leontief input-output model.** Branch of economics that uses linear algebra
    to model interdependencies of industries. (Wassily Leontief won 1973 Nobel Prize
    in Economics) [description](http://aix1.uottawa.ca/~jkhoury/leonteif.htm). Leontief
    divided American economy into 81 sectors ( petroleum, textiles, transportation,
    chemicals, steel, agriculture, etc.) [example](http://www.krellinst.org/AiS/textbook/unit7/f77_7.11_leontief.html)
    *Technology matrix* represents amount of each resource required to produce one
    unit of another resource. For example, producing 1 unit of petroleum requires
    0.2 units of transportation, 0.4 units of chemicals, and 0.1 unit of itself. Units
    measured in millions of dollars.'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If economy produces *net* of 900 milion dollars of petroleum, 300, 850, and
    800 of textiles, transportation, and chemicals, what is amount of each consumed
    *internally* by economy. Multiply Ax to get b [880, 110, 550, 822.50].
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Leontief closed model.** Balanced ecomomy: Ax = x. Total production of each
    sector equals total consumption.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Leontief open model.** External demand vector d: Ax + d = x Matrix is *productive*
    if solution exists which has nonnegative components. $1 coal requires 0.3 electricity,
    0.1 auto, and 0.1 of itself.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Demand d = [50 75 125]. (I - A)x = d. x = [229.9, 437.8, 237.4].
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Leslie matrix model.** In population ecology, the Leslie matrix models the
    age distribution of a population this is naturally segmented into age classes.
    Let F[i] be the fecundity rate of females in class i, and let S[i] be the survival
    rate from class i to i+1\. The Leslie matrix L is constructed by:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Leslie matrix](../Images/dd2d01015adadd630f858a0c5b6d5193.png)'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_IMG
- en: 'The follow table lists the birth and survival probabilities for [female New
    Zealand sheep](http://www.math.duke.edu/education/ccp/materials/linalg/leslie/lesl1.html).
    The original source is: [from G. Caughley, "Parameters for Seasonally Breeding
    Populations," Ecology 48(1967)834-839].'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| Age (years) | Birth rate | Survival rate |'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 0-1 | 0.000 | 0.845 |'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 1-2 | 0.045 | 0.975 |'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 2-3 | 0.391 | 0.965 |'
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 3-4 | 0.472 | 0.950 |'
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 4-5 | 0.484 | 0.926 |'
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 5-6 | 0.546 | 0.895 |'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 6-7 | 0.543 | 0.850 |'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 7-8 | 0.502 | 0.786 |'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 8-9 | 0.468 | 0.691 |'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 9-10 | 0.459 | 0.561 |'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 10-11 | 0.433 | 0.370 |'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: '| 11-12 | 0.421 | 0.000 |'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_TB
- en: 'Leslie matrix property: unique positive eigenvalue and corresponding eigenvector
    has all entries real and of the same sign. In this example 1.175. Use [eigenvalues](http://isolatium.uhh.hawaii.edu/linear/ch6/green.htm)
    to analyze.'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Leslie matrix model.** Chinook salmon in Columbia River Basin (Kareiva et
    al, 2002)'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Principal eigenvalue = rate of population growth = 0.93 (decrease 7% per year).
    Stationary distribution.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Maximum cardinality matching.** Given a bipartite G graph with N vertices
    on each side, find a matching of maximum cardinality. Form N-by-N adjacency matrix.
    If there is an edge between i and j, set entry i-j to a random number between
    0 and 2N. If determinant is nonzero, then G has a perfect matching. If determinant
    is zero, then with probability at least 1/2, G does not have a a perfect matching.
    Repeat to get better error tolerance. Same idea to get max cardinality, but use
    rank(G). Note: there are faster algorithms for finding a perfect matching using
    graphs, but this one is efficiently parallelizable.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最大基数匹配。** 给定一个双分图 G，每一边有 N 个顶点，找到最大基数匹配。形成 N×N 邻接矩阵。如果 i 和 j 之间有一条边，将 i-j
    的条目设置为 0 到 2N 之间的随机数。如果行列式非零，则 G 有一个完美匹配。如果行列式为零，则至少有 1/2 的概率 G 没有完美匹配。重复以获得更好的误差容限。相同的思路来获得最大基数，但使用
    rank(G)。注意：有更快的算法用于使用图找到完美匹配，但这个算法可以有效地并行化。'
- en: '**Maximum cardinality matching.** Redo previous exercise but to avoid overflow
    to all computations mod p, where p is a prime between N and 2N.'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最大基数匹配。** 重新做前面的练习，但为了避免溢出，将所有计算模 p，其中 p 是介于 N 和 2N 之间的素数。'
- en: '**Maximum cardinality matching.** Devise an algorithm to find the perfect matching
    if it exists.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最大基数匹配。** 设计一个算法来找到完美匹配（如果存在）。'
- en: '**Number of paths from s to t.** Given an undirected graph G, count the number
    of paths from s to t. Look at the kth power of the adjacency matrix G. Note that
    paths need not be simple.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**从 s 到 t 的路径数。** 给定一个无向图 G，计算从 s 到 t 的路径数。查看邻接矩阵 G 的 k 次幂。注意路径不一定是简单的。'
- en: '**Finding all simplicial vertices of a graph.** Given an undirected graph G,
    a *simplicial vertex* is a vertex v such that if you take any two of its neighbors
    x and y, then there is an edge between x and y. Find all simplicial vertices in
    a graph with N vertices in time less than N³. *Hint*: compute the N-by-N vertex
    adjacency matrix A, where A[vw] = 1 if there is an edge between v and w or if
    v = w, and 0 otherwise. Fact: a vertex is simplicial if and only if (A²)[vv] =
    (A²)[vw] for all vertices w adjacent to v. Use fast matrix multiplication to compute
    A².'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查找图的所有单纯顶点。** 给定一个无向图 G，*单纯顶点* 是一个顶点 v，如果你取任意两个它的邻居 x 和 y，那么 x 和 y 之间就有一条边。在时间复杂度小于
    N³ 的情况下找到图中所有的单纯顶点。*提示*：计算 N×N 顶点邻接矩阵 A，其中 A[vw] = 1 表示 v 和 w 之间有一条边或者 v = w，否则为
    0。事实：一个顶点是单纯的当且仅当对于所有与 v 相邻的顶点 w，(A²)[vv] = (A²)[vw]。使用快速矩阵乘法计算 A²。'
- en: '**Counting the number of triangles in a directed graph.** Given a directed
    graph G, a *triangle* is three vertices x, y, and z such that there is a directed
    cycle x->y->z->x or x->z->y->x. Given a graph with N vertices, write a program
    to print out all triangles in time less than N³. *Hint*: compute the N-by-N vertex
    adjacency matrix A, where A[vw] = 1 if there is an edge from v to w, and 0 otherwise
    (including if v = w). Then (A²)[vw] is the number of paths going from v to w through
    exactly one other intermediate vertex. There is a triangle x->y->z if an only
    if (A²)[xz] > 0 and A[zx] = 1.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算有向图中三角形的数量。** 给定一个有向图 G，*三角形* 是三个顶点 x、y 和 z，使得存在一个有向循环 x->y->z->x 或 x->z->y->x。给定一个具有
    N 个顶点的图，编写一个程序在时间复杂度小于 N³ 的情况下打印出所有的三角形。*提示*：计算 N×N 顶点邻接矩阵 A，其中 A[vw] = 1 表示从
    v 到 w 有一条边，否则为 0（包括 v = w 的情况）。然后 (A²)[vw] 表示从 v 到 w 通过恰好一个其他中间顶点的路径数。只有当 (A²)[xz]
    > 0 且 A[zx] = 1 时，存在三角形 x->y->z。'
- en: '**Numerical rank.** The *numerical rank* is the number of nonzero singular
    values. Use SVD to compute.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数值秩。** *数值秩* 是非零奇异值的数量。使用奇异值分解（SVD）进行计算。'
- en: '**Condition number.** The *condition number* κ is the ratio of the largest
    singular value to the smallest one. First proposed by Alan Turing! For a square
    matrix, it measures how close the matrix is to being singular. For a rectangular
    matrix, it measures how close the matrix is to being rank deficient. It is also
    useful to bound how much the solution to Ax = b can change if we make a small
    perturbation b. If the condition number is very large then we don''t expect very
    accurate results when we solve Ax = b. Roughly speaking the number of bits of
    accuracy in the solution is equal to the number of bits of accuracy in the input
    minus log[2]κ.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**条件数。** *条件数* κ 是最大奇异值与最小奇异值的比值。最初由 Alan Turing 提出！对于方阵，它衡量矩阵接近奇异的程度。对于矩形矩阵，它衡量矩阵接近秩不足的程度。它还有助于限制如果我们对
    Ax = b 进行微小扰动，解可以改变多少。如果条件数非常大，那么当我们解 Ax = b 时就不会得到非常准确的结果。粗略地说，解的精度位数等于输入精度位数减去
    log[2]κ。'
- en: 'Here''s a particularly pathological 4-by-4 matrix whose condition number is
    around 10^65\. This means that will less than 65 decimal digits of precision,
    we cannot expect any significant digits of accuracy in our answer. [Reference:
    S.M. Rump. A Class of Arbitrarily Ill-conditioned Floating-Point Matrices. SIAM
    Journal on Matrix Analysis and Applications (SIMAX), 12(4):645-653, 1991.]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个特别病态的 4×4 矩阵，其条件数约为 10^65。这意味着在不到 65 位小数精度的情况下，我们不能期望在答案中有任何有效数字。[参考：S.M.
    Rump. A Class of Arbitrarily Ill-conditioned Floating-Point Matrices. SIAM Journal
    on Matrix Analysis and Applications (SIMAX), 12(4):645-653, 1991.]
- en: '[PRE28]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Symmetric positive definite.** An N-by-N matrix A is *symmetric positive
    definite* if it is symmetric and x^TAx > 0 for all x ≠ 0 (equivalently, all eigenvalues
    are positive). Symmetric positive definite matrices arise as covariance matrices
    in statistics, stiffness matrices in finite element methods, normal equations
    in linear regression. Write a program to test whether a matrix is symmetric positive
    definite. Hint: all pivots are positive in Gaussian elimination (and no row interchanges).'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对称正定。** 一个 N×N 矩阵 A 是*对称正定*的，如果它是对称的且对于所有 x ≠ 0 都有 x^TAx > 0（等价地，所有特征值都是正的）。对称正定矩阵在统计学中作为协方差矩阵，在有限元方法中作为刚度矩阵，在线性回归的正规方程中出现。编写一个程序来测试一个矩阵是否是对称正定的。提示：在高斯消元中所有主元都是正的（且没有行交换）。'
- en: '**Cholesky decomposition.** Write a program [Cholesky.java](Cholesky.java.html)
    to compute the [Cholesky decomposition](http://en.wikipedia.org/wiki/Cholesky_decomposition)
    of a symmetric positive definite matrices: A = LL^T. Use the Cholesky-Banachiewicz
    algorithm.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Cholesky分解。** 编写一个程序[Cholesky.java](Cholesky.java.html)来计算对称正定矩阵的[Cholesky分解](http://en.wikipedia.org/wiki/Cholesky_decomposition)：A
    = LL^T。使用Cholesky-Banachiewicz算法。'
- en: '[PRE29]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '**Multidimensional scaling.** Reconstruct relative point positions given only
    inter-point distances. Solution to fundamental problem is technique used to draw
    map of US in 3d over surface of globe, etc. Given N points in the two dimensional
    plane, define an N-by-N matrix A such that A[ij] is the Euclidean distance between
    point i and point j. Find an *isometric embedding*, i.e., a set of points that
    satisfy these distances. *Hint*: let I be the N-by-N identity matrix, let B be
    the N-by-N matrix of squared pairwise distances, and let u be an N-by-1 vector
    of all 1''s, B be the matrix of squared distances among the n points, and let
    C = (-1/2)(I - uu^T/N) * B * (I - uu^T/N). If the points lie in an m-dimensional
    space, then C is positive semidefinite and has rank m. Let C = LL^T be the Cholesky
    decomposition of C. Then L contains the coordinates of the points.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多维缩放。** 仅根据点间距离重建相对点位置。解决基本问题的技术用于在地球表面上绘制美国的三维地图等。在二维平面上给定N个点，定义一个N×N矩阵A，使得A[ij]是点i和点j之间的欧几里德距离。找到一个*等距嵌入*，即满足这些距离的一组点。*提示*：让I为N×N单位矩阵，让B为N×N的平方成对距离矩阵，让u为全1的N×1向量，B为n个点之间的平方距离矩阵，并且让C
    = (-1/2)(I - uu^T/N) * B * (I - uu^T/N)。如果点位于m维空间中，则C是正半定的并且秩为m。让C = LL^T为C的Cholesky分解。然后L包含点的坐标。'
- en: '**Compressed column storage.** *Compressed column storage* (a.k.a. Harwell-Boeing
    storage) is completely analogous to *compressed row storage* except that the columns
    are stored sequentially. Implement matrix-vector multiply when using CCS. *Hint*:
    storing A using CCS is the same as storing A^T using CRS.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**压缩列存储。** *压缩列存储*（又称Harwell-Boeing存储）与*压缩行存储*完全类似，只是列按顺序存储。在使用CCS时实现矩阵-向量乘法。*提示*：使用CCS存储A与使用CRS存储A^T是相同的。'
- en: '**Sparse band matrices.** Use [compressed diagonal storage](http://www.cs.utk.edu/~dongarra/etemplates/node376.html)
    to represent a *banded matrix*. Implement matrix-vector multiplication efficiently.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**稀疏带矩阵。** 使用[压缩对角线存储](http://www.cs.utk.edu/~dongarra/etemplates/node376.html)来表示*带状矩阵*。高效实现矩阵-向量乘法。'
- en: '**Roots of a polynomial.** Given a polynomial a[n]x^n + ... + a[1]x + a[0],
    we can compute its roots by finding the eigenvalues of the *companion matrix*.'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多项式的根。** 给定多项式a[n]x^n + ... + a[1]x + a[0]，我们可以通过找到*伴随矩阵*的特征值来计算其根。'
- en: '![Companion matrix](../Images/8d8deb1054e9d4a7f9f454398f93990f.png)'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_IMG
  zh: '![伴随矩阵](../Images/8d8deb1054e9d4a7f9f454398f93990f.png)'
- en: Not numerically stable, so it's not guaranteed to work reliably.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不稳定数值，因此不能保证可靠工作。
- en: '**Real roots of a polynomial.** Write a program `RouthHurwitz.java` that takes
    as input the positive, real, coefficients of a polynomial a[0] + a[1]x¹ + ...
    + a[n]x^N and determines whether all zeros of the polynomial have negative real
    part. This is a classic problem in control theory and can be used to determine
    whether a linear system is stable (if the real parts of every root is negative
    then it is stable; otherwise unstable). From the celebrated [Routh-Hurwitz stability
    criterion](http://mathworld.wolfram.com/Routh-HurwitzTheorem.html) this is true
    if and only if all principal subdeterminants of the following N-by-N matrix are
    strictly positive.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多项式的实根。** 编写一个程序`RouthHurwitz.java`，其输入为多项式a[0] + a[1]x¹ + ... + a[n]x^N的正实系数，并确定多项式的所有零点是否具有负实部。这是控制理论中的经典问题，可用于确定线性系统是否稳定（如果每个根的实部为负，则它是稳定的；否则不稳定）。根据著名的[Routh-Hurwitz稳定性判据](http://mathworld.wolfram.com/Routh-HurwitzTheorem.html)，如果以下N×N矩阵的所有主子行列式严格为正，则为真。'
- en: '![Routh-Hurwitz](../Images/628a47204f791bc8bbb41c7c88d51ca4.png)'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_IMG
  zh: '![Routh-Hurwitz](../Images/628a47204f791bc8bbb41c7c88d51ca4.png)'
- en: By convention, a[m] = 0 if m < 0 or m > n.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 按照惯例，如果m < 0或m > n，则a[m] = 0。
- en: '*Solution*: to compute all subdeterminants, run GE without pivoting - if you
    encoutner any zero or negative pivots, answer no. We could compute eigenvalues
    as in the previous exercise, but it can be done without explicitly computing the
    roots.'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*解决方案*：计算所有子行列式，运行不进行主元交换的高斯消元 - 如果遇到任何零或负主元，答案为否。我们可以像前面的练习一样计算特征值，但可以在不显式计算根的情况下完成。'
- en: '**Graph connectivity.** Given adjacency matrix of undirected graph A(G), the
    multiplicity of the largest eigenvalue (lambda = 1), equals the number of connected
    components in G. G is bipartite iff -1 is an eigenvalue of A(G).'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**图的连通性。** 给定无向图A(G)的邻接矩阵，最大特征值（lambda = 1）的重数等于G中连通分量的数量。如果-1是A(G)的特征值，则G是二部图。'
